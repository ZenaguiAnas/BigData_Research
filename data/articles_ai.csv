Title,Authors,HTML Link,PDF Link,Abstract,Published in,Date of Publication,Page(s),Electronic ISSN,PubMed ID,DOI,DOI Link,Publisher
Assessing Trustworthy AI in Times of COVID-19: Deep Learning for Predicting a Multiregional Score Conveying the Degree of Lung Compromise in COVID-19 Patients,Himanshi Allahabadi; Julia Amann; Isabelle Balot; Andrea Beretta; Charles Binkley; Jonas Bozenhard; Frédérick Bruneault; James Brusseau; Sema Candemir; Luca Alessandro Cappellini; Subrata Chakraborty; Nicoleta Cherciu; Christina Cociancig; Megan Coffee; Irene Ek; Leonardo Espinosa-Leal; Davide Farina; Geneviève Fieux-Castagnet; Thomas Frauenfelder; Alessio Gallucci; Guya Giuliani; Adam Golda; Irmhild van Halem; Elisabeth Hildt; Sune Holm; Georgios Kararigas; Sébastien A. Krier; Ulrich Kühne; Francesca Lizzi; Vince I. Madai; Aniek F. Markus; Serg Masis; Emilie Wiinblad Mathez; Francesco Mureddu; Emanuele Neri; Walter Osika; Matiss Ozols; Cecilia Panigutti; Brendan Parent; Francesca Pratesi; Pedro A. Moreno-Sánchez; Giovanni Sartor; Mattia Savardi; Alberto Signoroni; Hanna-Maria Sormunen; Andy Spezzatti; Adarsh Srivastava; Annette F. Stephansen; Lau Bee Theng; Jesmin Jahan Tithi; Jarno Tuominen; Steven Umbrello; Filippo Vaccher; Dennis Vetter; Magnus Westerlund; Renee Wurth; Roberto V. Zicari; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9845195/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9845195,"This article’s main contributions are twofold: 1) to demonstrate how to apply the general European Union’s High-Level Expert Group’s (EU HLEG) guidelines for trustworthy AI in practice for the domain of healthcare and 2) to investigate the research question of what does “trustworthy AI” mean at the time of the COVID-19 pandemic. To this end, we present the results of a post-hoc self-assessment to evaluate the trustworthiness of an AI system for predicting a multiregional score conveying the degree of lung compromise in COVID-19 patients, developed and verified by an interdisciplinary team with members from academia, public hospitals, and industry in time of pandemic. The AI system aims to help radiologists to estimate and communicate the severity of damage in a patient’s lung from Chest X-rays. It has been experimentally deployed in the radiology department of the ASST Spedali Civili clinic in Brescia, Italy, since December 2020 during pandemic time. The methodology we have applied for our post-hoc assessment, called Z-Inspection®, uses sociotechnical scenarios to identify ethical, technical, and domain-specific issues in the use of the AI system in the context of the pandemic.",IEEE Transactions on Technology and Society,29 July 2022,272 - 289,2637-6415,36573115,10.1109/TTS.2022.3195114,https://doi.org/10.1109/TTS.2022.3195114,IEEE
It is Not “Accuracy vs. Explainability”—We Need Both for Trustworthy AI Systems,Dragutin Petkovic; ,https://ieeexplore.ieee.org/document/10029927/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10029927,"We are witnessing the emergence of an “AI economy and society” where AI technologies and applications are increasingly impacting health care, business, transportation, defense and many aspects of everyday life. Many successes have been reported where AI systems even surpassed the accuracy of human experts. However, AI systems may produce errors, can exhibit bias, may be sensitive to noise in the data, and often lack technical and judicial transparency resulting in reduction in trust and challenges to their adoption. These recent shortcomings and concerns have been documented in both the scientific and general press such as accidents with self-driving cars, biases in healthcare or hiring and face recognition systems for people of color, and seemingly correct decisions later found to be made due to wrong reasons etc. This has resulted in the emergence of many government and regulatory initiatives requiring trustworthy and ethical AI to provide accuracy and robustness, some form of explainability, human control and oversight, elimination of bias, judicial transparency and safety. The challenges in delivery of trustworthy AI systems have motivated intense research on explainable AI systems (XAI). The original aim of XAI is to provide human understandable information of how AI systems make their decisions in order to increase user trust. In this paper we first very briefly summarize current XAI work and then challenge the recent arguments that present “accuracy vs. explainability” as being mutually exclusive and for focusing mainly on deep learning with its limited XAI capabilities. We then present our recommendations for the broad use of XAI in all stages of delivery of high stakes trustworthy AI systems, e.g., development; validation/certification; and trustworthy production and maintenance.",IEEE Transactions on Technology and Society,30 January 2023,46 - 53,2637-6415,,10.1109/TTS.2023.3239921,https://doi.org/10.1109/TTS.2023.3239921,IEEE
"The Generative AI Landscape in Education: Mapping the Terrain of Opportunities, Challenges, and Student Perception",Zishan Ahmed; Shakib Sadat Shanto; Most. Humayra Khanom Rime; Md. Kishor Morol; Nafiz Fahad; Md. Jakir Hossen; Md. Abdullah-Al-Jubair; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10681094/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10681094,"Generative AI (GAI) technologies like ChatGPT are permanently changing academic education. Their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. This study aims to fill the literature gap regarding the use of multiple GAI tools and their effect on academic outcomes via a comprehensive review. A systematic literature review was performed following PRISMA guidelines to synthesize results on the potential and drawbacks of GAI in educational domains. We included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. We have also explored conceptual frameworks and the most creative AI applications with a special emphasis on uniqueness and practicability. Experiences, and Perceptions Concerning To compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students’ experiences and perceptions related to GAI used for educational purposes. At the basic level, GAI comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. However, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of AI-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. Student Perception Survey the text also indicates that most students, as per the student perception survey found AI systems useful in academic support. However, they also know the other side of the coin and are very familiar with the technology constra...",IEEE Access,16 September 2024,147023 - 147050,2169-3536,,10.1109/ACCESS.2024.3461874,https://doi.org/10.1109/ACCESS.2024.3461874,IEEE
SmartQuant: CXL-Based AI Model Store in Support of Runtime Configurable Weight Quantization,Rui Xie; Asad Ul Haq; Linsen Ma; Krystal Sun; Sanchari Sen; Swagath Venkataramani; Liu Liu; Tong Zhang; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10663202/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10663202,"Recent studies have revealed that, during the inference on generative AI models such as transformer, the importance of different weights exhibits substantial context-dependent variations. This naturally manifests a promising potential of adaptively configuring weight quantization to improve the generative AI inference efficiency. Although configurable weight quantization can readily leverage the hardware support of variable-precision arithmetics in modern GPU and AI accelerators, little prior research has studied how one could exploit variable weight quantization to proportionally improve the AI model memory access speed and energy efficiency. Motivated by the rapidly maturing CXL ecosystem, this work develops a CXL-based design solution to fill this gap. The key is to allow CXL memory controllers play an active role in supporting and exploiting runtime configurable weight quantization. Using transformer as a representative generative AI model, we carried out experiments that well demonstrate the effectiveness of the proposed design solution.",IEEE Computer Architecture Letters,02 September 2024,199 - 202,,,10.1109/LCA.2024.3452699,https://doi.org/10.1109/LCA.2024.3452699,IEEE
mTREE: A Customized Multicast-Enabled Tree-Based Network on Chip for AI Chips,Yong Zheng; Haigang Yang; Yi Shu; Yiping Jia; Zhihong Huang; ; ; ; ; ,https://ieeexplore.ieee.org/document/9684541/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9684541,"The network on chip (NoC) used in the AI chip is required to be able to deliver data to multiple destination endpoints simultaneously. The existing solutions, such as hierarchial mesh (HMESH) and FATTREE all modify the connection between routers to achieve multicasting. Although this method can achieve delivering data to multiple destination endpoints at the same time, it significantly increases the number of routers used and, therefore, brings a huge additional area and power consumption overhead. In order to solve this problem, this work designed a customized multicast-enabled tree-based NoC, named mTREE, by modifying the microarchitecture of the router, including the routing calculation unit, credit counter, and switch allocator. When implemented on Arria10 FPGA, mTREE only brings a 1% increase in resource utilization compared with the traditional tree-topology NoC. Compared with two other multicast-enabled NoCs: 1) FATTREE and 2) HMESH, mTREE can reach a
3.19×
–
3.50×
and
1.67×
–
3.02×
reduction in resource utilization, respectively, and a
4.81×
–
8.01×
and
2.85×
–
3.03×
reduction in energy consumption, respectively.",IEEE Embedded Systems Letters,18 January 2022,143 - 146,,,10.1109/LES.2022.3144196,https://doi.org/10.1109/LES.2022.3144196,IEEE
A Survey of Real-Time Strategy Game AI Research and Competition in StarCraft,Santiago Ontañón; Gabriel Synnaeve; Alberto Uriarte; Florian Richoux; David Churchill; Mike Preuss; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/6637024/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6637024,"This paper presents an overview of the existing work on AI for real-time strategy (RTS) games. Specifically, we focus on the work around the game StarCraft, which has emerged in the past few years as the unified test bed for this research. We describe the specific AI challenges posed by RTS games, and overview the solutions that have been explored to address them. Additionally, we also present a summary of the results of the recent StarCraft AI competitions, describing the architectures used by the participants. Finally, we conclude with a discussion emphasizing which problems in the context of RTS game AI have been solved, and which remain open.",IEEE Transactions on Computational Intelligence and AI in Games,18 October 2013,293 - 311,,,10.1109/TCIAIG.2013.2286295,https://doi.org/10.1109/TCIAIG.2013.2286295,IEEE
Unraveling ML Models of Emotion With NOVA: Multi-Level Explainable AI for Non-Experts,Alexander Heimerl; Katharina Weitz; Tobias Baur; Elisabeth André; ; ; ; ,https://ieeexplore.ieee.org/document/9288932/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9288932,"In this article, we introduce a next-generation annotation tool called NOVA for emotional behaviour analysis, which implements a workflow that interactively incorporates the ‘human in the loop’. A main aspect of NOVA is the possibility of applying semi-supervised active learning where Machine Learning techniques are used already during the annotation process by giving the possibility to pre-label data automatically. Furthermore, NOVA implements recent eXplainable AI (XAI) techniques to provide users with both, a confidence value of the automatically predicted annotations, as well as visual explanations. We investigate how such techniques can assist non-experts in terms of trust, perceived self-efficacy, cognitive workload as well as creating correct mental models about the system by conducting a user study with 53 participants. The results show that NOVA can easily be used by non-experts and lead to a high computer self-efficacy. Furthermore, the results indicate that XAI visualisations help users to create more correct mental models about the machine learning system compared to the baseline condition. Nevertheless, we suggest that explanations in the field of AI have to be more focused on user-needs as well as on the classification task and the model they want to explain.",IEEE Transactions on Affective Computing,09 December 2020,1155 - 1167,,,10.1109/TAFFC.2020.3043603,https://doi.org/10.1109/TAFFC.2020.3043603,IEEE
AIS-PVT: Long-Time AIS Data Assisted Pyramid Vision Transformer for Sea-Land Segmentation in Dual-Polarization SAR Imagery,Jiaqiu Ai; Weibao Xue; Yanan Zhu; Shuo Zhuang; Congan Xu; Hao Yan; Lifu Chen; Zhaocheng Wang; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10648835/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10648835,"Traditional synthetic aperture radar (SAR) image sea-land segmentation algorithms overlook the ship distribution priori-information provided by the automatic identification system (AIS) data, resulting in poor segmentation performance in complex environments such as ports, marine wetlands, beaches, and other sea-land boundaries. To address the above issues, this article comprehensively uses dual-polarization (VV and VH) SAR images and AIS data as the data source, and it specifically proposes a novel pyramid vision transformer (PVT) assisted by the long-time AIS data (AIS-PVT) for sea-land segmentation. AIS-PVT is the first attempt to integrate the ship distribution density priori-information, provided by the long-time AIS data, into the PVT network, thus the multiscale features of the sea and land can be better distinguished. In the decoding stage, we design a feature filter module (FFM). It aggregates features separately along two spatial directions from the skip connections, enhancing the representation of objects of interest while reducing the influence of redundant information. Furthermore, we develop a boundary-pixel-aware function to steer the model training process, allowing AIS-PVT to concentrate more on the neighborhood information of boundary pixels. Importantly, the AIS-PVT method captures global multiscale information and enhances the model’s data fusion capability. The conclusive experimental results demonstrate the superior performance of our approach in sea-land segmentation tasks, outperforming other state-of-the-art (SOTA) techniques.",IEEE Transactions on Geoscience and Remote Sensing,26 August 2024,,,,10.1109/TGRS.2024.3449894,https://doi.org/10.1109/TGRS.2024.3449894,IEEE
Explainable AI for Cheating Detection and Churn Prediction in Online Games,Jianrong Tao; Yu Xiong; Shiwei Zhao; Runze Wu; Xudong Shen; Tangjie Lyu; Changjie Fan; Zhipeng Hu; Sha Zhao; Gang Pan; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9772248/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9772248,"Online gaming is a multibillion dollar industry that entertains a large, global population. Empowering online games with AI has made a great success, however, ignores the explainability of black-box model makes AI less responsible and hinders its further development. In this article, we introduce and discuss the audience and the concept of XAI (eXplainable AI) in online games. We propose a GXAI workflow, which combines the strong expressiveness of multiview data sources and the clear transparency of multiview black-box models. We present four specific classifiers and explainers in the character portrait view, the behavior sequence view, the client image view, and the social graph view. Experiments conducted on real-world datasets for game cheating detection and player churn prediction show the accuracy of classification and the rationality of explanation. We also discover and present numerous interesting and valuable findings from the individual, local, and global explanations. We implement and deploy three practical applications, including evidence and reason generation, model debugging and testing, and model compression and comparison in NetEase Games and have received quite positive reviews from user studies. More future work is in progress since this is the first work that introduces XAI in online games.",IEEE Transactions on Games,10 May 2022,242 - 251,,,10.1109/TG.2022.3173399,https://doi.org/10.1109/TG.2022.3173399,IEEE
Towards Measuring Fairness in AI: The Casual Conversations Dataset,Caner Hazirbas; Joanna Bitton; Brian Dolhansky; Jacqueline Pan; Albert Gordo; Cristian Canton Ferrer; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9634168/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9634168,"This paper introduces a novel dataset to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of age, genders, apparent skin tones and ambient lighting conditions. Our dataset is composed of 3,011 subjects and contains over 45,000 videos, with an average of 15 videos per person. The videos were recorded in multiple U.S. states with a diverse set of adults in various age, gender and apparent skin tone groups. A key feature is that each subject agreed to participate for their likenesses to be used. Additionally, our age and gender annotations are provided by the subjects themselves. A group of trained annotators labeled the subjects’ apparent skin tone using the Fitzpatrick skin type scale. Moreover, annotations for videos recorded in low ambient lighting are also provided. As an application to measure robustness of predictions across certain attributes, we provide a comprehensive study on the top five winners of the DeepFake Detection Challenge (DFDC). Experimental evaluation shows that the winning models are less performant on some specific groups of people, such as subjects with darker skin tones and thus may not generalize to all people. In addition, we also evaluate the state-of-the-art apparent age and gender classification methods. Our experiments provides a thorough analysis on these models in terms of fair treatment of people from various backgrounds.","IEEE Transactions on Biometrics, Behavior, and Identity Science",03 December 2021,324 - 332,2637-6407,,10.1109/TBIOM.2021.3132237,https://doi.org/10.1109/TBIOM.2021.3132237,IEEE
Personas for Artificial Intelligence (AI) an Open Source Toolbox,Andreas Holzinger; Michaela Kargl; Bettina Kipperer; Peter Regitnig; Markus Plass; Heimo Müller; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9721903/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9721903,"Personas have successfully supported the development of classical user interfaces for more than two decades by mapping users’ mental models to specific contexts. The rapid proliferation of Artificial Intelligence (AI) applications makes it necessary to create new approaches for future human-AI interfaces. Human-AI interfaces differ from classical human-computer interfaces in many ways, such as gaining some degree of human-like cognitive, self-executing, and self-adaptive capabilities and autonomy, and generating unexpected outputs that require non-deterministic interactions. Moreover, the most successful AI approaches are so-called “black box” systems, where the technology and the machine learning process are opaque to the user and the AI output is far not intuitive. This work shows how the personas method can be adapted to support the development of human-centered AI applications, and we demonstrate this on the example of a medical context. This work is - to our knowledge - the first to provide personas for AI using an openly available Personas for AI toolbox . The toolbox contains guidelines and material supporting persona development for AI as well as templates and pictures for persona visualisation. It is ready to use and freely available to the international research and development community. Additionally, an example from medical AI is provided as a best practice use case. This work is intended to help foster the development of novel human-AI interfaces that will be urgently needed in the near future.",IEEE Access,25 February 2022,23732 - 23747,2169-3536,,10.1109/ACCESS.2022.3154776,https://doi.org/10.1109/ACCESS.2022.3154776,IEEE
A Game AI Competition to Foster Collaborative AI Research and Development,Ana Salta; Rui Prada; Francisco S. Melo; ; ; ,https://ieeexplore.ieee.org/document/9197664/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197664,"Game artificial intelligence (AI) competitions are important to foster research and development on Game AI and AI in general. These competitions supply different challenging problems that can be translated into other contexts, virtual or real. They provide frameworks and tools to facilitate the research on their core topics and provide means for comparing and sharing results. A competition is also a way to motivate new researchers to study these challenges. In this article, we present the Geometry Friends game AI competition. Geometry Friends is a two-player cooperative physics-based puzzle platformer computer game. The concept of the game is simple, though its solving has proven to be difficult. While the main and apparent focus of the game is cooperation, it also relies on other AI-related problems such as planning, plan execution, and motion control, all connected to situational awareness. All of these must be solved in real-time. In this article, we discuss the competition and the challenges it brings, and present an overview of the current solutions.",IEEE Transactions on Games,15 September 2020,398 - 409,,,10.1109/TG.2020.3024160,https://doi.org/10.1109/TG.2020.3024160,IEEE
A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model,,https://ieeexplore.ieee.org/document/10452390/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10452390,"In the realm of Generative AI, where various models are introduced, prompt engineering emerges as a significant technique within natural language processing-based Generative AI. Its primary function lies in effectively enhancing the results of sentence generation by large language models (LLMs). Notably, prompt engineering has gained attention as a method capable of improving LLM performance by modifying the structure of input prompts alone. In this study, we apply prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data. We achieve this through the utilization of the query transformation module (QTM). Our proposed QTM transforms input prompt sentences into three distinct query methods, breaking them down into objectives and key points, making them more comprehensible for LLMs. For performance validation, we employ Korean versions of LLMs, specifically SKT GPT-2 and Kakaobrain KoGPT-3. We compare four different query methods, including the original unmodified query, using Google SSA to assess the naturalness and specificity of generated sentences. The results demonstrate an average improvement of 11.46% when compared to the unmodified query, underscoring the efficacy of the proposed QTM in achieving enhanced performance.",Journal of Web Engineering,November 2023,1187 - 1206,,,10.13052/jwe1540-9589.2285,https://doi.org/10.13052/jwe1540-9589.2285,River Publishers
Toward a Policy Approach to Normative Artificial Intelligence Governance: Implications for AI Ethics Education,Dayoung Kim; Qin Zhu; Hoda Eldardiry; ; ; ,https://ieeexplore.ieee.org/document/10614075/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10614075,"There has been a trend among various stakeholders for AI governance, such as the government, industry, and academia, that advocates for a shift from traditional ethics approach to more recent policy-oriented approach. This paper starts by briefly introducing the motivation for such a change. To further help AI ethics researchers ground their discussion about how to operationalize abstract AI ethics into actionable policy, it introduces existing literature about AI policy development efforts with ethics focus. We also discuss the implications of the policy approach to normative AI governance for training the next generation of AI professionals. More specifically, this paper introduces two approaches that AI educators can employ to encourage their students to participate in policy discussions and practical exercises in AI-related courses. The insights derived from this paper hold particular significance for AI professionals, educators, and policymakers aiming to translate general AI ethics principles into operationalizable action items with broader policy implications in the design of AI systems.",IEEE Transactions on Technology and Society,29 July 2024,325 - 333,2637-6415,,10.1109/TTS.2024.3430940,https://doi.org/10.1109/TTS.2024.3430940,IEEE
Human-Centered AI in Smart Farming: Toward Agriculture 5.0,Andreas Holzinger; Iztok Fister; Iztok Fister; Hans-Peter Kaul; Senthold Asseng; ; ; ; ; ,https://ieeexplore.ieee.org/document/10510441/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10510441,"This paper delineates the contemporary landscape, challenges, and prospective developments in human-centred artificial intelligence (AI) within the ambit of smart farming, a pivotal element of the emergent Agriculture 5.0, supplanting Agriculture 4.0. Analogous to Industry 4.0, agriculture has witnessed a trend towards comprehensive automation, often marginalizing human involvement. However, this approach has encountered limitations in agricultural contexts for various reasons. While AI’s capacity to assume human tasks is acknowledged, the inclusion of human expertise and experiential knowledge (human-in-the-loop) often proves indispensable, corroborated by the Moravec’s Paradox: tasks simple for humans are complex for AI. Furthermore, social, ethical, and legal imperatives necessitate human oversight of AI, a stance strongly reflected in the European Union’s regulatory framework. Consequently, this paper explores the advancements in human-centred AI focusing on their application in agricultural processes. These technological strides aim to enhance crop yields, minimize labor and resource wastage, and optimize the farm-to-consumer supply chain. The potential of AI to augment human decision-making, thereby fostering a sustainable, efficient, and resilient agri-food sector, is a focal point of this discussion - motivated by the current worldwide extreme weather events. Finally, a framework for Agriculture 5.0 is presented, which balances technological prowess with the needs, capabilities, and contexts of human stakeholders. Such an approach, emphasizing accessible, intuitive AI systems that meaningfully complement human activities, is crucial for the successful realization of future Agriculture 5.0.",IEEE Access,30 April 2024,62199 - 62214,2169-3536,,10.1109/ACCESS.2024.3395532,https://doi.org/10.1109/ACCESS.2024.3395532,IEEE
XAI-IoT: An Explainable AI Framework for Enhancing Anomaly Detection in IoT Systems,Anna Namrita Gummadi; Jerry C. Napier; Mustafa Abdallah; ; ; ,https://ieeexplore.ieee.org/document/10534036/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10534036,"The exponential growth of Internet of Things (IoT) systems inspires new research directions on developing artificial intelligence (AI) techniques for detecting anomalies in these IoT systems. One important goal in this context is to accurately detect and anticipate anomalies (or failures) in IoT devices and identify main characteristics for such anomalies to reduce maintenance cost and minimize downtime. In this paper, we propose an explainable AI (XAI) framework for enhancing anomaly detection in IoT systems. Our framework has two main components. First, we propose AI-based anomaly detection of IoT systems where we adapt two classes of AI methods (single AI methods, and ensemble methods) for anomaly detection in smart IoT systems. Such anomaly detection aims at detecting anomaly data (from deployed sensors or network traffic between IoT devices). Second, we conduct feature importance analysis to identify the main features that can help AI models identify anomalies in IoT systems. For this feature analysis, we use seven different XAI methods for extracting important features for different AI methods and different attack types. We test our XAI framework for anomaly detection through two real-world IoT datasets. The first dataset is collected from IoT-based manufacturing sensors and the second dataset is collected from IoT botnet attacks. For the IoT-based manufacturing dataset, we detect the level of defect for data from IoT sensors. For the IoT botnet attack dataset, we detect different attack classes from different kinds of botnet attacks on the IoT network. For both datasets, we provide extensive feature importance analysis using different XAI methods for our different AI models to extract the top features. We release our codes for the community to access it for anomaly detection and feature analysis for IoT systems and to build on it with new datasets and models. Taken together, we show that accurate anomaly detection can be achieved along with understanding top ...",IEEE Access,17 May 2024,71024 - 71054,2169-3536,,10.1109/ACCESS.2024.3402446,https://doi.org/10.1109/ACCESS.2024.3402446,IEEE
An Area-Efficient Systolic Array Redundancy Architecture for Reliable AI Accelerator,Hayoung Lee; Jongho Park; Sungho Kang; ; ; ,https://ieeexplore.ieee.org/document/10587312/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10587312,"The increasing demand for data-intensive analytics, driven by the rapid advances in artificial intelligence (AI), has led to the proposal of various AI accelerators. However, as AI-based solutions are being applied to applications that require high accuracy and reliability, ensuring the dependability of these solutions has become a critical issue. In this brief, we present an area-efficient systolic array redundancy architecture for reliable AI accelerator. In the proposed architecture, computations assigned to faulty multiply-accumulate (MAC) units are bypassed using dedicated routes. Subsequently, the same computations are executed in shiftable redundant MACs or selectable redundant MACs. This ensures the correct completion of calculations all without performance reduction. Moreover, the reassignment of computations can be efficiently managed through a simple scheduling algorithm. As a result, the proposed architecture achieves a high repair rate through the redundant MACs and effective computation reassignment. Despite these capabilities, the proposed architecture incurs only a small area overhead.",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,08 July 2024,1950 - 1954,,,10.1109/TVLSI.2024.3421563,https://doi.org/10.1109/TVLSI.2024.3421563,IEEE
Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services,Minrui Xu; Hongyang Du; Dusit Niyato; Jiawen Kang; Zehui Xiong; Shiwen Mao; Zhu Han; Abbas Jamalipour; Dong In Kim; Xuemin Shen; Victor C. M. Leung; H. Vincent Poor; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10398474/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10398474,"Artificial Intelligence-Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. This survey paper focuses on the deployment of AIGC applications, e.g., ChatGPT and Dall-E, at mobile edge networks, namely mobile AIGC networks, that provide personalized and customized AIGC services in real time while maintaining user privacy. We begin by introducing the background and fundamentals of generative models and the lifecycle of AIGC services at mobile AIGC networks, which includes data collection, training, fine-tuning, inference, and product management. We then discuss the collaborative cloud-edge-mobile infrastructure and technologies required to support AIGC services and enable users to access AIGC at mobile edge networks. Furthermore, we explore AIGC-driven creative applications and use cases for mobile AIGC networks. Additionally, we discuss the implementation, security, and privacy challenges of deploying mobile AIGC networks. Finally, we highlight some future research directions and open issues for the full realization of mobile AIGC networks.",IEEE Communications Surveys & Tutorials,12 January 2024,1127 - 1170,,,10.1109/COMST.2024.3353265,https://doi.org/10.1109/COMST.2024.3353265,IEEE
"Exploring the Effect of Generative AI on Social Sustainability Through Integrating AI Attributes, TPB, and T-EESST: A Deep Learning-Based Hybrid SEM-ANN Approach",Mostafa Al-Emran; Bassam Abu-Hijleh; AbdulRahman A. Alsewari; ; ; ,https://ieeexplore.ieee.org/document/10670553/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10670553,"The swift progress of generative artificial intelligence (AI) tools offers remarkable potential for revolutionizing educational methods and enhancing social sustainability. Despite its potential, understanding the factors driving its adoption and how that affects social sustainability remains underexplored. This study aims to address this gap by integrating AI attributes (“perceived anthropomorphism,” “perceived intelligence,” and “perceived animacy”) with the theory of planned behavior and the technology-environmental, economic, and social sustainability theory (T-EESST) to develop a theoretical research model. Utilizing a hybrid structural equation modeling and artificial neural network approach, we analyzed data collected from 1048 university students to evaluate the developed model. Our findings revealed that while perceived behavioral control has an insignificant impact on generative AI use, attitudes emerge as the most critical factor, further reinforced by the significant role of subjective norms. Perceived anthropomorphism, perceived intelligence, and perceived animacy were also found to influence students’ attitudes significantly. More importantly, the findings supported the role of generative AI in positively affecting social sustainability, aligning with the principles of T-EESST. This study's significance lies in its holistic examination of the interplay between technological attributes, motivational aspects, and sustainability outcomes, offering valuable insights for various stakeholders.",IEEE Transactions on Engineering Management,10 September 2024,14512 - 14524,,,10.1109/TEM.2024.3454169,https://doi.org/10.1109/TEM.2024.3454169,IEEE
The Ethics of AI in Games,David Melhart; Julian Togelius; Benedikte Mikkelsen; Christoffer Holmgård; Georgios N. Yannakakis; ; ; ; ; ,https://ieeexplore.ieee.org/document/10125072/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10125072,"Video games are one of the richest and most popular forms of human-computer interaction and, hence, their role is critical for our understanding of human behaviour and affect at a large scale. As artificial intelligence (AI) tools are gradually adopted by the game industry a series of ethical concerns arise. Such concerns, however, have so far not been extensively discussed in a video game context. Motivated by the lack of a comprehensive review on the ethics of AI as applied to games, we survey the current state of the art in this area and discuss ethical considerations of these systems from the holistic perspective of the affective loop . Through the components of this loop, we study the ethical challenges that AI faces in video game development. Elicitation highlights the ethical boundaries of artificially induced emotions; sensing showcases the trade-off between privacy and safe gaming spaces; and detection , as utilised during in-game adaptation , poses challenges to transparency and ownership. This paper calls for an open dialogue and action for the games of today and the virtual spaces of the future. By setting an appropriate framework we aim to protect users and to guide developers towards safer and better experiences for their customers.",IEEE Transactions on Affective Computing,16 May 2023,79 - 92,,,10.1109/TAFFC.2023.3276425,https://doi.org/10.1109/TAFFC.2023.3276425,IEEE
E-XAI: Evaluating Black-Box Explainable AI Frameworks for Network Intrusion Detection,Osvaldo Arreche; Tanish R. Guntur; Jack W. Roberts; Mustafa Abdallah; ; ; ; ,https://ieeexplore.ieee.org/document/10433134/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10433134,"The exponential growth of intrusions on networked systems inspires new research directions on developing artificial intelligence (AI) techniques for intrusion detection systems (IDS). In particular, the need to understand and explain these AI models to security analysts (managing these IDS to safeguard their networks) motivates the usage of explainable AI (XAI) methods in real-world IDS. In this work, we propose an end-to-end framework to evaluate black-box XAI methods for network IDS. We evaluate both global and local scopes for these black-box XAI methods for network intrusion detection. We analyze six different evaluation metrics for two popular black-box XAI techniques, namely SHAP and LIME. These metrics are descriptive accuracy, sparsity, stability, efficiency, robustness, and completeness. They cover main metrics from network security and AI domains. We evaluate our XAI evaluation framework using three popular network intrusion datasets and seven AI methods with different characteristics. We release our codes for the network security community to access it as a baseline XAI framework for network IDS. Our framework shows the limitations and strengths of current black-box XAI methods when applied to network IDS.",IEEE Access,12 February 2024,23954 - 23988,2169-3536,,10.1109/ACCESS.2024.3365140,https://doi.org/10.1109/ACCESS.2024.3365140,IEEE
Demystifying Defects: Federated Learning and Explainable AI for Semiconductor Fault Detection,Tanish Patel; Ramalingam Murugan; Gokul Yenduri; Rutvij H. Jhaveri; Hichem Snoussi; Tarek Gaber; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10589388/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10589388,"Semiconductor manufacturing, a critical driver of modern technology, involves intricate processes for fabricating integrated circuits on materials like silicon. This industry’s pivotal role spans various applications, from smartphones to computers, emphasizing the importance of fault detection to ensure the reliability and cost-efficiency of electronic devices. Fault detection within this sector entails collaboration among multiple stakeholders, including Original Equipment Manufacturers (OEMs), Integrated Device Manufacturers (IDMs), wafer foundries, and software providers. A common challenge is the reluctance to share sensitive design data centrally, which is essential for building traditional machine learning models. To overcome these challenges, this paper introduces an innovative fault detection model that leverages Federated Learning (FL) and Explainable AI (XAI). FL’s decentralized approach enhances model learning across multiple nodes without requiring the pooling of sensitive data, thus preserving data privacy. Concurrently, XAI ensures that the developed models maintain transparency and trustworthiness, even when trained on distributed datasets. This FL-based fault detection model permits stakeholders to train ML models on node-specific data without centralizing sensitive information. It accommodates heterogeneous and asynchronously-stored data, diverse machine learning models, and nodes with varying capacities and data volumes. By addressing the opacity of deep learning models, FL and XAI unveil their predictive behaviors in identifying semiconductor faults. Empirical results, obtained using a public dataset, demonstrate a significant improvement in defect identification precision, achieving an exceptional test accuracy of 98.78%. These findings underscore the potential of the proposed approach to transform fault detection in semiconductor manufacturing, thereby enhancing the reliability and efficiency of the production process.",IEEE Access,08 July 2024,116987 - 117007,2169-3536,,10.1109/ACCESS.2024.3425226,https://doi.org/10.1109/ACCESS.2024.3425226,IEEE
Developing a Transparent Diagnosis Model for Diabetic Retinopathy Using Explainable AI,Tariq Shahzad; Muhammad Saleem; Muhammad Sajid Farooq; Sagheer Abbas; Muhammad Adnan Khan; Khmaies Ouahada; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10706847/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10706847,"Diabetic retinopathy is a leading cause of vision complications and partially sighted which pose considerable diagnostic difficulties because of its diverse and varying symptoms. Some of them include the fact that the disease displays a non-uniform pattern, where patients present different symptoms; the requirement of highly qualified specialists to interpret the images of the fundus; the risk of errors in the interpretation of images or their inconsistency; and the absence of clear morphological signs often makes early diagnosis unlikely. Traditional diagnosis mostly rely on the expert interpretation of retinal images, which can lead to bias and inaccuracy; highlighting the need for improved diagnostic methods. Although traditional Artificial Intelligence (AI) methods enhance the diagnostic capabilities remarkably, their black box nature and information opacity restrict healthcare providers to comprehend the reasoning framework of the AI to build trust and optimize its usage in practice. Explainable AI (XAI) is an emerging approach that addresses the black-box problem by improving the interpretability of models, which allows users to understand the logic behind certain decisions. This research proposed a diagnosis model for detecting diabetic retinopathy using XAI approaches that increases the interpretability of the models to help clinicians understand the reasons behind the decisions. The proposed model is used to enhance diagnostic accuracy, offer comprehensible, and concise insights regarding the diagnostics. The convergence history plots of the proposed model validate the learning process to achieve 94% better diagnostic accuracy than traditional methods while improving interpretability and applicability in healthcare settings, indicating improvement in accuracy and loss reduction.",IEEE Access,07 October 2024,149700 - 149709,2169-3536,,10.1109/ACCESS.2024.3475550,https://doi.org/10.1109/ACCESS.2024.3475550,IEEE
"AI and Security, From an Information Security and Risk Manager Standpoint",Pranith Shetty; ,https://ieeexplore.ieee.org/document/10542982/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10542982,"Fields such as machine learning and artificial intelligence are proven business enablers, we have several use cases in the field of technology from basic implementations such as automated scanners, and weak forms such as Alexa and Siri that have paved the way for further development. Search for more avenues of investment in this field continues till date. It’s also evident that researchers and organizations have barely scratched the surface in terms of exploring and using AI (Artificial intelligence) as a technology. Theoretical forms of AI have not yet been implemented. This paper aims to provide some context around the various forms of AI currently used and can be explored in the near future. It’s important to be mindful that, with the use of any technology, even AI, there are challenges, regulations, and security risks that tag along. Firms need to pay close attention to the macro factors that could impact the adoption and AI in their respective businesses. This study aims to provide a brief overview of the aforementioned road blocks that could impact AI adoption, however, there are some solution strategies or approaches that could help firms along the way to overcome those road blocks. These strategies might take time to build and take effect but they will be beneficial in the long run and thus help with not only sustainable implementation, but also complete and successful adoption of AI as a technology enabler.",IEEE Access,31 May 2024,77468 - 77474,2169-3536,,10.1109/ACCESS.2024.3408144,https://doi.org/10.1109/ACCESS.2024.3408144,IEEE
Empirical Evaluations of Framework for Adaptive Trust Calibration in Human-AI Cooperation,Kazuo Okamura; Seiji Yamada; ; ,https://ieeexplore.ieee.org/document/9281021/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9281021,"Recent advances in AI technologies are dramatically changing the world and impacting our daily life. However, human users still essentially need to cooperate with AI systems to complete tasks as such technologies are never perfect. For optimal performance and safety in human-AI cooperation, human users must appropriately adjust their level of trust to the actual reliability of AI systems. Poorly calibrated trust can be a major cause of serious issues with safety and efficiency. Previous works on trust calibration have emphasized the importance of system transparency for avoiding trust miscalibration. Measuring and influencing trust are still challenging issues; consequently, not many studies have focused on how to detect improper trust calibration nor how to mitigate it. We approach these research challenges with a behavior-based approach to capture the status of calibration. A framework of adaptive trust calibration is proposed, including a formal definition of improper trust calibration called “a trust equation”. It involves cognitive cues called “trust calibration cues (TCCs)” and a conceptual entity called “trust calibration AI” (TCAI), which supervises the status of trust calibration. We conducted empirical evaluations using a simulated drone environment with two types of cooperative tasks: a visual search task and a real-time navigation task. We designed trust changing scenarios and evaluated our framework. The results demonstrated that adaptively presenting a TCC could promote trust calibration more effectively than a traditional system transparency approach.",IEEE Access,04 December 2020,220335 - 220351,2169-3536,,10.1109/ACCESS.2020.3042556,https://doi.org/10.1109/ACCESS.2020.3042556,IEEE
A New Zero-Overhead Test Method for Low-Power AI Accelerators,Sangjun Lee; Jongho Park; Sungwhan Park; Hyemin Kim; Sungho Kang; ; ; ; ; ,https://ieeexplore.ieee.org/document/10366839/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10366839,"Artificial intelligence (AI) accelerators that support AI services consist of multiple identical cores for parallel computation to accelerate artificial neural networks. Recently, systolic array-based architectures for low-power AI accelerators have been studied to support battery-operated edge devices and reduce power consumption. In this brief, a zero-overhead method is proposed for efficient testing of systolic array-based low-power AI accelerators. By using the structural characteristics of the systolic array and a reset operation, the proposed method can test multiple identical cores based on the systolic array without any additional hardware. The proposed method is divided into MAC and comparator test methods to use the structural characteristics of systolic arrays for low-power AI accelerators. The experimental results demonstrate that the proposed method achieves 100% test coverage without any additional hardware and has reasonable test times compared to previous methods.",IEEE Transactions on Circuits and Systems II: Express Briefs,20 December 2023,2649 - 2653,,,10.1109/TCSII.2023.3344696,https://doi.org/10.1109/TCSII.2023.3344696,IEEE
SXAD: Shapely eXplainable AI-Based Anomaly Detection Using Log Data,Kashif Alam; Kashif Kifayat; Gabriel Avelino Sampedro; Vincent Karovič; Tariq Naeem; ; ; ; ; ,https://ieeexplore.ieee.org/document/10589622/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10589622,"Artificial Intelligence (AI) has made tremendous progress in anomaly detection. However, AI models work as a black-box, making it challenging to provide reasoning behind their judgments in a Log Anomaly Detection (LAD). To the rescue, Explainable Artificial Intelligence (XAI) improves system log analysis. It follows a white-box model for transparency, understandability, trustworthiness, and dependability of Machine Learning (ML) and Deep Learning (DL) Models. In addition, Shapely Additive Explanation (SHAP), added to system dynamics, makes informed judgments and adoptable proactive methods to optimize system functionality and reliability. Therefore, this paper proposed the Shapely eXplainable Anomaly Detection (SXAD) framework to identify different events (features) that impact the models’ interpretability, trustworthiness, and explainability. The framework utilizes the Kernel SHAP approach, which is based on Shapley values principle, providing an innovative approach to event selection and identifying specific events causing abnormal behavior. This study addresses the LAD by transforming it from a black-box model into a white-box one, leveraging XAI to make it transparent, interpretable, explainable, and dependable. It utilizes benchmark data from the Hadoop Distributed File System (HDFS), organized using a Drain parser, and employs several ML models, such as Decision Tree (DT), Random Forest (RF), and Gradient Boosting (GB). These models achieve impressive accuracy rates of 99.99%, 99.85%, and 99.99%, respectively. Our contribution are novel because no earlier work has been done in the area of Log Anomaly Detection (LAD) with integration of XAI-SHAP.",IEEE Access,09 July 2024,95659 - 95672,2169-3536,,10.1109/ACCESS.2024.3425472,https://doi.org/10.1109/ACCESS.2024.3425472,IEEE
Designing and Evaluating User Experience of an AI-Based Defense System,Sunyoung Park; Hyun K. Kim; Jaehyun Park; Yuryeon Lee; ; ; ; ,https://ieeexplore.ieee.org/document/10304133/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10304133,"In recent years, artificial intelligence (AI) has been applied in various fields, with rapid expansion of the scope of AI-human interactions. However, most AI technologies continue to exhibit black-box characteristics, i.e., their decisions and actions are not explainable, degrading user experience (UX). Recently, research on explainable AI (XAI), focusing on both AI performance and UX, has garnered significant attention. However, development of generalizable UX evaluation tools for AI and improvement of AI UX have not been investigated adequately. In this study, a UX evaluation tool is developed for AI based on a systematic literature review and verified using exploratory and confirmatory factor analyses. Subsequently, based on identified AI UX factors, UX of an AI defense system is upgraded. Based on user evaluation, there were significant improvements in eight factors (satisfaction, safety, controllability, trust, causality, efficiency, accountability, and explainability) with the exception of fairness. The proposed evaluation tool is expected to serve as a cornerstone for future evaluation of AI UX advancement.",IEEE Access,01 November 2023,122045 - 122056,2169-3536,,10.1109/ACCESS.2023.3329257,https://doi.org/10.1109/ACCESS.2023.3329257,IEEE
Explainable AI Based Neck Direction Prediction and Analysis During Head Impacts,S. Shridevi; Susan Elias; ; ,https://ieeexplore.ieee.org/document/10440073/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10440073,"The position and orientation of the human neck need to be measured, analyzed, and monitored during head impacts to provide preventive healthcare measures. The proposed research explores the role of explainable Artificial Intelligence and Machine Learning in predicting the direction of the neck by analysing the muscle forces with appropriate explanations to support any clinical system for correct decision-making. The experimental data includes mild head impacts that were replicated with median American football simulating flexion and lateral movements and was performed on ten subjects including five male and five females. OpenSim software system is used for biomechanical modeling, simulation, and analysis and to visualize the direction of the neck. Different machine learning models including a sequential neural network model were built on the labelled tendon force muscle data. The XGB classifier achieved the best performance in predicting the neck direction with an accuracy of 98 percent. The proposed research work’s accuracy is promising when compared to existing works. Explainable Artificial Intelligence integration deduces the predictions of machine learning models adding meaningful interpretations to the achieved results.",IEEE Access,19 February 2024,31399 - 31408,2169-3536,,10.1109/ACCESS.2024.3367602,https://doi.org/10.1109/ACCESS.2024.3367602,IEEE
An Automated Approach for Predicting Road Traffic Accident Severity Using Transformer Learning and Explainable AI Technique,Omar Ibrahim Aboulola; Ebtisam Abdullah Alabdulqader; Aisha Ahmed AlArfaj; Shtwai Alsubai; Tai-Hoon Kim; ; ; ; ; ,https://ieeexplore.ieee.org/document/10477984/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10477984,"Traffic accidents continue to be a significant cause of fatalities, injuries, and considerable disruptions on our highways. Understanding the underlying factors behind these incidents is crucial for improving safety on road networks. While recent studies have highlighted the usefulness of predictive modeling in uncovering factors leading to accidents, there remains a gap in explaining the inner workings of complex machine learning and deep learning models and how various features influence accident prediction. This lack of transparency may lead to these models being perceived as black boxes, potentially undermining trust in their findings among stakeholders. The primary aim of this research is to develop predictive models using diverse transfer learning techniques and shed light on the most influential factors using Shapley values. In predicting injury severity in accidents, we employ Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Residual Networks (ResNET), EfficientNetB4, InceptionV3, Extreme Inception (Xception), Visual Geometry Group (VGG19), AlexNet, and MobileNet. Among these models, MobileNet emerges with the highest accuracy at 0.9817. Furthermore, by comprehending how different features impact accident prediction models, researchers can deepen their understanding of the factors contributing to accidents and devise more effective interventions for their prevention.",IEEE Access,22 March 2024,61062 - 61072,2169-3536,,10.1109/ACCESS.2024.3380895,https://doi.org/10.1109/ACCESS.2024.3380895,IEEE
Explainable and Fair AI: Balancing Performance in Financial and Real Estate Machine Learning Models,Deepak Bhaskar Acharya; B. Divya; Karthigeyan Kuppan; ; ; ,https://ieeexplore.ieee.org/document/10729220/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10729220,"This paper introduces a framework that integrates fairness and transparency into advanced machine learning models, specifically LightGBM and XGBoost, applied to loan approval and house price prediction datasets. The key contribution is using fairness-focused techniques, such as Calibrated Equalized Odds and Intersectional Fairness, which are not widely studied in financial and real estate contexts. To improve model transparency, SHAP (SHapley Additive exPlanations) is utilized along with a novel fairness-based interpretability method to measure both model fairness and the importance of individual features. Through comprehensive experiments, we show that LightGBM delivers high accuracy while balancing fairness and performance effectively. The broader relevance of this work is discussed in the context of governance and regulatory requirements, highlighting the importance of responsible practices in high-stakes financial decision-making processes. This research highlights the importance of fairness and transparency in real-world applications, promoting equity, trust, and adherence to evolving legal standards, and provides practical insights for data scientists, machine learning researchers, and professionals in the real estate and financial sectors.",IEEE Access,22 October 2024,154022 - 154034,2169-3536,,10.1109/ACCESS.2024.3484409,https://doi.org/10.1109/ACCESS.2024.3484409,IEEE
Toward Trustworthy AI: Blockchain-Based Architecture Design for Accountability and Fairness of Federated Learning Systems,Sin Kit Lo; Yue Liu; Qinghua Lu; Chen Wang; Xiwei Xu; Hye-Young Paik; Liming Zhu; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9686048/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9686048,"Federated learning is an emerging privacy-preserving AI technique where clients (i.e., organizations or devices) train models locally and formulate a global model based on the local model updates without transferring local data externally. However, federated learning systems struggle to achieve trustworthiness and embody responsible AI principles. In particular, federated learning systems face accountability and fairness challenges due to multistakeholder involvement and heterogeneity in client data distribution. To enhance the accountability and fairness of federated learning systems, we present a blockchain-based trustworthy federated learning architecture. We first design a smart contract-based data-model provenance registry to enable accountability. Additionally, we propose a weighted fair data sampler algorithm to enhance fairness in training data. We evaluate the proposed approach using a COVID-19 X-ray detection use case. The evaluation results show that the approach is feasible to enable accountability and improve fairness. The proposed algorithm can achieve better performance than the default federated learning setting in terms of the model’s generalization and accuracy.",IEEE Internet of Things Journal,19 January 2022,3276 - 3284,,,10.1109/JIOT.2022.3144450,https://doi.org/10.1109/JIOT.2022.3144450,IEEE
Investigation of a Web-Based Explainable AI Screening for Prolonged Grief Disorder,Wan Jou She; Chee Siang Ang; Robert A. Neimeyer; Laurie A. Burke; Yihong Zhang; Adam Jatowt; Yukiko Kawai; Jun Hu; Matthias Rauterberg; Holly G. Prigerson; Panote Siriaraya; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9745031/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9745031,"Losing a loved one through death is known to be one of the most challenging life events. To help the bereaved and their therapists monitor and better understand the factors that contribute to Prolonged Grief Disorder (PGD), we co-designed and studied a web-based explainable AI screening system named “Grief Inquiries Following Tragedy (GIFT).” We used an initial iteration of the system to collect PGD-related data from 611 participants. Using this data, we developed a model that could be used to screen and explain the different factors contributing to PGD. Our results showed that a Random Forest model using Bereavement risk and outcome features performed best in detecting PGD (AUC=0.772), with features such as a negative intepretation of grief and the ability to integrate stressful life events contributing strongly to the model. Afterwards, five grief experts were asked to provide feedback on a mock-up of the results generated by the GIFT model, and discuss the potential value of the explanatory AI model in real-world PGD care. Overall, the grief experts were generally receptive towards using such a tool in a clinical setting and acknowledged the benefit of offering a personalized result to the users based on the explainable AI model. Our results also showed that, in addition to the explainability of the model, the grief experts also preferred a more “empathetic” and “actionable” AI system, especially, when designing for patient end-users.",IEEE Access,30 March 2022,41164 - 41185,2169-3536,,10.1109/ACCESS.2022.3163311,https://doi.org/10.1109/ACCESS.2022.3163311,IEEE
The Challenge of Zero Touch and Explainable AI,,https://ieeexplore.ieee.org/document/10255474/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10255474,"With ever increasing complexity and dynamicity in digital service provider networks, especially with the emergence of 5G, operators seek more automation to reduce the cost of operations, time to service and revenue of new and innovative services, and increase the efficiency of resource utilization, Complex algorithms leveraging ML (machine learning) are introduced, often with the need for frequent training as the networks evolve. Inference is then applied either in the core directly, or in the management stack to trigger actions and configuration changes automatically. This is the essence of Zero Touch. The challenge that analysts are often faced with is to trace back from the inference or prediction to the original events or symptoms that led to the triggered action, which ML model version or pipeline was used. This paper describes the challenges faced by analysts and provides some solutions.",Journal of ICT Standardization,2021,147 - 158,,,10.13052/jicts2245-800X.925,https://doi.org/10.13052/jicts2245-800X.925,River Publishers
Rapid and Reliable Adaptation of Video Game AI,Sander Bakkes; Pieter Spronck; Jaap van den Herik; ; ; ,https://ieeexplore.ieee.org/document/5191044/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5191044,"Current approaches to adaptive game AI typically require numerous trials to learn effective behavior (i.e., game adaptation is not rapid). In addition, game developers are concerned that applying adaptive game AI may result in uncontrollable and unpredictable behavior (i.e., game adaptation is not reliable). These characteristics hamper the incorporation of adaptive game AI in commercially available video games. In this paper, we discuss an alternative to these current approaches. Our alternative approach to adaptive game AI has as its goal adapting rapidly and reliably to game circumstances. Our approach can be classified in the area of case-based adaptive game AI. In the approach, domain knowledge required to adapt to game circumstances is gathered automatically by the game AI, and is exploited immediately (i.e., without trials and without resource-intensive learning) to evoke effective behavior in a controlled manner in online play. We performed experiments that test case-based adaptive game AI on three different maps in a commercial real-time strategy (RTS) game. From our results, we may conclude that case-based adaptive game AI provides a strong basis for effectively adapting game AI in video games.",IEEE Transactions on Computational Intelligence and AI in Games,04 August 2009,93 - 104,,,10.1109/TCIAIG.2009.2029084,https://doi.org/10.1109/TCIAIG.2009.2029084,IEEE
A Survey and Perspective on Industrial Cyber-Physical Systems (ICPS): From ICPS to AI-Augmented ICPS,Jiyeong Chae; Sanghoon Lee; Junhyung Jang; Seohyung Hong; Kyung-Joon Park; ; ; ; ; ,https://ieeexplore.ieee.org/document/10285426/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10285426,"Digital Transformation integrates information technology across a broad spectrum of industrial sectors. Industrial Cyber-Physical Systems (ICPS) play a vital role in this transformation by harmonizing machinery, production, logistics, and societal needs through innovative information technologies. This article investigates the adoption of industrial artificial intelligence (industrial AI) as a methodology for effective ICPS design, introducing AI-Augmented ICPS (AICPS). The study conducts a survey, focusing on the components and interactions of AICPS. We propose design considerations for the implementation of AICPS and investigate the application of cutting-edge industrial AI techniques in each interaction. From the standpoint of AI augmentation, this article offers insights by identifying key perspectives, including uncertainty of information, safety of AI, explainability of AI, human-societal interactive ICPS, and standardization of industrial AI. This article aims to enhance understanding of AICPS and lay the groundwork for integrating independent industrial AI techniques into ICPS.",IEEE Transactions on Industrial Cyber-Physical Systems,13 October 2023,257 - 272,2832-7004,,10.1109/TICPS.2023.3323600,https://doi.org/10.1109/TICPS.2023.3323600,IEEE
Empowering SMEs “Harnessing the Potential of Gen AI for Resilience and Competitiveness”,Elias G. Carayannis; Roman Dumitrescu; Tommy Falkowski; Nikos-Rigert Zota; ; ; ; ,https://ieeexplore.ieee.org/document/10670531/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10670531,"This study investigates how generative artificial intelligence (Gen AI) can enhance the resilience and competitiveness of small and medium enterprises (SMEs). The central question addressed is: How can SMEs leverage Gen AI to navigate challenges and capitalize on opportunities in an evolving digital landscape? We argue that Gen AI offers transformative potential for SMEs by automating processes, enhancing decision-making and fostering innovation, thereby improving their ability to adapt and thrive amidst market uncertainties. Through a comprehensive analysis of SMEs and Gen AI, this article underscores the importance of strategic AI integration, addresses the associated challenges, and provides policy recommendations to support SMEs in harnessing AI for sustainable growth. By exploring real-world examples and theoretical insights, we aim to equip SMEs with the directions, actions, and strategies necessary to succeed in the Gen AI era.",IEEE Transactions on Engineering Management,10 September 2024,14754 - 14774,,,10.1109/TEM.2024.3456820,https://doi.org/10.1109/TEM.2024.3456820,IEEE
Three Challenges to Secure AI Systems in the Context of AI Regulations,Ronan Hamon; Henrik Junklewitz; Josep Soler Garrido; Ignacio Sanchez; ; ; ; ,https://ieeexplore.ieee.org/document/10506836/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10506836,"This article examines the interplay between artificial intelligence (AI) and cybersecurity in light of future regulatory requirements on the security of AI systems, specifically focusing on the robustness of high-risk AI systems against cyberattacks in the context of the European Union’s AI Act. The paper identifies and analyses three challenges to achieve compliance of AI systems with the cybersecurity requirement: accounting for the diversity and the complexity of AI technologies, assessing AI-specific risks, and developing secure-by-design AI systems. The contribution of the article consists in providing an overview of AI cybersecurity practices and identifying gaps in current approaches to security conformity assessment for AI systems. Our analysis highlights the unique vulnerabilities present in AI systems and the absence of established cybersecurity practices tailored to these systems, and emphasises the need for continuous alignment between legal requirements and technological capabilities, acknowledging the necessity for further research and development to address the challenges. It concludes that comprehensive cybersecurity practices must evolve to accommodate the unique aspects of AI, with a collaborative effort from various sectors to ensure effective implementation and standardisation.",IEEE Access,22 April 2024,61022 - 61035,2169-3536,,10.1109/ACCESS.2024.3391021,https://doi.org/10.1109/ACCESS.2024.3391021,IEEE
Unleashing the Potential of Conversational AI: Amplifying Chat-GPT’s Capabilities and Tackling Technical Hurdles,Vikas Hassija; Arjab Chakrabarti; Anushka Singh; Vinay Chamola; Biplab Sikdar; ; ; ; ; ,https://ieeexplore.ieee.org/document/10343095/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10343095,"Conversational AI has seen a growing interest among government, researchers, and industrialists. This comprehensive survey paper provides an in-depth analysis of large language models, specifically focusing on ChatGPT. This paper discusses the architecture, training process, and challenges associated with large language models, including bias, interpretability, and ethics. It explores various applications of ChatGPT and examines future research trends, such as improving model generalization, addressing data scarcity, and integrating multimodal capabilities. This survey also serves as a roadmap for researchers, practitioners, and policymakers, offering valuable insights into the current state and future potential of large language models and ChatGPT.",IEEE Access,05 December 2023,143657 - 143682,2169-3536,,10.1109/ACCESS.2023.3339553,https://doi.org/10.1109/ACCESS.2023.3339553,IEEE
Explainable AI for Human-Centric Ethical IoT Systems,Nancy Ambritta P.; Parikshit N. Mahalle; Rajkumar V. Patil; Nilanjan Dey; Rubén González Crespo; R. Simon Sherratt; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10335691/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10335691,"The current era witnesses the notable transition of society from an information-centric to a human-centric one aiming at striking a balance between economic advancements and upholding the societal and fundamental needs of humanity. It is undeniable that the Internet of Things (IoT) and artificial intelligence (AI) are the key players in realizing a human-centric society. However, for society and individuals to benefit from advanced technology, it is important to gain the trust of human users by guaranteeing the inclusion of ethical aspects such as safety, privacy, nondiscrimination, and legality of the system. Incorporating explainable AI (XAI) into the system to establish explainability and transparency supports the development of trust among stakeholders, including the developers of the system. This article presents the general class of vulnerabilities that affect IoT systems and directs the readers’ attention toward intrusion detection systems (IDSs). The existing state-of-the-art IDS system is discussed. An attack model modeling the possible attacks is presented. Furthermore, since our focus is on providing explanations for the IDS predictions, we first present a consolidated study of the commonly used explanation methods along with their advantages and disadvantages. We then present a high-level human-inclusive XAI framework for the IoT that presents the participating components and roles. We also hint upon a few approaches to upholding safety and privacy using XAI that we will be taking up in our future work. An attack model based on the study of possible attacks on the system is also presented in the article. The article also presents guidelines to choose a suitable XAI method and a taxonomy of explanation evaluation mechanisms, which is an important yet less visited aspect of explainable AI.",IEEE Transactions on Computational Social Systems,30 November 2023,3407 - 3419,,,10.1109/TCSS.2023.3330738,https://doi.org/10.1109/TCSS.2023.3330738,IEEE
Accelerating Innovation With Generative AI: AI-Augmented Digital Prototyping and Innovation Methods,Volker Bilgram; Felix Laarmann; ; ,https://ieeexplore.ieee.org/document/10115412/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10115412,"Easy-to-use generative artificial intelligence (AI) is democratizing the use of AI in innovation management and may significantly change the way how we work and innovate. In this article, we show how large language models (LLMs), such as generative pretrained transformer (GPT), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. Drawing on six months of experimenting with LLMs in internal and client innovation projects, we share first-hand experiences and concrete examples of AI-assisted approaches. The article highlights a large variety of use cases for generative AI ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role LLMs may play in future knowledge management systems. Moreover, we argue that generative AI may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. Our experiences also provide insights into how human innovation teams purposively and effectively interact with AIs and integrate them into their workflows.",IEEE Engineering Management Review,04 May 2023,18 - 25,,,10.1109/EMR.2023.3272799,https://doi.org/10.1109/EMR.2023.3272799,IEEE
AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers,Arif Ali Khan; Muhammad Azeem Akbar; Mahdi Fahmideh; Peng Liang; Muhammad Waseem; Aakash Ahmad; Mahmood Niazi; Pekka Abrahamsson; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10066257/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10066257,"Artificial intelligence (AI) solutions and technologies are being increasingly adopted in smart systems contexts; however, such technologies are concerned with ethical uncertainties. Various guidelines, principles, and regulatory frameworks are designed to ensure that AI technologies adhere to ethical well-being. However, the implications of AI ethics principles and guidelines are still being debated. To further explore the significance of AI ethics principles and relevant challenges, we conducted a survey of 99 randomly selected representative AI practitioners and lawmakers (e.g., AI engineers and lawyers) from 20 countries across five continents. To the best of our knowledge, this is the first empirical study that unveils the perceptions of two different types of population (AI practitioners and lawmakers) and the study findings confirm that transparency, accountability, and privacy are the most critical AI ethics principles. On the other hand, lack of ethical knowledge, no legal frameworks, and lacking monitoring bodies are found to be the most common AI ethics challenges. The impact analysis of the challenges across principles reveals that conflict in practice is a highly severe challenge. Moreover, the perceptions of practitioners and lawmakers are statistically correlated with significant differences for particular principles (e.g. fairness and freedom) and challenges (e.g. lacking monitoring bodies and machine distortion). Our findings stimulate further research, particularly empowering existing capability maturity models to support ethics-aware AI systems’ development and quality assessment.",IEEE Transactions on Computational Social Systems,10 March 2023,2971 - 2984,,,10.1109/TCSS.2023.3251729,https://doi.org/10.1109/TCSS.2023.3251729,IEEE
Dynamic Selection of Reliance Calibration Cues With AI Reliance Model,Yosuke Fukuchi; Seiji Yamada; ; ,https://ieeexplore.ieee.org/document/10343151/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10343151,"Understanding what an AI system can and cannot do is necessary for end-users to use the AI properly without being over- or under-reliant on it. Reliance calibration cues (RCCs) communicate an AI’s capability to users, resulting in optimizing their reliance on it. Previous studies have typically focused on continuously presenting RCCs, and although providing an excessive amount of RCCs is sometimes problematic, limited consideration has been given to the question of how an AI can selectively provide RCCs. This paper proposes vPred-RC, an algorithm in which an AI decides whether to provide an RCC and which RCC to provide. It evaluates the influence of an RCC on user reliance with a cognitive model that predicts whether a human will assign a task to an AI agent with or without an RCC. We tested vPred-RC in a human-AI collaborative task called the collaborative CAPTCHA (CC) task. First, our reliance prediction model was trained on a dataset of human task assignments for the CC task and found to achieve 83.5% accuracy. We further evaluated vPred-RC’s dynamic RCC selection in a user study. As a result, the RCCs selected by vPred-RC enabled participants to more accurately assign tasks to an AI when and only when the AI succeeded compared with randomly selected ones, suggesting that vPred-RC can successfully calibrate human reliance with a reduced number of RCCs. The selective presentation of RCCs has the potential to enhance the efficiency of collaboration between humans and AIs with fewer communication costs.",IEEE Access,05 December 2023,138870 - 138881,2169-3536,,10.1109/ACCESS.2023.3339548,https://doi.org/10.1109/ACCESS.2023.3339548,IEEE
XAI-LCS: Explainable AI-Based Fault Diagnosis of Low-Cost Sensors,Aparna Sinha; Debanjan Das; ; ,https://ieeexplore.ieee.org/document/10306254/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10306254,"An accurate technique for early detection of sensor faults proves useful in the uninterrupted supply of correct monitoring data across the Internet of Things (IoT) network. Most of the existing AI-based fault diagnosis techniques have a high computational burden, and their “black-box” nature creates challenges in generating adequate trust in high-risk industrial applications. To address the existing drawbacks, a unique IoT-based method, i.e., XAI-LCS, has been proposed that uses eXtreme gradient boosting algorithm for detecting different types of sensor faults, such as bias, drift, complete failure (CF), and precision degradation. This method is also capable of handling imbalanced data distribution to prevent biased predictions. The fault detection method identifies four types of sensor faults with 99.8% validation accuracy. The explainable AI interprets the prediction outcome and increases the trustworthiness of the used AI model.",IEEE Sensors Letters,03 November 2023,,2475-1472,,10.1109/LSENS.2023.3330046,https://doi.org/10.1109/LSENS.2023.3330046,IEEE
At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence,Abdulkadir Celik; Ahmed M. Eltawil; ; ,https://ieeexplore.ieee.org/document/10422716/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10422716,"As we transition from the 5G epoch, a new horizon beckons with the advent of 6G, seeking a profound fusion with novel communication paradigms and emerging technological trends, bringing once-futuristic visions to life along with added technical intricacies. Although analytical models lay the foundations and offer systematic insights, we have recently witnessed a noticeable surge in research suggesting machine learning (ML) and artificial intelligence (AI) can efficiently deal with complex problems by complementing or replacing model-based approaches. The majority of data-driven wireless research leans heavily on discriminative AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI (GenAI) pertains to generative models (GMs) capable of discerning the underlying data distribution, patterns, and features of the input data. This makes GenAI a crucial asset in wireless domain wherein real-world data is often scarce, incomplete, costly to acquire, and hard to model or comprehend. With these appealing attributes, GenAI can replace or supplement DAI methods in various capacities. Accordingly, this combined tutorial-survey paper commences with preliminaries of 6G and wireless intelligence by outlining candidate 6G applications and services, presenting a taxonomy of state-of-the-art DAI models, exemplifying prominent DAI use cases, and elucidating the multifaceted ways through which GenAI enhances DAI. Subsequently, we present a tutorial on GMs by spotlighting seminal examples such as generative adversarial networks, variational autoencoders, flow-based GMs, diffusion-based GMs, generative transformers, large language models, autoregressive GMs, to name a few. Contrary to the prevailing belief that GenAI is a nascent trend, our exhaustive review of approximately 120 technical papers demonstrates the scope of research across core wireless research areas, including 1) physical layer design; 2) network optimization, organization, and management; 3) networ...",IEEE Open Journal of the Communications Society,05 February 2024,2433 - 2489,2644-125X,,10.1109/OJCOMS.2024.3362271,https://doi.org/10.1109/OJCOMS.2024.3362271,IEEE
Empirical Assessment of AI-Powered Tools for Vocabulary Acquisition in EFL Instruction,Yiyun Wang; Jin Wu; Fang Chen; Zhu Wang; Jingjing Li; Liping Wang; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10639964/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10639964,"The deep integration of Artificial Intelligence (AI) is gradually becoming a key force in innovating the teaching of English as a Foreign Language (EFL). This study aims to assess the practical effects of AI technology in providing customized instructional support and learning pathways in EFL instruction. The study reveals the benefits of AI in the instruction of English vocabulary, utilizing the Apriori algorithm from association rule mining and empirical analysis from survey data of 110 second-year university students across four different majors using AI-powered language learning platforms and AI-powered mobile language learning applications (such as UNIPUS AIGC platform and iTEST, intelligent assessment mobile application). It also deduces related teaching strategies and learning models. The results indicate that the use of AI-powered language learning platforms positively impacts English vocabulary learning outcomes in EFL instruction, and the combined use of AI-powered mobile language learning applications for self-testing and in-class tests effectively enhances vocabulary learning efficiency. The findings and conclusions of this study provide valuable insights for EFL educational practice and demonstrate the potential of AI in boosting the effectiveness of language learning, offering empirical support and guidance for future educational decision-making.",IEEE Access,20 August 2024,131892 - 131905,2169-3536,,10.1109/ACCESS.2024.3446657,https://doi.org/10.1109/ACCESS.2024.3446657,IEEE
"Generative AI, Ingenuity, and Law",Joseph R. Carvalko; ,https://ieeexplore.ieee.org/document/10598190/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10598190,"This paper discusses generative pre-trained transformer technology and its intersection with forms of creativity and law. It highlights the potential of generative AI to change considerable elements of society, including modes of creative endeavors, problem-solving, employment, education, justice, medicine, and governance. The author emphasizes the need for policymakers and experts to join in regulating against the potential risks and implications of this technology. The European Commission has taken steps to address the risks of AI through the European AI Act (EIA), which categorizes AI uses based on their potential harm. The legislation aims to ensure scrutiny and control in extreme cases like autonomous weapons or medical devices. However, the author criticizes the lack of meaningful AI oversight in the United States and argues that time has come for government to step in and offer meaningful regulation given the technology’s (1) rate of diffusion (2) virtually uncountable product permutations, the purposes, extent and depths to which it is anticipated to penetrate institutional and daily life.",IEEE Transactions on Technology and Society,15 July 2024,169 - 182,2637-6415,,10.1109/TTS.2024.3413591,https://doi.org/10.1109/TTS.2024.3413591,IEEE
"The Why, What, and How of Artificial General Intelligence Chip Development",Alex P. James; ,https://ieeexplore.ieee.org/document/9390376/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9390376,"The AI chips increasingly focus on implementing neural computing at low power and cost. The intelligent sensing, automation, and edge computing applications have been the market drivers for AI chips. Increasingly, the generalisation, performance, robustness, and scalability of the AI chip solutions are compared with human-like intelligence abilities. Such a requirement to transit from application-specific to general intelligence AI chip must consider several factors. This article provides an overview of this cross-disciplinary field of study, elaborating on the generalisation of intelligence as understood in building artificial general intelligence (AGI) systems. This work presents a listing of emerging AI chip technologies, classification of edge AI implementations, and the funnel design flow for AGI chip development. Finally, the design consideration required for building an AGI chip is listed along with the methods for testing and validating it.",IEEE Transactions on Cognitive and Developmental Systems,30 March 2021,333 - 347,,,10.1109/TCDS.2021.3069871,https://doi.org/10.1109/TCDS.2021.3069871,IEEE
"Artificial Intelligence Techniques for Securing Fog Computing Environments: Trends, Challenges, and Future Directions",Deafallah Alsadie; ,https://ieeexplore.ieee.org/document/10684173/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10684173,"Fog computing, an extension of cloud computing, enhances capabilities by processing data closer to the source, thereby addressing latency and bandwidth issues inherent in traditional cloud models. However, the integration of Artificial Intelligence (AI) into fog computing introduces challenges, particularly in resource management, security, and privacy. This paper systematically reviews AI applications within fog computing environments, adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to ensure rigorous analysis. The studies were selected based on predefined inclusion criteria, including research published between 2010 and 2024 in peer-reviewed journals and conference papers, with searches conducted in databases like IEEE Xplore, ACM Digital Library, SpringerLink, and Scopus. The review identifies critical issues such as resource constraints, transparency in AI-driven security systems, and the need for adaptable AI models to address evolving security threats. In response, innovative solutions such as lightweight AI models (e.g., Pruned Neural Networks, Quantized Models, Knowledge Distillation), Explainable AI (XAI) (e.g., Model-Agnostic Methods, Feature Importance Analysis, Rule-Based Approaches), and federated learning are proposed. Additionally, a novel taxonomy is introduced, categorizing AI techniques into resource management, security enhancement, and privacy-preserving methods, offering a structured framework for researchers and practitioners. The paper concludes that effective AI integration in fog computing is essential for developing secure, efficient, and adaptable distributed systems, with significant implications for both academia and industry.",IEEE Access,19 September 2024,151598 - 151648,2169-3536,,10.1109/ACCESS.2024.3463791,https://doi.org/10.1109/ACCESS.2024.3463791,IEEE
Fuzzy Centered Explainable Network for Reinforcement Learning,Liang Ou; Yu-Chen Chang; Yu-Kai Wang; Chin-Teng Lin; ; ; ; ,https://ieeexplore.ieee.org/document/10183374/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10183374,"The explainability of reinforcement learning (RL) models has received vast amount of interest as its applications have widened. Most existing explainable RL models focus on improving the explainability of an agent's observations instead of the relationships between agent states and actions. This study presents a fuzzy centered explainable network (FCEN) for RL tasks to interpret the relationships between agent states and actions. The proposed FCEN leverages the interpretability of fuzzy neural networks to establish if–then rules and a generative model to visualize learned knowledge. Precisely, the FCEN includes if–then rules that formulate state-action mappings with human-understandable logic, such as the form “IF Input is A THEN Output is B.” In addition, these rules connect with a generative model that concretizes the states into human-understandable patterns (figures). Our experimental results obtained on 4 Atari games show that the proposed FCEN can achieve a high level of performance in RL tasks and enormously boost the explainability of RL agents both globally and locally. In other words, the FCEN maintains a high-level explanation for the agent decision logic and the possibility of low-level analysis for each given observation sample. The explainability boost does not undermine reward learning performance, humans can even enhance the agent's performance with the provided explainability.",IEEE Transactions on Fuzzy Systems,13 July 2023,203 - 213,,,10.1109/TFUZZ.2023.3295055,https://doi.org/10.1109/TFUZZ.2023.3295055,IEEE
Enhancing Interpretability in Deep Learning-Based Inversion of 2-D Ground Penetrating Radar Data: An Explainable AI (XAI) Strategy,Abhishek Kumar; Upendra K. Singh; Biswajeet Pradhan; ; ; ,https://ieeexplore.ieee.org/document/10530263/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10530263,"Recent advancements in deep learning (DL) have demonstrated potential for interpreting ground-penetrating radar (GPR) data, which is crucial for near surface geophysical investigations. However, the complexity of DL models and the challenge of interpreting their decision-making processes remain significant obstacles. This study addresses these challenges by applying explainable AI (XAI) techniques—specifically, local interpretable model-agnostic explanations (LIMEs) and gradient-weighted class activation mapping (Grad-CAM)—to elucidate the DL-based inversion process for 2-D GPR data. Our novel approach marks the first application of these XAI techniques in the context of GPR data analysis for subsurface utility mapping, revealing critical features and hierarchical feature extraction processes that drive the model’s predictions. By offering detailed insights into the model’s internal operations, this research not only enhances the interpretability of DL models in geophysical applications but also establishes a new standard for incorporating XAI in subsurface utility detection, paving the way for more accurate, reliable, and understandable DL applications in geophysical studies.",IEEE Geoscience and Remote Sensing Letters,14 May 2024,,,,10.1109/LGRS.2024.3400934,https://doi.org/10.1109/LGRS.2024.3400934,IEEE
An AI-Based Ventilation KPI Using Embedded IoT Devices,Francisco Maciá-Pérez; Iren Lorenzo-Fonseca; José-Vicente Berná-Martínez; ; ; ,https://ieeexplore.ieee.org/document/10021578/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10021578,"The air ventilation of enclosed premises has a direct impact on the occupants’ well-being. If not properly regulated, the air ventilation can originate a multitude of diseases and pathologies. The present study proposes a new KPI (ventilation KPI) adapted to Smart Cities. It is especially designed for academic environments (Smart Universities) in which community members spend a long time gathered in classrooms, seminars, laboratories, etc. The ventilation KPI (or KPIv) was designed to support decision making and is based on the estimation of the number of occupants of an enclosed space and the accumulation of existing CO2. Two AI techniques are proposed to perform these estimations, specifically, two regressive neural networks. The resulting models, together with the KPI, were implemented through the development of value-added services for the University of Alicante’s Smart University platform. The network models were designed to be embedded within the built IoT device prototypes. These prototypes are small and inexpensive. They act as intelligent sensors and are connected via a low consumption and emission network (LoRa). The case study showed that it is possible to take advantage of the preexisting services and resources of these platforms and to validate the KPIv.",IEEE Embedded Systems Letters,19 January 2023,9 - 12,,,10.1109/LES.2023.3238284,https://doi.org/10.1109/LES.2023.3238284,IEEE
Explainable AI for 6G Use Cases: Technical Aspects and Research Challenges,Shen Wang; M. Atif Qureshi; Luis Miralles-Pechuán; Thien Huynh-The; Thippa Reddy Gadekallu; Madhusanka Liyanage; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10499970/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10499970,"Around 2020, 5G began its commercialization journey, and discussions about the next-generation networks (such as 6G) emerged. Researchers predict that 6G networks will have higher bandwidth, coverage, reliability, energy efficiency, and lower latency, and will be an integrated “human-centric” network system powered by artificial intelligence (AI). This 6G network will lead to many real-time automated decisions, ranging from network resource allocation to collision avoidance for self-driving cars. However, there is a risk of losing control over decision-making due to the high-speed, data-intensive AI decision-making that may go beyond designers’ and users’ comprehension. To mitigate this risk, explainable AI (XAI) methods can be used to enhance the transparency of the black-box AI decision-making process. This paper surveys the application of XAI towards the upcoming 6G age, including 6G technologies (such as intelligent radio and zero-touch network management) and 6G use cases (such as industry 5.0). Additionally, the paper summarizes the lessons learned from recent attempts and outlines important research challenges in applying XAI for 6G use cases soon.",IEEE Open Journal of the Communications Society,16 April 2024,2490 - 2540,2644-125X,,10.1109/OJCOMS.2024.3386872,https://doi.org/10.1109/OJCOMS.2024.3386872,IEEE
Ethics of Artificial Intelligence for Cultural Heritage: Opportunities and Challenges,Simona Tiribelli; Sofia Pansoni; Emanuele Frontoni; Benedetta Giovanola; ; ; ; ,https://ieeexplore.ieee.org/document/10680564/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10680564,"Artificial Intelligence (AI) has witnessed remarkable advancements in recent years and has significantly impacted various domains, including cultural heritage. Indeed, AI technologies offer unprecedented capacities to analyze huge amounts of historical data, enabling researchers and art historians to uncover precious patterns, connections, and insights that might otherwise remain elusive. Also, the efficiency and accuracy of AI techniques play a pivotal role in many cultural heritage-related tasks, such as cataloging and organizing extensive cultural collections, streamlining the management of heritage resources for present and future generations. However, the integration of AI in cultural heritage also brings forth intricate ethical questions. These span over the issues of authenticity, subjectivity, and interpretation biases of an AI-empowered, reproduced, and/or generated artwork up to the legal concerns related to authorship. However, such issues are mostly undefined and unaddressed in the scholarship at the intersection on AI, ethics, and cultural heritage. This paper aims to pave the way to fill such a gap of context-sensitive ethical issues for AI in cultural heritage. To this aim, the paper first analyzes the main opportunities and benefits raised by AI in cultural heritage. Then, matching benchmark, agreed-upon AI ethics principles elaborated in the AI ethics scholarship in the last decade and relevant to cultural heritage, it highlights specific ethical risks that ought to be considered for the development and deployment of trustworthy AI in and for cultural heritage. Finally, areas requiring further attention and work, and actors call to intervene, are identified to facilitate next steps for ethics and governance of AI in cultural heritage.",IEEE Transactions on Technology and Society,16 September 2024,293 - 305,2637-6415,,10.1109/TTS.2024.3432407,https://doi.org/10.1109/TTS.2024.3432407,IEEE
Creating AI Characters for Fighting Games Using Genetic Programming,Giovanna Martínez-Arellano; Richard Cant; David Woods; ; ; ,https://ieeexplore.ieee.org/document/7792145/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7792145,"This paper proposes a character generation approach for the M.U.G.E.N. fighting game that can create engaging AI characters using a computationally cheap process without the intervention of the expert developer. The approach uses a genetic programming algorithm that refines randomly generated character strategies into better ones using tournament selection. The generated AI characters were tested by 27 human players and were rated according to results, perceived difficulty and how engaging the gameplay was. The main advantages of this procedure are that no prior knowledge of how to code the strategies of the AI character is needed and there is no need to interact with the internal code of the game. In addition, the procedure is capable of creating a wide diversity of players with different strategic skills, which could be potentially used as a starting point to a further adaptive process.",IEEE Transactions on Computational Intelligence and AI in Games,20 December 2016,423 - 434,,,10.1109/TCIAIG.2016.2642158,https://doi.org/10.1109/TCIAIG.2016.2642158,IEEE
"Reconfigurability, Why It Matters in AI Tasks Processing: A Survey of Reconfigurable AI Chips",Shaojun Wei; Xinhan Lin; Fengbin Tu; Yang Wang; Leibo Liu; Shouyi Yin; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9996124/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9996124,"Nowadays, artificial intelligence (AI) technologies, especially deep neural networks (DNNs), play an vital role in solving many problems in both academia and industry. In order to simultaneously meet the demand of performance, energy efficiency and flexibility in DNN processing, various reconfigurable AI chips have been proposed in the past several years. They are based on FPGA or CGRA platforms and have domain-specific reconfigurability to customize the computing units and data paths for different DNN tasks without re-produce the chips. This paper surveys typical reconfigurable AI chips from three reconfiguration hierarchies: processing element level, processing element array level, and chip level. Each reconfiguration hierarchy covers a set of important optimization techniques for DNN computation which are frequently adopted in real life. This paper lists the reconfigurable AI chip works in chronological order, discusses the hardware development process for each optimization techniques, and analyzes the necessity of reconfigurability in AI tasks processing. The trends of each reconfiguration hierarchy and insights about the cooperation of techniques from different hierarchies are also proposed.",IEEE Transactions on Circuits and Systems I: Regular Papers,21 December 2022,1228 - 1241,,,10.1109/TCSI.2022.3228860,https://doi.org/10.1109/TCSI.2022.3228860,IEEE
"Advancements in Deep Reinforcement Learning and Inverse Reinforcement Learning for Robotic Manipulation: Toward Trustworthy, Interpretable, and Explainable Artificial Intelligence",Recep Ozalp; Aysegul Ucar; Cuneyt Guzelis; ; ; ,https://ieeexplore.ieee.org/document/10493015/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10493015,"This article presents a literature review of the past five years of studies using Deep Reinforcement Learning (DRL) and Inverse Reinforcement Learning (IRL) in robotic manipulation tasks. The reviewed articles are examined in various categories, including DRL and IRL for perception, assembly, manipulation with uncertain rewards, multitasking, transfer learning, multimodal, and Human-Robot Interaction (HRI). The articles are summarized in terms of the main contributions, methods, challenges, and highlights of the latest and relevant studies using DRL and IRL for robotic manipulation. Additionally, summary tables regarding the problem and solution are presented. The literature review then focuses on the concepts of trustworthy AI, interpretable AI, and explainable AI (XAI) in the context of robotic manipulation. Moreover, this review provides a resource for future research on DRL/IRL in trustworthy robotic manipulation.",IEEE Access,05 April 2024,51840 - 51858,2169-3536,,10.1109/ACCESS.2024.3385426,https://doi.org/10.1109/ACCESS.2024.3385426,IEEE
An Interpretive Perspective: Adversarial Trojaning Attack on Neural-Architecture-Search Enabled Edge AI Systems,Ship Peng Xu; Ke Wang; Md. Rafiul Hassan; Mohammad Mehedi Hassan; Chien-Ming Chen; ; ; ; ; ,https://ieeexplore.ieee.org/document/9780600/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9780600,"In this article, we propose and analyze a group of adversarial backdoor attack methods on neural-architecture-search (NAS) enabled edge AI systems in industrial Internet of Things (IIoT) domain. NAS is a new popular way to generate scale-adaptive deep neural networks which can meet the respective requirements of cloud, edge, and terminal AI computing in IIoT domain. However, since most users in NAS-enabled edge side are not the generators of AI models, the deployed edge AI models may have some vulnerabilities such as backdoors. These might pose serious security issues in IIoT. We propose some effective policies to attack such edge AI systems and provide advice about how to defend them. The most significant attack through third-party pretrained NAS in IIoT may occur by backdoor attacks while the third party might introduce vulnerability in the training dataset. The article designs backdoor attack processes to NAS-enabled edge devices to identify NAS’s vulnerability to adversarial trojaning attacks and interpret the backdoor attacks. It shows that the existence of high impact nodes greatly weakens the robustness of the network. A malicious attacker can quickly paralyze the network by only selecting a few high impact nodes. Finally, it provides advice and possible solution on defending the adversarial backdoor attacks to NAS.",IEEE Transactions on Industrial Informatics,24 May 2022,503 - 510,,,10.1109/TII.2022.3177442,https://doi.org/10.1109/TII.2022.3177442,IEEE
Enhancing User Trust and Interpretability in AI-Driven Feature Request Detection for Mobile App Reviews: An Explainable Approach,Ishaya Gambo; Rhodes Massenon; Chia-Chen Lin; Roseline Oluwaseun Ogundokun; Saurabh Agarwal; Wooguil Pak; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10636143/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10636143,"Mobile app developers struggle to prioritize updates by identifying feature requests within user reviews. While machine learning models can assist, their complexity often hinders transparency and trust. This paper presents an explainable Artificial Intelligence (AI) approach that combines advanced explanation techniques with engaging visualizations to address this issue. Our system integrates a bidirectional Long Short-Term Memory (BiLSTM) model with attention mechanisms, enhanced by Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP). We evaluate this approach on a diverse dataset of 150,000 app reviews, achieving an F1 score of 0.82 and 89% accuracy, significantly outperforming baseline Support Vector Machine (F1: 0.66) and Convolutional Neural Network (CNN) (F1: 0.72) models. Our empirical user studies with developers demonstrate that our explainable approach improves trust (27%) when explanations are provided and correct interpretation (73%). The system’s interactive visualizations allowed developers to validate predictions, with over 80% overlap between model-highlighted phrases and human annotations for feature requests. These findings highlight the importance of integrating explainable AI into real-world software engineering workflows. The paper’s results and future directions provide a promising approach for feature request detection in app reviews to create more transparent, trustworthy, and effective AI systems.",IEEE Access,14 August 2024,114023 - 114045,2169-3536,,10.1109/ACCESS.2024.3443527,https://doi.org/10.1109/ACCESS.2024.3443527,IEEE
Activation Control of Vision Models for Sustainable AI Systems,Jonathan Burton-Barr; Basura Fernando; Deepu Rajan; ; ; ,https://ieeexplore.ieee.org/document/10459148/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10459148,"Impact Statement:
Research surrounding AI control mainly focuses on non-AI functions with control over AI functions being rare. Available works use AI control to select AI models for a user-specified AI system or to increase the accuracy of an AI system. When AI control is applied in such a fashion, it can increase energy or inference cost (Shen et al., 2023; Wu et al., 2023; Maini et al., 2022). Our article lays foundation for AI-on-AI control that reduces these costs for systems with multiple computer vision functions. SICEC evaluates an input and only activates the relevant system functions for that input. SICEC also attempts to gauge the complexity of an image and assign lower cost function-related models when possible. Results promote the viability of cost-reductive AI-on-AI control research showing significant energy and inference time reductions. SICEC like methodology could be applied to increase the long-term sustainability of various AI systems, examples being computer vision cloud, generative...",IEEE Transactions on Artificial Intelligence,05 March 2024,3470 - 3481,2691-4581,,10.1109/TAI.2024.3372935,https://doi.org/10.1109/TAI.2024.3372935,IEEE
Bridging Technology and Psychology: AI-Driven Analysis of Student’s Class Lecture Activity for Improved Learning Outcomes,M. Raihan; Anjan Debnath; Prokash Chondra Adhikary; Mehedi Masud; Hossam Meshref; Anupam Kumar Bairagi; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10706218/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10706218,"Students’ emotional state and attention significantly impact how they handle stress and interact with their studies. These factors are crucial in defining their learning objectives and general personal growth, influencing their academic achievement. Because Bangladesh has distinct educational and mental health difficulties, it is important to comprehend these dynamics. Time series analysis is a useful technique for tracking lecture activities in class and how they affect student participation since it provides insightful information about behavior patterns across time. This investigation aims to address these problems by using MotionWatch 8 and a comprehensive questionnaire to analyze class lecture activities. This study employs ensemble methodologies, deep Learning algorithms, and a diverse range of machine learning models to assess and predict student behavior. A hybrid model is one of the techniques that produced the most stunning results, proving how well it could capture complex patterns in time series data. To assess the robustness of the algorithms, the study also looked at how different datasets performed. Ultimately, the models’ interpretability was improved, and their decision-making processes were given a more profound understanding by utilizing explainable AI methods, including SHAP, LIME, and permutation importance. The effort establishes new standards for improving student engagement and well-being through data-driven insights, sophisticated models, and explainable AI.",IEEE Access,07 October 2024,147320 - 147349,2169-3536,,10.1109/ACCESS.2024.3474848,https://doi.org/10.1109/ACCESS.2024.3474848,IEEE
Enhancing Going Concern Prediction With Anchor Explainable AI and Attention-Weighted XGBoost,Putthiporn Thanathamathee; Siriporn Sawangarreerak; Dinna Nina Mohd Nizam; ; ; ,https://ieeexplore.ieee.org/document/10530315/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10530315,"In the rapidly evolving sector of financial analytics, predicting a firm’s going concern status accurately is vital for informed user decisions. This study introduces a novel method that synergizes Anchor Explainable Artificial Intelligence (XAI) with an Attention-Weighted Extreme Gradient Boosting (XGBoost) model, significantly improving the precision and clarity of going concern predictions. Traditional models often trade off explainability against complexity, diminishing user confidence. Our solution, integrating Anchor XAI, offers lucid, comprehensible explanations for the model’s predictions, enhancing trust and interpretability. The developed Attention-Weighted XGBoost algorithm, targeting essential financial indicators, markedly surpasses traditional approaches in prediction by its 98% accuracy, as evidenced by improved precision and recall. This integration not only makes the prediction process more transparent but also advances the field towards more interpretable AI solutions. Additionally, our approach highlights important features specific to each class, distinguishing our findings with significant indicators like working capital/total assets, and total equity for potential non-going concerns, debt ratio, current assets to total liabilities ratio, and long-term funds to fixed assets ratio for going concerns, alongside governance factors such as the number of independent directors and BIG4 audit status for entities with going concern doubt. These advancements demonstrate the effectiveness of melding explainable AI with attention mechanisms to bolster the trustworthiness and clarity of financial forecasts, opening new research paths in financial analytics.",IEEE Access,14 May 2024,68345 - 68363,2169-3536,,10.1109/ACCESS.2024.3401007,https://doi.org/10.1109/ACCESS.2024.3401007,IEEE
Who/What Is My Teammate? Team Composition Considerations in Human–AI Teaming,Nathan J. McNeese; Beau G. Schelble; Lorenzo Barberis Canonico; Mustafa Demir; ; ; ; ,https://ieeexplore.ieee.org/document/9474953/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9474953,"There are many unknowns regarding the characteristics and dynamics of human-AI teams, including a lack of understanding of how certain human-human teaming concepts may or may not apply to human-AI teams and how this composition affects team performance. This article outlines an experimental research study that investigates essential aspects of human-AI teaming such as team performance, team situation awareness, and perceived team cognition in various mixed composition teams (human-only, human-human-AI, human-AI-AI, and AI-only) through a simulated emergency response management scenario. Results indicate dichotomous outcomes regarding perceived team cognition and performance metrics, as perceived team cognition was not predictive of performance. Performance metrics like team situational awareness and team score showed that teams composed of all human participants performed at a lower level than mixed human-AI teams, with the AI-only teams attaining the highest performance. Perceived team cognition was highest in human-only teams, with mixed composition teams reporting perceived team cognition 58% below the all-human teams. These results inform future mixed teams of the potential performance gains in utilizing mixed teams' over human-only teams in certain applications, while also highlighting mixed teams' adverse effects on perceived team cognition.",IEEE Transactions on Human-Machine Systems,05 July 2021,288 - 299,,,10.1109/THMS.2021.3086018,https://doi.org/10.1109/THMS.2021.3086018,IEEE
Supervised Learning Achieves Human-Level Performance in MOBA Games: A Case Study of Honor of Kings,Deheng Ye; Guibin Chen; Peilin Zhao; Fuhao Qiu; Bo Yuan; Wen Zhang; Sheng Chen; Mingfei Sun; Xiaoqian Li; Siqin Li; Jing Liang; Zhenjie Lian; Bei Shi; Liang Wang; Tengfei Shi; Qiang Fu; Wei Yang; Lanxiao Huang; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9248616/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9248616,"We present JueWu-SL, the first supervised-learning-based artificial intelligence (AI) program that achieves human-level performance in playing multiplayer online battle arena (MOBA) games. Unlike prior attempts, we integrate the macro-strategy and the micromanagement of MOBA-game-playing into neural networks in a supervised and end-to-end manner. Tested on Honor of Kings, the most popular MOBA at present, our AI performs competitively at the level of High King players in standard 5v5 games.",IEEE Transactions on Neural Networks and Learning Systems,04 November 2020,908 - 918,,33147150,10.1109/TNNLS.2020.3029475,https://doi.org/10.1109/TNNLS.2020.3029475,IEEE
"A Systematic Literature Review on AI Safety: Identifying Trends, Challenges, and Future Directions",Wissam Salhab; Darine Ameyed; Fehmi Jaafar; Hamid Mcheick; ; ; ; ,https://ieeexplore.ieee.org/document/10630784/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10630784,"Artificial intelligence (AI) is revolutionizing many aspects of our lives, except it raises fundamental safety and ethical issues. In this survey paper, we review the current state of research on safe and trustworthy AI. This work provides a structured and systematic overview of AI safety. In which, we emphasize the significance of designing AI systems with safety focus, encompassing elements from data management, model development, and deployment. We underscore the need for AI systems to align with human values and operate within mounted ethical frameworks. In addition, we notice the need for a complete safety framework that courses the development and implementation of AI systems, ensuring they do not inadvertently cause damage to humans. Our results show that AI safety is associated with model learning techniques, verification and validation methods, failure modes, and managing AI autonomy. As discussed in the literature, the main concerns include explainability, interpretability, robustness, reliability, fairness, bias, and adversarial attacks.",IEEE Access,08 August 2024,131762 - 131784,2169-3536,,10.1109/ACCESS.2024.3440647,https://doi.org/10.1109/ACCESS.2024.3440647,IEEE
Test and Yield Loss Reduction of AI and Deep Learning Accelerators,Mehdi Sadi; Ujjwal Guin; ; ,https://ieeexplore.ieee.org/document/9324766/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9324766,"With data-driven analytics becoming mainstream, the global demand for dedicated artificial intelligence (AI) and deep learning accelerator chips is soaring. These accelerators, designed with densely packed processing elements (PE), are especially vulnerable to the manufacturing defects and functional faults common in the advanced semiconductor process nodes resulting in significant yield loss. In this work, we demonstrate an application-driven methodology of binning the AI accelerator chips, and yield loss reduction by correlating the circuit faults in the PEs of the accelerator with the desired accuracy of the target AI workload. We exploit the inherent fault tolerance features of trained deep learning models and a strategy of selective deactivation of faulty PEs to develop the presented yield loss reduction and test methodology. An analytical relationship is derived between fault location, fault rate, and the AI task’s accuracy for deciding if the accelerator chip can pass the final yield test. A yield-loss reduction-aware fault isolation, ATPG, and test flow are presented for the multiply and accumulate units of the PEs. Results obtained with widely used AI/deep learning benchmarks demonstrate that the accelerators can sustain 5% fault rate in PE arrays while suffering from less than 1% accuracy loss, thus enabling product binning and yield loss reduction of these chips.",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,14 January 2021,104 - 115,,,10.1109/TCAD.2021.3051841,https://doi.org/10.1109/TCAD.2021.3051841,IEEE
Creating Pro-Level AI for a Real-Time Fighting Game Using Deep Reinforcement Learning,Inseok Oh; Seungeun Rho; Sangbin Moon; Seongho Son; Hyoil Lee; Jinyun Chung; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9314886/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9314886,"Reinforcement learning (RL) combined with deep neural networks has performed remarkably well in many genres of games recently. It has surpassed human-level performance in fixed game environments and turn-based two-player board games. However, to the best of our knowledge, current research has yet to produce a result that has surpassed human-level performance in modern complex fighting games. This is due to the inherent difficulties with real-time fighting games, including: vast action spaces, action dependencies, and imperfect information. We overcame these challenges and made 1v1 battle AI agents for the commercial game Blade and Soul . The trained agents competed against five professional gamers and achieved a winning rate of 62%. This article presents a practical RL method that includes a novel self-play curriculum and data skipping techniques. Through the curriculum, three different styles of agents were created by reward shaping and were trained against each other. Additionally, this article suggests data-skipping techniques that could increase data efficiency and facilitate explorations in vast spaces. Since our method can be generally applied to all two-player competitive games with vast action spaces, we anticipate its application to game development including level design and automated balancing.",IEEE Transactions on Games,06 January 2021,212 - 220,,,10.1109/TG.2021.3049539,https://doi.org/10.1109/TG.2021.3049539,IEEE
TextFocus: Assessing the Faithfulness of Feature Attribution Methods Explanations in Natural Language Processing,Ettore Mariotti; Anna Arias-Duart; Michele Cafagna; Albert Gatt; Dario Garcia-Gasulla; Jose Maria Alonso-Moral; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10543008/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10543008,"Among the existing eXplainable AI (XAI) approaches, Feature Attribution methods are a popular option due to their interpretable nature. However, each method leads to a different solution, thus introducing uncertainty regarding their reliability and coherence with respect to the underlying model. This work introduces TextFocus, a metric for evaluating the faithfulness of Feature Attribution methods for Natural Language Processing (NLP) tasks involving classification. To address the absence of ground truth explanations for such methods, we introduce the concept of textual mosaics. A mosaic is composed of a combination of sentences belonging to different classes, which provides an implicit ground truth for attribution. The accuracy of explanations can be then evaluated by comparing feature attribution scores with the known class labels in the mosaic. The performance of six feature attribution methods is systematically compared on three sentence classification tasks by using TextFocus, with Integrated Gradients being the best overall method in terms of faithfulness and computational requirements. The proposed methodology fills a gap in NLP evaluation, by providing an objective way to assess Feature Attribution methods while finding their optimal parameters.",IEEE Access,31 May 2024,138870 - 138880,2169-3536,,10.1109/ACCESS.2024.3408062,https://doi.org/10.1109/ACCESS.2024.3408062,IEEE
Explainable AI for Enhanced Interpretation of Liver Cirrhosis Biomarkers,Greeshma Arya; Ashish Bagwari; Hiteshi Saini; Prachi Thakur; Ciro Rodriguez; Pedro Lezama; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10305150/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10305150,"Liver cirrhosis is a terminal pathological result of chronic liver damage, illicit drugs, hepatotoxicity, and non-alcoholic steatohepatitis. Assessment of liver cirrhosis via non-invasive methods in order to circumvent the limitations of liver biopsy. This research builds upon the growing body of knowledge in liver cirrhosis assessment by examining a dataset comprising cases of primary biliary cirrhosis. Prior research has primarily concentrated on comparative analyses and development of machine learning models integrating imaging modalities such as ultrasound, magnetic resonance imaging (MRI), and elastography, with limited focus on serum biomarkers. This research endeavors to address the neglected aspects of liver cirrhosis assessment by leveraging Explainable AI algorithm to bridge the gap between AI models and human comprehension via providing insights into the intricate decision-making process of the proposed machine learning model, thus enhancing transparency and trustworthiness. This novel approach aims to overcome the limitations of previous works and contribute to improved liver cirrhosis diagnosis.",IEEE Access,02 November 2023,123729 - 123741,2169-3536,,10.1109/ACCESS.2023.3329759,https://doi.org/10.1109/ACCESS.2023.3329759,IEEE
Edge TMS: Optimized Real-Time Temperature Monitoring Systems Deployed on Edge AI Devices,Henar Mike O. Canilang; Angela C. Caliwag; James Rigor C. Camacho; Wansu Lim; Martin Maier; ; ; ; ; ,https://ieeexplore.ieee.org/document/10173681/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10173681,"The temperature monitoring system (TMS) aims to reduce the infection spread and outbreak of COVID-19 through early detection. Conventional and currently deployed TMS have high implementation cost and require a substantial amount of space. Also, the performance often depends on the accuracy of the thermal camera. To address this, we propose Edge TMS wherein a multitask cascaded convolutional neural networks (MTCNNs)-based TMS is deployed on an edge AI device. To overcome the resource constraints of edge AI devices, an optimization method is applied to compress MTCNN up to
100×
. The compressed MTCNN is deployed on the local PC, Jetson Xavier, Jetson TX2, and Jetson Nano which yields pruning-per-reduction ratio (PPRR) values of 1.21, 1.63, 1.99, and 2.10, respectively. We proposed the PPRR metric to measure the performance of the compressed model. Low PPRR values indicate an improvement in the hardware performance and computational efficiency of the optimized model. The optimized model deployed in all the Jetson series achieved an average percent power reduced (%R) of 53.18% with a percent difference of 35.9% from the results of the local PC.",IEEE Internet of Things Journal,05 July 2023,2490 - 2506,,,10.1109/JIOT.2023.3292744,https://doi.org/10.1109/JIOT.2023.3292744,IEEE
Transparency and Privacy: The Role of Explainable AI and Federated Learning in Financial Fraud Detection,Tomisin Awosika; Raj Mani Shukla; Bernardi Pranggono; ; ; ,https://ieeexplore.ieee.org/document/10509682/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10509682,"Fraudulent transactions and how to detect them remain a significant problem for financial institutions around the world. The need for advanced fraud detection systems to safeguard assets and maintain customer trust is paramount for financial institutions, but some factors make the development of effective and efficient fraud detection systems a challenge. One of such factors is the fact that fraudulent transactions are rare and that many transaction datasets are imbalanced; that is, there are fewer significant samples of fraudulent transactions than legitimate ones. This data imbalance can affect the performance or reliability of the fraud detection model. Moreover, due to the data privacy laws that all financial institutions are subject to follow, sharing customer data to facilitate a higher-performing centralized model is impossible. Furthermore, the fraud detection technique should be transparent so that it does not affect the user experience. Hence, this research introduces a novel approach using Federated Learning (FL) and Explainable AI (XAI) to address these challenges. FL enables financial institutions to collaboratively train a model to detect fraudulent transactions without directly sharing customer data, thereby preserving data privacy and confidentiality. Meanwhile, the integration of XAI ensures that the predictions made by the model can be understood and interpreted by human experts, adding a layer of transparency and trust to the system. Experimental results, based on realistic transaction datasets, reveal that the FL-based fraud detection system consistently demonstrates high performance metrics. This study grounds FL’s potential as an effective and privacy-preserving tool in the fight against fraud.",IEEE Access,29 April 2024,64551 - 64560,2169-3536,,10.1109/ACCESS.2024.3394528,https://doi.org/10.1109/ACCESS.2024.3394528,IEEE
Explainable AI and Robustness-Based Test and Evaluation of Reinforcement Learning,Ali K. Raz; Kshitij Mall; Sean Matthew Nolan; Winston Levin; Linas Mockus; Kris Ezra; Ahmad Mia; Kyle Williams; Julie Parish; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10534821/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10534821,"Reinforcement learning is a powerful and proven approach to generating near-optimal decision policies across domains, although characterizing performance boundaries, explaining decisions, and quantifying output uncertainties are major barriers to widespread adoption of reinforcement learning for real-time use. This is particularly true for high-risk and safety-critical aerospace systems where the cost of failure is high and performance envelopes for systems of interest may be small. To address these issues, this article presents a three-part test and evaluation framework for reinforcement learning, which is purpose-built from a systems engineering perspective on artificial intelligence. This framework employs explainable AI techniques—namely, Shapley additive explanations—to examine opaque decision-making, introduces robustness testing to characterize performance bounds and sensitivities, and incorporates output validation against accepted solutions. In this article, we consider an example problem of a high-speed aerospace vehicle emergency descent problem where a reinforcement learning agent is trained to control vehicle angle of attack (AoA). Shapley additive explanations expose the most significant features that impact the selection of AoA command while robustness testing characterizes the acceptable range of disturbances in flight parameters the trained vehicle can accommodate. Finally, the outputs from the reinforcement learning agent are compared with a baseline optimal trajectory as an acceptance criterion of RL solutions.",IEEE Transactions on Aerospace and Electronic Systems,20 May 2024,6110 - 6123,,,10.1109/TAES.2024.3403078,https://doi.org/10.1109/TAES.2024.3403078,IEEE
Fast and Efficient Lung Abnormality Identification With Explainable AI: A Comprehensive Framework for Chest CT Scan and X-Ray Images,Md. Zahid Hasan; Sidratul Montaha; Inam Ullah Khan; Md. Mehedi Hassan; Abdullah Al Mahmud; A. K. M. Rakibul Haque Rafid; Sami Azam; Asif Karim; Spyridon Prountzos; Efthymia Alexopoulou; Umama Binta Ashraf; Sheikh Mohammed Shariful Islam; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10445174/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10445174,"A novel automated multi-classification approach is proposed for the anticipation of lung abnormalities using chest X-ray and CT images. The study leverages a publicly accessible dataset with an insufficient and unbalanced number of images, addressing this issue by employing the data augmentation approach DCGAN to balance the dataset. Various preprocessing procedures are applied to improve features and reduce noise in lung pictures. As the base for the model, the vision trans-former and convolution-based compact convolutional transformer (CCT) model is utilized. To determine the best model configuration, an ablation study is performed on the original CCT model using a CT scan dataset with image dimensions of
32×32
. Following that, this model is trained on the X-ray dataset to evaluate performance on an entirely other modality. The performances are compared to six pre-trained models with
32×32
images. While traditional models achieved modest performance, with test accuracies ranging from 43% to 77% and 49% to 73% requiring lengthy training times, the suggested model performed exceptionally well, obtaining test accuracies of 99.77% and 95.37% for CT and X-ray, respectively with a short training duration of 10–12 and 40–42 seconds/epoch. Robustness is demonstrated through the progressive reduction of the number of training images, with findings indicating that the model maintains good performance even on a reduced dataset. An explainable AI technique Grad-CAM is used to explain the model’s judgment. Grad-CAM-based color visualization is shown to explain model assessments and help health specialists make quick, confident decisions. This study used image preprocessing and deep learning techniques to detect lung anomalies, and it addressed the challenges of training time and computational complexity.",IEEE Access,26 February 2024,31117 - 31135,2169-3536,,10.1109/ACCESS.2024.3369900,https://doi.org/10.1109/ACCESS.2024.3369900,IEEE
"Explainable AI (XAI) for Constructing a Lexicon for Classifying Green Energy Jobs: A Comparative Analysis of Occupation, Industry, and Location Composition With Traditional Energy Jobs",Haohui Chen; Claire M. Mason; ; ,https://ieeexplore.ieee.org/document/10601610/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10601610,"Growing concerns about climate change and environmental sustainability demand a shift from traditional to green energy. Insight into the different workforce profiles of green and traditional energy supply chains is critical to manage impacts to workers in traditional energy occupations and to identify what skills and occupations are needed in green energy jobs. The role and skills descriptions captured in big datasets of online job ads have the potential to deliver these insights but considerable time and effort is required to train algorithms to differentiate job ads pertaining to traditional and green energy occupations. In addition, algorithms usually need to be developed for each dataset of interest whereas lexicon-based approaches can be adapted relatively easily. In this study, we illustrate the use of explainable AI techniques (in combination with a set of initial keywords) to build a lexicon that can be used to identify (with 82% precision rate) traditional and green energy job ads across the supply chain (from energy production to energy policy, regulation and sales). Our study demonstrates the XAI-enhanced lexicon’s efficacy in uncovering differences in the industry, occupation, and geographic profile of traditional and green energy job ads. The findings provide valuable insights into the distributional consequences of the green energy transition by revealing where careful management of this transition is most needed whilst also illustrating the potential for XAI to support the development of precise and comprehensive lexicons.",IEEE Access,18 July 2024,142709 - 142720,2169-3536,,10.1109/ACCESS.2024.3430317,https://doi.org/10.1109/ACCESS.2024.3430317,IEEE
FireDetXplainer: Decoding Wildfire Detection With Transparency and Explainable AI Insights,Syeda Fiza Rubab; Arslan Abdul Ghaffar; Gyu Sang Choi; ; ; ,https://ieeexplore.ieee.org/document/10486908/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10486908,"Recent analyses by leading national wildfire and emergency monitoring agencies have highlighted an alarming trend: the impact of wildfire devastation has escalated to nearly three times that of a decade ago. To address this challenge, we propose FireDetXplainer (FDX), a robust deep-learning model that enhances the interpretability often lacking in current solutions. FDX employs an innovative approach, combining transfer learning and fine-tuning methodologies with the Learning without Forgetting (LwF) framework. A key aspect of our methodology is the utilization of the pre-trained MobileNetV3 model, renowned for its efficiency in image classification tasks. Through strategic adaptation and augmentation, we have achieved an exceptional classification accuracy of 99.91%. The model is further refined with convolutional blocks and advanced image pre-processing techniques, contributing to this high level of precision. Leveraging diverse datasets from Kaggle and Mendeley, FireDetXplainer incorporates Explainable AI (XAI) tools such as Gradient Weighted Class Activation Map (Grad-CAM) and Local Interpretable Model-Agnostic Explanations (LIME) for comprehensive result interpretation. Our extensive experimental results demonstrate that FireDetXplainer not only outperforms existing state-of-the-art models but does so with remarkable accuracy, making it a highly effective solution for interpretable image classification in wildfire management.",IEEE Access,01 April 2024,52378 - 52389,2169-3536,,10.1109/ACCESS.2024.3383653,https://doi.org/10.1109/ACCESS.2024.3383653,IEEE
Performance Comparison and Visualization of AI-Generated-Image Detection Methods,Daeeol Park; Hyunsik Na; Daeseon Choi; ; ; ,https://ieeexplore.ieee.org/document/10508937/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10508937,"Recent advancements in artificial intelligence (AI) have revolutionized the field of image generation. This has concurrently escalated social problems and concerns related to AI image generation, underscoring the necessity for an effective AI-generated-image detection method. Therefore, numerous methods for detecting AI-generated images have been developed, but there remains a need for research comparing the effectiveness of and visualizing these detection methods. In this study, we classify AI-generated-image detection methods by the image features they use and compare their generalization performance in detecting AI-generated images of different types. We selected five AI-generated-image detection methods for performance evaluation and selected vision transformer as an additional method for comparison. We use two types of training datasets, i.e., ProGAN and latent diffusion; combine existing AI-generated-image test datasets into a diverse test dataset; and divide them into three types of generative models, i.e., generative adversarial network (GAN), diffusion, and transformer, to evaluate the comprehensive performance of the detection methods. We also analyze their detection performance on images with data augmentation, considering scenarios that make it difficult to detect AI-generated images. Grad-CAM and t-SNE are used to visualize the detection area and data distribution of each detection method. As a result, we determine that artifact-feature-based detection performs well on GAN and real images, whereas image-encoder-feature-based detection performs well on diffusion and transformer images. In summary, our research analyzes the comparative detection performance of various AI-generated-image detection methods, identifies their limitations, and suggests directions for further research.",IEEE Access,26 April 2024,62609 - 62627,2169-3536,,10.1109/ACCESS.2024.3394250,https://doi.org/10.1109/ACCESS.2024.3394250,IEEE
Problems With SHAP and LIME in Interpretable AI for Education: A Comparative Study of Post-Hoc Explanations and Neural-Symbolic Rule Extraction,Danial Hooshyar; Yeongwook Yang; ; ,https://ieeexplore.ieee.org/document/10684198/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10684198,"Given that education is classified as a ‘high-risk’ domain under regulatory frameworks like the EU AI Act, ensuring accurate and trustworthy interpretability in educational AI applications is critical due to its profound impact on student learning and development. This study compares a knowledge-based artificial neural network (KBANN) with a conventional artificial neural network (ANN) in the context of educational predictive modeling, focusing on generalizability, interpretability, and the fidelity of post-hoc explanations. While both models demonstrate comparable predictive performance, KBANN uniquely integrates structured educational knowledge, aligning more closely with essential educational principles and causal relationships. Post-hoc explanation methods, such as Kernel SHAP, Permutation SHAP, and LIME, were applied to the ANN to interpret its decision-making process, revealing significant variability in the assessment of feature importance. Through simulations based on the extracted rules from KBANN, we further examined the fidelity and reliability of these methods. Our findings, from global feature importance and correlation analyses, showed that post-hoc methods often fail to accurately reflect the structured knowledge learned by the model, misattributing importance to less relevant features. This misalignment and the resultant discrepancies in feature interpretation raise concerns about the reliability of these explanations, suggesting they may not always provide a trustworthy or accurate basis for understanding the predictive models. Finally, KBANN’s rule extraction achieved significantly lower computation times compared to post-hoc methods, highlighting its practical efficiency. These findings collectively underscore the limitations of post-hoc explanation methods in conveying the true reasons behind model predictions, urging caution among stakeholders and researchers when using these methods for interpretability in AI for education.",IEEE Access,19 September 2024,137472 - 137490,2169-3536,,10.1109/ACCESS.2024.3463948,https://doi.org/10.1109/ACCESS.2024.3463948,IEEE
Mobility AI Agents and Networks,Haoxuan Ma; Yifan Liu; Qinhua Jiang; Brian Yueshuai He; Xishun Liao; Jiaqi Ma; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10664547/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10664547,"Intelligent vehicles and smart mobility systems are at the forefront of transportation evolution, yet effective management of these new mobility technologies and services are non-trivial. This perspective presents an Intelligent Mobility System Digital Twin (MSDT) framework as a solution. Our framework uniquely maps human beings and vehicles to AI agents, and the mobility systems to AI networks, creating realistic digital simulacra of the physical mobility system. By integrating AI agents and AI networks, this framework offers unprecedented capabilities in prediction and automated simulation of the entire mobility systems, thereby improving planning, operations, and decision-making in smart cities.",IEEE Transactions on Intelligent Vehicles,04 September 2024,5124 - 5129,,,10.1109/TIV.2024.3454285,https://doi.org/10.1109/TIV.2024.3454285,IEEE
How to Regulate Large Language Models for Responsible AI,J. Berengueres; ,https://ieeexplore.ieee.org/document/10536000/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10536000,"Large Language Models (LLMs) are predictive probabilistic models capable of passing several professional tests at a level comparable to humans. However, these capabilities come with ethical concerns. Ethical oversights in several LLM-based products include: (i) a lack of content or source attribution, and (ii) a lack of transparency in what was used to train the model. This paper identifies four touchpoints where ethical safeguards can be applied to realize a more responsible AI in LLMs. The key finding is that applying safeguards before the training occurs aligns with established engineering practices of addressing issues at the source. However, this approach is currently shunned. Finally, historical parallels are drawn with the U.S. automobile industry, which initially resisted safety regulations but later embraced them once consumer attitudes evolved.",IEEE Transactions on Technology and Society,21 May 2024,191 - 197,2637-6415,,10.1109/TTS.2024.3403681,https://doi.org/10.1109/TTS.2024.3403681,IEEE
GenNI: Human-AI Collaboration for Data-Backed Text Generation,Hendrik Strobelt; Jambay Kinley; Robert Krueger; Johanna Beyer; Hanspeter Pfister; Alexander M. Rush; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9552430/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9552430,"Table2Text systems generate textual output based on structured data utilizing machine learning. These systems are essential for fluent natural language interfaces in tools such as virtual assistants; however, left to generate freely these ML systems often produce misleading or unexpected outputs. GenNI (Generation Negotiation Interface) is an interactive visual system for high-level human-AI collaboration in producing descriptive text. The tool utilizes a deep learning model designed with explicit control states. These controls allow users to globally constrain model generations, without sacrificing the representation power of the deep learning models. The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable. We report multiple use cases on two experiments that improve over uncontrolled generation approaches, while at the same time providing fine-grained control. A demo and source code are available at https://genni.vizhub.ai.",IEEE Transactions on Visualization and Computer Graphics,29 September 2021,1106 - 1116,,34587072,10.1109/TVCG.2021.3114845,https://doi.org/10.1109/TVCG.2021.3114845,IEEE
Leveraging Human-AI Collaboration in Crowd-Powered Source Search: A Preliminary Study,,https://ieeexplore.ieee.org/document/10241351/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10241351,"Source search is an important problem in our society, relating to finding fire sources, gas sources, or signal sources. Particularly, in an unexplored and potentially dangerous environment, an autonomous source search algorithm that employs robotic searchers is usually applied to address the problem. Such environments could be completely unknown and highly complex. Therefore, novel search algorithms have been designed, combining heuristic methods and intelligent optimization, to tackle search problems in large and complex search spaces. However, these intelligent search algorithms were not designed to address completeness and optimality, and therefore commonly suffer from the problems such as local optimums or endless loops. Recent studies have used crowd-powered systems to address the complex problems that cannot be solved by machines on their own. While leveraging human intelligence in an AI system has been shown to be effective in making the system more reliable, whether using the power of the crowd can improve autonomous source search algorithms remains unanswered. To this end, we propose a crowd-powered source search approach enabling human-AI collaboration, which uses human intelligence as external supports to improve existing search algorithms and meanwhile reduces human efforts using AI predictions. Furthermore, we designed a crowd-powered prototype system and carried out an experiment with both experts and non-experts, to complete 200 source search scenarios (704 crowdsourcing tasks). Quantitative and qualitative analysis showed that the sourcing search algorithm enhanced by crowd could achieve both high effectiveness and efficiency. Our work provides valuable insights in human-AI collaborative system design.",Journal of Social Computing,June 2023,95 - 111,2688-5255,,10.23919/JSC.2023.0002,https://doi.org/10.23919/JSC.2023.0002,TUP
Likelihood of Questioning AI-Based Recommendations Due to Perceived Racial/Gender Bias,Carlos M. Parra; Manjul Gupta; Denis Dennehy; ; ; ,https://ieeexplore.ieee.org/document/9576526/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9576526,"Advances in artificial intelligence (AI) are giving rise to a multitude of AI-embedded technologies that are increasingly impacting all aspects of modern society. Yet, there is a paucity of rigorous research that advances understanding of when, and which type of, individuals are more likely to question AI-based recommendations due to perceived racial and gender bias. This study, which is part of a larger research stream contributes to knowledge by using a scenario-based survey that was issued to a sample of 387 U.S. participants. The findings suggest that considering perceived racial and gender bias, human resource (HR) recruitment and financial product/service procurement scenarios exhibit a higher questioning likelihood. Meanwhile, the healthcare scenario presents the lowest questioning likelihood. Furthermore, in the context of this study, U.S. participants tend to be more susceptible to questioning AI-based recommendations due to perceived racial bias rather than gender bias.",IEEE Transactions on Technology and Society,15 October 2021,41 - 45,2637-6415,,10.1109/TTS.2021.3120303,https://doi.org/10.1109/TTS.2021.3120303,IEEE
CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,Jordan J. Bird; Ahmad Lotfi; ; ,https://ieeexplore.ieee.org/document/10409290/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10409290,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot distinguish the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.",IEEE Access,19 January 2024,15642 - 15650,2169-3536,,10.1109/ACCESS.2024.3356122,https://doi.org/10.1109/ACCESS.2024.3356122,IEEE
Towards Explainable AI for Channel Estimation in Wireless Communications,Abdul Karim Gizzini; Yahia Medjahdi; Ali J. Ghandour; Laurent Clavier; ; ; ; ,https://ieeexplore.ieee.org/document/10368353/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10368353,"Research into 6G networks has been initiated to support a variety of critical artificial intelligence (AI) assisted applications such as autonomous driving. In such applications, AI-based decisions should be performed in a real-time manner. These decisions include resource allocation, localization, channel estimation, etc. Considering the black-box nature of existing AI-based models, it is highly challenging to understand and trust the decision-making behavior of such models. Therefore, explaining the logic behind those models through explainable AI (XAI) techniques is essential for their employment in critical applications. This manuscript proposes a novel XAI-based channel estimation (XAI-CHEST) scheme that provides detailed reasonable interpretability of the deep learning (DL) models that are employed in doubly-selective channel estimation. The aim of the proposed XAI-CHEST scheme is to identify the relevant model inputs by inducing high noise on the irrelevant ones. As a result, the behavior of the studied DL-based channel estimators can be further analyzed and evaluated based on the generated interpretations. Simulation results show that the proposed XAI-CHEST scheme provides valid interpretations of the DL-based channel estimators for different scenarios.",IEEE Transactions on Vehicular Technology,21 December 2023,7389 - 7394,,,10.1109/TVT.2023.3345632,https://doi.org/10.1109/TVT.2023.3345632,IEEE
AI World Cup: Robot-Soccer-Based Competitions,Chansol Hong; Inbae Jeong; Luiz Felipe Vecchietti; Dongsoo Har; Jong-Hwan Kim; ; ; ; ; ,https://ieeexplore.ieee.org/document/9376289/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9376289,"Games have been used as excellent testbeds for research on artificial intelligence (AI) and computational intelligence for their diversity and complexity. In this article, we present AI World Cup, a set of AI competitions based on the game of soccer. We provide an introduction to the three challenges that concern a robot soccer match using both value-based and image-based state representations. AI Soccer runs the robot soccer match by participants managing each team of five two-wheeled robots. AI Commentator and AI Reporter observe the AI Soccer match and output real-time commentary and a summary article, respectively. Also, we introduce the AI World Cup platform along with rationale behind notable design choices. The official international AI World Cups held in 2018 and 2019 and the AI Masters competition held in 2019 as a part of the World Cyber Games are briefly discussed. Technical aspects of the strategies developed by participants are also discussed.",IEEE Transactions on Games,11 March 2021,330 - 341,,,10.1109/TG.2021.3065410,https://doi.org/10.1109/TG.2021.3065410,IEEE
Effective and Diverse Adaptive Game AI,IstvÁn Szita; Marc Ponsen; Pieter Spronck; ; ; ,https://ieeexplore.ieee.org/document/4804734/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4804734,"Adaptive techniques tend to converge to a single optimum. For adaptive game AI, such convergence is often undesirable, as repetitive game AI is considered to be uninteresting for players. In this paper, we propose a method for automatically learning diverse but effective macros that can be used as components of adaptive game AI scripts. Macros are learned by a cross-entropy method (CEM). This is a selection-based optimization method that, in our experiments, maximizes an interestingness measure. We demonstrate the approach in a computer role-playing game (CRPG) simulation with two duelling wizards, one of which is controlled by an adaptive game AI technique called “dynamic scripting.” Our results show that the macros that we learned manage to increase both adaptivity and diversity of the scripts generated by dynamic scripting, while retaining playing strength.",IEEE Transactions on Computational Intelligence and AI in Games,24 March 2009,16 - 27,,,10.1109/TCIAIG.2009.2018706,https://doi.org/10.1109/TCIAIG.2009.2018706,IEEE
"AI-assisted superresolution cosmological simulations – II. Halo substructures, velocities, and higher order statistics",,https://ieeexplore.ieee.org/document/9584091/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9584091,"In this work, we expand and test the capabilities of our recently developed superresolution (SR) model to generate high-resolution (HR) realizations of the full phase-space matter distribution, including both displacement and velocity, from computationally cheap low-resolution (LR) cosmological N-body simulations. The SR model enhances the simulation resolution by generating 512 times more tracer particles, extending into the deeply nonlinear regime where complex structure formation processes take place. We validate the SR model by deploying the model in 10 test simulations of box size 100 h −1  Mpc, and examine the matter power spectra, bispectra, and two-dimensional power spectra in redshift space. We find the generated SR field matches the true HR result at per cent level down to scales of k ∼ 10 h  Mpc −1 . We also identify and inspect dark matter haloes and their substructures. Our SR model generates visually authentic small-scale structures that cannot be resolved by the LR input, and are in good statistical agreement with the real HR results. The SR model performs satisfactorily on the halo occupation distribution, halo correlations in both real and redshift space, and the pairwise velocity distribution, matching the HR results with comparable scatter, thus demonstrating its potential in making mock halo catalogues. The SR technique can be a powerful and promising tool for modelling small-scale galaxy formation physics in large cosmological volumes.",Monthly Notices of the Royal Astronomical Society,July 2021,1021 - 1033,,,10.1093/mnras/stab2113,https://doi.org/10.1093/mnras/stab2113,OUP
Wireless Capsule Endoscopy Image Classification: An Explainable AI Approach,Dara Varam; Rohan Mitra; Meriam Mkadmi; Radi Aman Riyas; Diaa Addeen Abuhani; Salam Dhou; Ayman Alzaatreh; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10262261/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10262261,"Deep Learning has contributed significantly to the advances made in the fields of Medical Imaging and Computer Aided Diagnosis (CAD). Although a variety of Deep Learning (DL) models exist for the purposes of image classification in the medical domain, more analysis needs to be conducted on their decision-making processes. For this reason, several novel Explainable AI (XAI) techniques have been proposed in recent years to better understand DL models. Currently, medical professionals rely on visual inspections to diagnose potential diseases in endoscopic imaging in the preliminary stages. However, we believe that the use of automated systems can enhance both the efficiency for such diagnoses. The aim of this study is to increase the reliability of model predictions within the field of endoscopic imaging by implementing several transfer learning models on a balanced subset of Kvasir-capsule, a Wireless Capsule Endoscopy imaging dataset. This subset includes the top 9 classes of the dataset for training and testing. The results obtained were an F1-score of 97% ±1% for the Vision Transformer model, although other models such as MobileNetv3Large and ResNet152v2 were also able to achieve F1-scores of over 90%. These are currently the highest-reported metrics on this data, improving upon prior studies done on the same dataset. The heatmaps of several XAI techniques, including GradCAM, GradCAM++, LayersCAM, LIME, and SHAP have been presented in image form and evaluated according to their highlighted regions of importance. This is in an effort to better understand the decisions of the top-performing DL models and look beyond their black-box nature.",IEEE Access,25 September 2023,105262 - 105280,2169-3536,,10.1109/ACCESS.2023.3319068,https://doi.org/10.1109/ACCESS.2023.3319068,IEEE
Toward Transparent Load Disaggregation—A Framework for Quantitative Evaluation of Explainability Using Explainable AI,Djordje Batic; Vladimir Stankovic; Lina Stankovic; ; ; ,https://ieeexplore.ieee.org/document/10198359/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10198359,"Load Disaggregation, or Non-intrusive Load Monitoring (NILM), refers to the process of estimating energy consumption of individual domestic appliances from aggregated household consumption. Recently, Deep Learning (DL) approaches have seen increased adoption in NILM community. However, DL NILM models are often treated as black-box algorithms, which introduces algorithmic transparency and explainability concerns, hindering wider adoption. Recent works have investigated explainability of DL NILM, however they are limited to computationally expensive methods or simple classification problems. In this work, we present a methodology for explainability of regression-based DL NILM with visual explanations, using explainable AI (XAI). Two explainability levels are provided. Sequence-level explanations highlight important features of predicted time-series sequence of interest, while point-level explanations enable visualising explanations at a point in time. To facilitate wider adoption of XAI, we define desirable properties of NILM explanations - faithfulness, robustness and effective complexity. Addressing the limitation of existing XAI NILM approaches that don’t assess the quality of explanations, desirable properties of explanations are used for quantitative evaluation of explainability. We show that proposed framework enables better understanding of NILM outputs and helps improve design by providing a visualization strategy and rigorous evaluation of quality of XAI methods, leading to transparency of outcomes.",IEEE Transactions on Consumer Electronics,01 August 2023,4345 - 4356,,,10.1109/TCE.2023.3300530,https://doi.org/10.1109/TCE.2023.3300530,IEEE
Secure Explainable-AI Approach for Brake Faults Prediction in Heavy Transport,Muhammad Ahmad Khan; Maqbool Khan; Hussain Dawood; Hassan Dawood; Ali Daud; ; ; ; ; ,https://ieeexplore.ieee.org/document/10638039/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10638039,"Ensuring the safety of vehicles requires the critical responsibility of diagnosing and correcting brake faults. Implementing this proactive measure to address brake faults not only ensures the protection of lives but also enhances the efficiency and cost-effectiveness of repair processes conducted on-site. Machine learning technology has recently contributed to a significant rise in the popularity of predictive maintenance. The objective of this study is to provide a method for identifying issues with the air pressure system (APS) of air brake systems in heavy-duty vehicles. The data obtained by sensors has been used to analyse the APS failure in this Scania Truck. After examining numerous classification methods, Random Forest was determined to have the greatest performance, with a classification accuracy of 99.4%. Moreover, the implementation of eXplainable Artificial Intelligence has included the use of SHapley Additive exPlanation (SHAP) and Local Interpretable Model-agnostic Explanations (LIME) to provide explanations for the contributions of features in model predictions. We picked 20 features from the wheel speed sensor data received from several Internet of Things (IoTs) sensors, which significantly influenced our final selection. By repeatedly applying random forest to these 20 features, we achieved the same degree of accuracy as previously. Consequently, our suggested approach used a reduced amount of computer resources and was less intricate to execute in terms of calculation.",IEEE Access,16 August 2024,114940 - 114950,2169-3536,,10.1109/ACCESS.2024.3444907,https://doi.org/10.1109/ACCESS.2024.3444907,IEEE
Computational Intelligence and AI in Games: A New IEEE Transactions,Simon M. Lucas; ,https://ieeexplore.ieee.org/document/4907351/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4907351,"The author first provides an overview of computational intelligence and AI in games. Then he describes the new IEEE Transactions, which will publish archival quality original papers in all aspects of computational intelligence and AI related to all types of games. To name some examples, these include computer and video games, board games, card games, mathematical games, games that model economies or societies, serious games with educational and training applications, and games involving physical objects such as robot football and robotic car racing. Emphasis will also be placed on the use of these methods to improve performance in, and understanding of, the dynamics of games, as well as gaining insight into the properties of the methods as applied to games. It will also include using games as a platform for building intelligent embedded agents for real-world applications. The journal builds on a scientific community that has already been active in recent years with the development of new conference series such as the IEEE Symposium on Computational Intelligence in Games (CIG) and Artificial Intelligence and Interactive Digital Entertainment (AIIDE), as well as special issues on games in journals such as the IEEE Transactions on Evolutionary Computation. When setting up the journal, a decision was made to include both artificial intelligence (AI) and computational intelligence (CI) in the title. AI seeks to simulate intelligent behavior in any way that can be programmed effectively. Some see the field of AI as being all-inclusive, while others argue that there is nothing artificial about real intelligence as exhibited by higher mammals.",IEEE Transactions on Computational Intelligence and AI in Games,02 May 2009,1 - 3,,,10.1109/TCIAIG.2009.2021433,https://doi.org/10.1109/TCIAIG.2009.2021433,IEEE
Towards Human-Centered Explainable AI: A Survey of User Studies for Model Explanations,Yao Rong; Tobias Leemann; Thai-Trang Nguyen; Lisa Fiedler; Peizhu Qian; Vaibhav Unhelkar; Tina Seidel; Gjergji Kasneci; Enkelejda Kasneci; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10316181/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10316181,"Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how human-computer interaction (HCI) and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97 core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability , and human-AI collaboration performance . Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI.",IEEE Transactions on Pattern Analysis and Machine Intelligence,13 November 2023,2104 - 2122,,37956008,10.1109/TPAMI.2023.3331846,https://doi.org/10.1109/TPAMI.2023.3331846,IEEE
On the Intersection of Explainable and Reliable AI for Physical Fatigue Prediction,Sara Narteni; Vanessa Orani; Enrico Cambiaso; Matteo Rucco; Maurizio Mongelli; ; ; ; ; ,https://ieeexplore.ieee.org/document/9831436/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9831436,"In the era of Industry 4.0, the use of Artificial Intelligence (AI) is widespread in occupational settings. Since dealing with human safety, explainability and trustworthiness of AI are even more important than achieving high accuracy. eXplainable AI (XAI) is investigated in this paper to detect physical fatigue during manual material handling task simulation. Besides comparing global rule-based XAI models (LLM and DT) to black-box models (NN, SVM, XGBoost) in terms of performance, we also compare global models with local ones (LIME over XGBoost). Surprisingly, global and local approaches achieve similar conclusions, in terms of feature importance. Moreover, an expansion from local rules to global rules is designed for Anchors, by posing an appropriate optimization method (Anchors coverage is enlarged from an original low value, 11%, up to 43%). As far as trustworthiness is concerned, rule sensitivity analysis drives the identification of optimized regions in the feature space, where physical fatigue is predicted with zero statistical error. The discovery of such “non-fatigue regions” helps certifying the organizational and clinical decision making.",IEEE Access,18 July 2022,76243 - 76260,2169-3536,,10.1109/ACCESS.2022.3191907,https://doi.org/10.1109/ACCESS.2022.3191907,IEEE
Designing Hybrid Human–AI Orchestration Tools for Individual and Collaborative Activities: A Technology Probe Study,Vanessa Echeverria; Kexin Yang; LuEttaMae Lawrence; Nikol Rummel; Vincent Aleven; ; ; ; ; ,https://ieeexplore.ieee.org/document/10050813/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10050813,"Combining individual and collaborative learning is common, but dynamic combinations (which happen as-the-need arises, rather than in preplanned ways, and may happen on an individual basis) are rare. This work reports findings from a technology probe study exploring alternative designs for classroom co-orchestration support for dynamically transitioning between individual and collaborative learning. The study involved 1) a technology-probe classroom study in an authentic, AI-supported classroom to understand teachers' and students' needs for co-orchestration support over dynamic transitions; and 2) workshops and interviews with students and teachers to get informed feedback about their lived experiences. About 118 students and 3 teachers from a middle school in the US experienced a pairing policy—student, teacher, and AI-controlled pairing policy—(i.e., identifying students needing help and potential helpers) for switching from individual to a peer-tutoring activity. This work aims to answer the following questions: 1) How did students and teachers react to these pairing policies? and 2) What are students' and teachers' desires for sharing control over the orchestration of dynamic transitions? Findings suggest the need for a form of hybrid control between students, teachers, and AI systems over transitions, as well as for adaptivity and adaptability for different classroom characteristics, teachers, and students' prior knowledge.",IEEE Transactions on Learning Technologies,23 February 2023,191 - 205,,,10.1109/TLT.2023.3248155,https://doi.org/10.1109/TLT.2023.3248155,IEEE
LCNN: Lightweight CNN Architecture for Software Defect Feature Identification Using Explainable AI,Momotaz Begum; Mehedi Hasan Shuvo; Mostofa Kamal Nasir; Amran Hossain; Mohammad Jakir Hossain; Imran Ashraf; Jia Uddin; Md. Abdus Samad; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10499820/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10499820,"Software defect identification (SDI) is a key part of improving the quality of software projects and lowering the risks that along with maintenance. It does identify the software defect causes that have not been reached yet to get sufficient results. On the other hand, many researchers have recently developed several models, including NN, ML, DL, advanced CNN, and LSTM, to enhance the effectiveness of defect prediction. Due to an insufficient dataset size, repeated investigations, and no longer appropriate baseline selection, the research on the CNN model was unable to produce reliable results. In addition, XAI a well-known explainability approach creates deep models in computer vision, as well as successfully handles the software defect prediction that is easy for humans to understand. To address these issues, firstly we have used SMOTE for preprocessing which was collected from the NASA repository; categorical and numerical data. Secondly, we have experimented with software defect prediction using 1D-CNN and 2D-CNN named lightweight CNN (LCNN). Subsequently, evaluation we have employed a 100-repetition holdout validation. For the cross-validation setup, we utilized the 1D-CNN model was
20×1
, and for the 2D-CNN model, it was
4×5×1
. After that, the results of the experiment were compared and assessed in terms of accuracy, MSE, and AUC. The result shows that 2D-CNN shows 1.36% better contrast with 1D-CNN. Thirdly, we have conducted research on the identification of software defect features via LIME and SHAP in XAI stand as state-of-the-art techniques. However, we cannot use 2D-CNN because it involves more complex relationships, making it challenging to create transparent explanations. That is why we have realized that 1D-CNN will superior result to explain the root cause of software feature identifications. Finally, LIME provides accurate visualization of software defect features in contrast with SHAP, as well as it helps the stakeholde...",IEEE Access,16 April 2024,55744 - 55756,2169-3536,,10.1109/ACCESS.2024.3388489,https://doi.org/10.1109/ACCESS.2024.3388489,IEEE
Advanced Techniques for Biometric Authentication: Leveraging Deep Learning and Explainable AI,Smita Khairnar; Shilpa Gite; Kashish Mahajan; Biswajeet Pradhan; Abdullah Alamri; Sudeep D. Thepade; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10723309/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10723309,"Liveness face detection is essential for modern biometric systems, ensuring that input data is genuine and not derived from a false image or video. Liveness face detection in today’s biometric systems will ensure that input comes from a real, live person rather than a manipulated image or video. The novelty of this study lies in combining deep learning models with local interpretable model-agnostic interpretation (LIME) to enhance the interpretability and transparency of facial liveness detection systems. This technology is necessary for preventing spoofing attacks and attempts by hackers to break the security feature via pictures, videos, masks, etc. Spoofing refers to the compromise of a biometric system by providing it with untruthful material, photographs, videos, or masks to gain access. However, if not dealt with, such forms of fraud could affect the security of the biometrics. Liveness detection relies on several strategies, from basic facial actions like blinking and head twists to even more advanced algorithms that can identify natural skin texture and warmth or detect differences at the pixel level between live and static images. Robust liveness detection in biometric authentication significantly enhances security and reliability. The objective of this research is to test the different pre-trained models to detect spoofing attacks and to use LIME to explain the model’s predictions. This paper focuses on a dataset of Spoof in Wild with Multiple Attacks Version 2 (SiWMv2), comprising 14 different spoofing techniques, ranging from replay attacks and makeup disguises with paper glasses to more complex ones. Seven pre-trained architectures, VGG16, DenseNet201, InceptionV3, VGG19, ResNet50, MobileNetV2, and Xception, are fine-tuned with the potential for actual automatic liveness identification in facial images. Deep learning approaches achieve superior detection performance against contemporary spoofing techniques. These techniques aim to enhance the interpreta...",IEEE Access,21 October 2024,153580 - 153595,2169-3536,,10.1109/ACCESS.2024.3474690,https://doi.org/10.1109/ACCESS.2024.3474690,IEEE
Visualizing and Comparing Machine Learning Predictions to Improve Human-AI Teaming on the Example of Cell Lineage,Jiayi Hong; Ross Maciejewski; Alain Trubuil; Tobias Isenberg; ; ; ; ,https://ieeexplore.ieee.org/document/10239303/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10239303,"We visualize the predictions of multiple machine learning models to help biologists as they interactively make decisions about cell lineage —the development of a (plant) embryo from a single ovum cell . Based on a confocal microscopy dataset, traditionally biologists manually constructed the cell lineage, starting from this observation and reasoning backward in time to establish their inheritance. To speed up this tedious process, we make use of machine learning (ML) models trained on a database of manually established cell lineages to assist the biologist in cell assignment. Most biologists, however, are not familiar with ML, nor is it clear to them which model best predicts the embryo's development. We thus have developed a visualization system that is designed to support biologists in exploring and comparing ML models, checking the model predictions, detecting possible ML model mistakes, and deciding on the most likely embryo development. To evaluate our proposed system, we deployed our interface with six biologists in an observational study. Our results show that the visual representations of machine learning are easily understandable, and our tool, LineageD+, could potentially increase biologists’ working efficiency and enhance the understanding of embryos.",IEEE Transactions on Visualization and Computer Graphics,04 September 2023,1956 - 1969,,37665712,10.1109/TVCG.2023.3302308,https://doi.org/10.1109/TVCG.2023.3302308,IEEE
Counterfactual Explanation of AI Models Using an Adaptive Genetic Algorithm With Embedded Feature Weights,Ebtisam AlJalaud; Manar Hosny; ; ,https://ieeexplore.ieee.org/document/10536083/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10536083,"Explainable Artificial Intelligence (XAI) is a cutting-edge AI development motivated by the need for transparency of black-box models in AI systems. This transparency enhances user trust, facilitates accountability, and enables a better understanding of AI systems decisions, especially in critical applications where insights into decision processes are essential. These benefits have increased XAI research interest, aiming to provide techniques for interpreting and understanding the behavior of intelligent models. Counterfactual explanation is a popular technique for model interpretation based on updating a few features such that the outcome of an AI model is changed. Users can gain insights into the critical features or factors influencing the AI system’s decision by analyzing these counterfactuals. However, most counterfactual techniques require more qualifications, such as simplicity, robustness, and coherence. In this research, we propose a novel approach, Adaptive Feature Weight Genetic Explanation (AFWGE), for generating counterfactual explanations of AI models, where a custom genetic algorithm (GA) is employed, incorporating adaptive feature weights to enhance the algorithm’s performance. Experimental results on four benchmark datasets show that AFWGE allows for the adaptation of feature weights during the evolutionary process, producing more effective counterfactual explanations with superior proximity, sparsity, plausibility, and actionability. Furthermore, it emphasizes feature weights as reliable indicators of the significance of the model’s features, providing valuable insights for interpreting the model. AFWGE not only advances the field of counterfactual explanation generation but also establishes a robust framework for assessing feature importance in machine learning models.",IEEE Access,22 May 2024,74993 - 75009,2169-3536,,10.1109/ACCESS.2024.3404043,https://doi.org/10.1109/ACCESS.2024.3404043,IEEE
Explaining Technology We Do Not Understand,Greg Adamson; ,https://ieeexplore.ieee.org/document/10032112/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10032112,"Since 2016 a significant program of work has been initiated by the U.S. Defense Advanced Research Projects Agency (DARPA) under the title of explainable artificial intelligence (XAI). This program is seen as important for AI adoption, in this case to include the needs of warfighters to effectively collaborate with AI “partners.” Technology adoption is often promoted based on beliefs, which bears little relationship to the benefit a technology will provide. These beliefs include “progress,” technology superiority, and technology as cornucopia. The XAI program has widely promoted a new belief: that AI is in general explainable. As AI systems often have concealed or black box characteristics, the problem of explainability is significant. This paper argues that due to their complexity, AI systems should be approached in a way similar to the way the scientific method is used to approach natural phenomena. One approach encouraged by DARPA, model induction, is based on post-hoc reasoning. Such inductive reasoning is consistent with the scientific method. However, that method has a history of controls that are applied to create confidence in an uncertain, inductive, outcome. The paper proposes some controls consistent with a philosophical examination of black boxes. As AI systems are being used to determine who should have access to scarce resources and who should be punished and in what way, the claim that AI can be explained is important. Widespread recent experimentation with ChatGPT has also highlighted the challenges and expectations of AI systems.",IEEE Transactions on Technology and Society,30 January 2023,34 - 45,2637-6415,,10.1109/TTS.2023.3240107,https://doi.org/10.1109/TTS.2023.3240107,IEEE
Z-Inspection®: A Process to Assess Trustworthy AI,Roberto V. Zicari; John Brodersen; James Brusseau; Boris Düdder; Timo Eichhorn; Todor Ivanov; Georgios Kararigas; Pedro Kringen; Melissa McCullough; Florian Möslein; Naveed Mushtaq; Gemma Roig; Norman Stürtz; Karsten Tolle; Jesmin Jahan Tithi; Irmhild van Halem; Magnus Westerlund; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9380498/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9380498,"The ethical and societal implications of artificial intelligence systems raise concerns. In this article, we outline a novel process based on applied ethics, namely, Z-Inspection ® , to assess if an AI system is trustworthy. We use the definition of trustworthy AI given by the high-level European Commission's expert group on AI. Z-Inspection ® is a general inspection process that can be applied to a variety of domains where AI systems are used, such as business, healthcare, and public sector, among many others. To the best of our knowledge, Z-Inspection ® is the first process to assess trustworthy AI in practice.",IEEE Transactions on Technology and Society,17 March 2021,83 - 97,2637-6415,,10.1109/TTS.2021.3066209,https://doi.org/10.1109/TTS.2021.3066209,IEEE
"Sketching an AI Marketplace: Tech, Economic, and Regulatory Aspects",Abhishek Kumar; Benjamin Finley; Tristan Braud; Sasu Tarkoma; Pan Hui; ; ; ; ; ,https://ieeexplore.ieee.org/document/9319656/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9319656,"Artificial intelligence shows promise for solving many practical societal problems in areas such as healthcare and transportation. However, the current mechanisms for AI model diffusion such as Github code repositories, academic project webpages, and commercial AI marketplaces have some limitations; for example, a lack of monetization methods, model traceability, and model auditabilty. In this work, we sketch guidelines for a new AI diffusion method based on a decentralized online marketplace. We consider the technical, economic, and regulatory aspects of such a marketplace including a discussion of solutions for problems in these areas. Finally, we include a comparative analysis of several current AI marketplaces that are already available or in development. We find that most of these marketplaces are centralized commercial marketplaces with relatively few models.",IEEE Access,11 January 2021,13761 - 13774,2169-3536,,10.1109/ACCESS.2021.3050929,https://doi.org/10.1109/ACCESS.2021.3050929,IEEE
How Generative AI Was Mentioned in Social Media and Academic Field? A Text Mining Based on Internet Text Data,Wenchao Zhang; Ruonan Yan; Lei Yuan; ; ; ,https://ieeexplore.ieee.org/document/10474404/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10474404,"As ChatGPT has evolved, generative AI (Artificial Intelligence) has gone viral on the internet since 2022. Heated discussions on generative AI have appeared in both social media and academic field, generating massive textual data. Overwhelming media coverage of generative AI may lead to biased conception. To date, there has been no systematic analysis of how generative AI is mentioned on the internet. Moreover, little attention has been paid to demonstrating the gap in perceptions of generative AI between social media and academic field. This study seeks to focus on the following specific research questions: What are the key terms related to generative AI, what are the key term differences in social media and academic field on generative AI, and what are the topic differences of generative AI in social media and academic field? A text-mining approach supported by KH-coder was employed. The research data were drawn from two main text sources: the Sina Weibo platform and the CNKI periodical database. The results revealed statistically significant differences in key terms and topics related to generative AI between the social media and academic field. Our findings enhance the understanding of public ideas and the trend of generative AI on the internet, and provide supportive information for future studies on generative AI applications.",IEEE Access,18 March 2024,43940 - 43947,2169-3536,,10.1109/ACCESS.2024.3379010,https://doi.org/10.1109/ACCESS.2024.3379010,IEEE
Translating Image XAI to Multivariate Time Series,Lorenzo Tronchin; Ermanno Cordelli; Lorenzo Ricciardi Celsi; Daniele Maccagnola; Massimo Natale; Paolo Soda; Rosa Sicilia; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10439172/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10439172,"As Artificial Intelligence (AI) is becoming part of our daily lives, the need to understand and trust its decisions is becoming a pressing issue. EXplainable AI (XAI) aims at answering this demand, providing tools to get insights into the models’ behaviour and reasoning. Following this trend, our research paper explores the explainability of a deployed multimodal architecture applied to a real-world dataset of multivariate time series. The study aims to enhance the trustworthiness of an AI agent responsible for crash detection in an insurance company’s automatic assistance service. By introducing an XAI layer, we provide insights into the AI agent’s decision-making process, enabling the optimization of emergency medical services allocation. The dataset consists of real-world telematics data collected from vehicles equipped with black box technology. The challenge lies in explaining the complex interactions within the multivariate time series data to accurately understand the forces applied to vehicles during accidents. To this end, we adapt to this context two state-of-the-art XAI model-specific approaches, originally designed for images. We offer a qualitative and a quantitative evaluation, also comparing with a well-known agnostic method, and further validating our findings on an external dataset. The results show that Integrated Gradients, among the methodologies examined, is the most effective approach. Its ability to handle the complexity of the data provides the most comprehensive and insightful explanations for the considered use case. The findings emphasize the potential of XAI to enhance the trustworthiness of AI systems and optimize emergency response in the insurance industry. Code is available at https://github.com/ltronchin/translating-xai-mts.git .",IEEE Access,19 February 2024,27484 - 27500,2169-3536,,10.1109/ACCESS.2024.3366994,https://doi.org/10.1109/ACCESS.2024.3366994,IEEE
Multiscale Bayesian Modeling for RTS Games: An Application to StarCraft AI,Gabriel Synnaeve; Pierre Bessière; ; ,https://ieeexplore.ieee.org/document/7293159/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7293159,"This paper showcases the use of Bayesian models for real-time strategy (RTS) games AI in three distinct core components: micromanagement (units control), tactics (army moves and positions), and strategy (economy, technology, production, army types). The strength of having end-to-end probabilistic models is that distributions on specific variables can be used to interconnect different models at different levels of abstraction. We applied this modeling to StarCraft, and evaluated each model independently. Along the way, we produced and released a comprehensive data set for RTS machine learning.",IEEE Transactions on Computational Intelligence and AI in Games,06 October 2015,338 - 350,,,10.1109/TCIAIG.2015.2487743,https://doi.org/10.1109/TCIAIG.2015.2487743,IEEE
"Recent Advances in Trustworthy Explainable Artificial Intelligence: Status, Challenges, and Perspectives",Atul Rawal; James McCoy; Danda B. Rawat; Brian M. Sadler; Robert St. Amant; ; ; ; ; ,https://ieeexplore.ieee.org/document/9645355/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9645355,"Impact Statement:
With examples of bias in the predictions/decisions made by Artificial Intelligence (AI) systems being more and more common nowadays, a new field of research called Explainable AI (XAI) has emerged in the recent years, which aims to make AI/ML systems, their behavior, and predictions more comprehensible to the end users. This paper provides a comprehensive survey of XAI, starting from its design and development to goals and how to evaluate the effectiveness of such systems, and a comparison of the methods used to achieve explainability. We highlight the importance of security for XAI systems due to the lack of studies/research available in literature and provide an insight into the recent advances towards secure XAI. This paper serves as a foundational review for XAI, its current state-of-art, challenges facing the field, and perspectives on its future.",IEEE Transactions on Artificial Intelligence,10 December 2021,852 - 866,2691-4581,,10.1109/TAI.2021.3133846,https://doi.org/10.1109/TAI.2021.3133846,IEEE
Navigating and Addressing Public Concerns in AI: Insights From Social Media Analytics and Delphi,Mehrdad Maghsoudi; Amirmahdi Mohammadi; Sajjad Habibipour; ; ; ,https://ieeexplore.ieee.org/document/10630673/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10630673,"The rapid advancement and integration of artificial intelligence (AI) in various domains of society have given rise to a complex landscape of public concerns. This research endeavors to systematically explore these concerns by employing a multi-stage methodology that combines large-scale social media data collection from Twitter and advanced text analytics. The study identifies seven distinct clusters of concerns, encompassing privacy and security, workforce displacement, existential risks, social and ethical implications, dependency on AI, misuse of AI, and lack of transparency. To further contextualize these findings, the Delphi method was employed to gather insights from AI ethics experts, providing a deeper understanding of the public’s apprehensions. The results underscore the critical need for addressing these concerns to foster public trust and acceptance of AI technologies. This comprehensive analysis offers valuable guidance for policymakers, AI developers, and stakeholders to navigate and mitigate the multifaceted issues associated with AI, ultimately contributing to more informed and responsible AI deployment. By addressing these public concerns, the study aims to pave the way for a more ethically sound and socially acceptable integration of AI into society, ensuring that the benefits of AI can be realized while minimizing potential risks and negative impacts. Through this systematic approach, the research highlights the importance of continuous monitoring and proactive management of AI-related concerns to sustain public confidence and promote beneficial AI innovation.",IEEE Access,08 August 2024,126043 - 126062,2169-3536,,10.1109/ACCESS.2024.3440660,https://doi.org/10.1109/ACCESS.2024.3440660,IEEE
AIS Data Aided Rayleigh CFAR Ship Detection Algorithm of Multiple-Target Environment in SAR Images,Jiaqiu Ai; Zhilin Pei; Baidong Yao; Zhaocheng Wang; Mengdao Xing; ; ; ; ; ,https://ieeexplore.ieee.org/document/9535229/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9535229,"This article proposes an automatic identification system (AIS) data aided Rayleigh constant false alarm rate (AIS-RCFAR) ship detection algorithm of multiple-target environment in synthetic aperture radar (SAR) images. This method aims to improve the detection performance in complex environment with the aid of AIS data. Traditional CFAR detectors generally use all the samples in the local background window for parameter estimation. However, in multiple-target environment, clutter edges and transition areas, due to the interference of the high-intensity outliers, such as target pixels, ghosts, and other interfering pixels, the parameters are often overestimated, causing degradation of the detection performance. Aiming at solving this problem, AIS-RCFAR designs an adaptive-threshold based clutter trimming method with an adaptive-trimming-depth aided by AIS data to effectively eliminate the high-intensity outliers in the local background window while greatly sustaining the real sea clutter samples. Maximum-likelihood-estimator with a closed-form solution is proposed to precisely estimate the parameters using the adaptively-trimmed clutter samples, the probability density function of the sea clutter following Rayleigh distribution can be accurately modeled. AIS-RCFAR greatly enhances the detection rate in both homogeneous and nonhomogeneous multiple-target environment, it also achieves a very low false alarm rate. In addition, the whole procedure of AIS-RCFAR is simple and efficient. Simulated data and real SAR images with corresponding matched AIS data are used for experiments to validate the superiority and feasibility of AIS-RCFAR.",IEEE Transactions on Aerospace and Electronic Systems,10 September 2021,1266 - 1282,,,10.1109/TAES.2021.3111849,https://doi.org/10.1109/TAES.2021.3111849,IEEE
"Auth-AIS: Secure, Flexible, and Backward-Compatible Authentication of Vessels AIS Broadcasts",Savio Sciancalepore; Pietro Tedeschi; Ahmed Aziz; Roberto Di Pietro; ; ; ; ,https://ieeexplore.ieee.org/document/9390297/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9390297,"Automatic Identification System (AIS) is the de-facto communication standard used by vessels to broadcast identification and position information. However, being AIS communications neither encrypted nor authenticated, they can be eavesdropped and spoofed by adversaries, leading to potentially threatening scenarios. Existing solutions, including the ones conceived in the avionics domain, do not consider integration with the AIS standard, and they do not provide protection against rogue messages flooding. In this article, we propose Auth-AIS, a secure, flexible, standard-compliant, and backward-compatible authentication framework to secure AIS broadcast messages. Auth-AIS leverages existing sound cryptographic tools, including TESLA and Bloom Filters, inheriting their security properties while contextualizing them in the AIS technology. Auth-AIS is a software-only solution, that can be seamlessly integrated into existing AIS deployments, without requiring any hardware replacement. Its innovative design also provides backward-compatibility—i.e., Auth-AIS messages can be received also by AIS users not adopting Auth-AIS, while renouncing at its security guarantees. Auth-AIS can work in either two configuration modes: Deterministic Security Configuration, able to achieve low-delay authentication with a message overhead of 75 percent, or Probabilistic Security Configuration, reducing the message overhead down to 35.71 percent, while experiencing a marginal increase in the authentication delay. All these security configurations guarantee an 80 bits equivalent security level and false-positive rate less than 2 --40 . Note that these latter security parameters can easily be tuned to fit different security requirements. Finally, the source code of Auth-AIS in the GNURadio ecosystem has been released as open-source, to foster research activities from both Industry and Academia on secure AIS communications.",IEEE Transactions on Dependable and Secure Computing,30 March 2021,2709 - 2726,,,10.1109/TDSC.2021.3069428,https://doi.org/10.1109/TDSC.2021.3069428,IEEE
Xducation of Things (XoT): Harnessing AI and Edge Computing to Educate All Things,Rio Nurtantyana; Wu-Yuin Hwang; Uun Hariyanti; ; ; ,https://ieeexplore.ieee.org/document/10705310/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10705310,"Most English foreign language (EFL) studies focus solely on human beings. This research explores how edge computing can facilitate learning for all things. The XoT (Xducation of Things) framework was proposed to educate both human and all things. All things encompass two terms: AI-Agent and smartthings (covering physical and digital smart objects). At the core of this framework is Smart Question Answer Forwarding Mechanism (SQA-Forwarding), specifically designed to assist all things in building knowledge. To demonstrate this, the smartXoT environment was developed based on XoT framework, and its impacts on EFL learners was assessed. A quasi-experimental study involving 26 EFL learners, divided into an experimental group (EG) and a control group (CG), examined the differences in learning achievement of smartthingsand EFL learners when using the smartXoT environment with/without SQA-Forwarding. Findings, on one hand, indicated that smartthingsin the EG developed knowledge bases greater than those in the CG. On the other hand, the interaction between EFL learners and smartthingswith SQA-Forwarding significantly improved learners’ writing skills, with revisions playing a crucial role in enhancing writing quality. Thus, the XoT framework offers a novel and promising approach to educating both humans and all things.",IEEE Access,04 October 2024,147138 - 147155,2169-3536,,10.1109/ACCESS.2024.3474015,https://doi.org/10.1109/ACCESS.2024.3474015,IEEE
"Beyond A Reasonable Doubt? Audiovisual Evidence, AI Manipulation, Deepfakes, and the Law",Yvonne Apolo; Katina Michael; ; ,https://ieeexplore.ieee.org/document/10632877/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10632877,"THE CAPTURE is a mystery thriller series, that completed its second season on Peacock and BBC One. The British television drama revolves around the alteration of direct audiovisual evidence on the command of a special unit that believes there is enough circumstantial evidence to either convict or acquit an individual of a felony. Based on the plot of the television series, this paper explores the potential for a variety of AI-enabled applications to be used in the course of criminal proceedings. The implications of evidence tampering are considered through AI manipulation toward the realization that deepfake evidence may well be admitted in court dependent on the human decision-maker. Will the future demand the interpolation of visual evidence for high profile criminal cases, and what does the existence of Generative AI and deepfakes mean for the forensic analysis of audiovisual evidence? After contemplating the socio-technical plausibility of the central premise of THE CAPTURE, this paper then turns to its legal implications. Drawing on examples from U.S. and Australian legal frameworks, the paper considers the consequences of AI-corrected, augmented or generated audiovisual evidence on three facets of natural justice: (1) the presumption of innocence; (2) the fair trial; and (3) lawyers’ ethical duties of competence and to the administration of justice. The key takeaways of the paper are that: (1) deepfake evidence will continue to proliferate; (2) that the law will need to address both the substantive and procedural impacts of such evidence, and (3) that the legal profession must continue to educate its lawyers and practitioners, and associated stakeholders, of the nature, uses and risks posed by deepfake audiovisual artefacts to maintain public trust in the legal system.",IEEE Transactions on Technology and Society,09 August 2024,156 - 168,2637-6415,,10.1109/TTS.2024.3427816,https://doi.org/10.1109/TTS.2024.3427816,IEEE
Employ AI to Improve AI Services : Q-Learning Based Holistic Traffic Control for Distributed Co-Inference in Deep Learning,Chaofeng Zhang; Mianxiong Dong; Kaoru Ota; ; ; ,https://ieeexplore.ieee.org/document/9540249/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9540249,"As the inevitable part of intelligent service in the new era, the services for AI tasks themselves have received significant attention, which due to the urgency of energy and computing resources, is difficult to implement in a stable and widely distributed system and coordinately utilize remote edge devices and cloud. In this article, we introduce an AI-based holistic network optimization solution to schedule AI services. Our proposed deep Q-learning algorithm optimizes the overall throughput of AI co-inference tasks themselves by balancing the uneven computation resources and traffic conditions. We use a multi-hop DAG (Directed Acyclic Graph) to describe a deep neural network (DNN) based co-inference network structure and introduce the virtual queue to analyze the Lyapunov stability for the system. Then, a priority-based data forwarding strategy is proposed to maximize the bandwidth efficiency, and we develop a Real-time Deep Q-learning based Edge Forwarding Scheme Optimization Algorithm (RDFO) to maximize the overall task processing rate. Finally, we conduct the platform simulation for the distributed co-inference system. Through the comparison with other benchmarks, we testify to the optimality of our proposal.",IEEE Transactions on Services Computing,16 September 2021,627 - 639,,,10.1109/TSC.2021.3113184,https://doi.org/10.1109/TSC.2021.3113184,IEEE
Dynamic AI-IoT: Enabling Updatable AI Models in Ultralow-Power 5G IoT Devices,Mohammad AlSelek; Jose M. Alcaraz-Calero; Qi Wang; ; ; ,https://ieeexplore.ieee.org/document/10349697/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10349697,"This article addresses the challenge of integrating dynamic AI capabilities into ultralow-power (ULP) IoT devices, a critical necessity in the rapidly evolving landscape of 5G and potential 6G technologies. We introduce the Dynamic AI-IoT architecture, a novel framework designed to eliminate the need for cumbersome firmware updates. This architecture leverages Narrowband IoT (NB-IoT) to facilitate smooth cloud interactions and incorporates tailored firmware extensions for enabling dynamic interactions with Tiny Machine Learning (TinyML) models. A sophisticated memory management mechanism, grounded in memory alignment and dynamic AI operations resolution, is introduced to efficiently handle AI tasks. Empirical experiments demonstrate the feasibility of implementing a Dynamic AI-IoT system using ULP IoT devices on a 5G testbed. The results show model updates taking less than one second and an average inference time of approximately 46 ms.",IEEE Internet of Things Journal,08 December 2023,14192 - 14205,,,10.1109/JIOT.2023.3340858,https://doi.org/10.1109/JIOT.2023.3340858,IEEE
Networking Systems of AI: On the Convergence of Computing and Communications,Liang Song; Xing Hu; Guanhua Zhang; Petros Spachos; Konstantinos N. Plataniotis; Hequan Wu; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9766416/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9766416,"Artificial intelligence (AI) and 5G system have been two hot technical areas that are changing the world. On the deep convergence of computing and communication, networking systems of AI (NSAI) is presenting a paradigm shift, where distributed AI becomes immersive in all elements of the network, i.e., cloud, edge, and terminal devices, which make AI virtually operating as a networking system. On the other hand, by the evolution of the communication systems, a network is becoming a service-specific system interweaved with AI, i.e., the network operates as an AI system, enabling real-time smart services. With the developing technology trends of “AI as a network and network as an AI,” the ecosystem of NSAI can be presenting the next-generation waves of both AI systems and B5G-6G communication networks. In this article, we mainly aim to provide a comprehensive survey on the system architecture, key technologies, application scenarios, challenges, and opportunities of NSAI, which can shed light on the future developments of both telecommunications and AI computing. The contributions of this article also include: 1) providing a unified framework for the deep convergence of computing and communications, where the network and application/service can be jointly optimized as a single integrated system and 2) suggesting the roadmap and open research problems in realizing the online-evolutive integration of cyberspace, physical world, and human society, toward the ubiquitous brain networks (UBNs), which are requiring the joint efforts from both research communities of computing and communication.",IEEE Internet of Things Journal,03 May 2022,20352 - 20381,,,10.1109/JIOT.2022.3172270,https://doi.org/10.1109/JIOT.2022.3172270,IEEE
OverlapTransformer: An Efficient and Yaw-Angle-Invariant Transformer Network for LiDAR-Based Place Recognition,Junyi Ma; Jun Zhang; Jintao Xu; Rui Ai; Weihao Gu; Xieyuanli Chen; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9785497/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9785497,"Place recognition is an important capability for autonomously navigating vehicles operating in complex environments and under changing conditions. It is a key component for tasks such as loop closing in SLAM or global localization. In this letter, we address the problem of place recognition based on 3D LiDAR scans recorded by an autonomous vehicle. We propose a novel lightweight neural network exploiting the range image representation of LiDAR sensors to achieve fast execution with less than 2 ms per frame. We design a yaw-angle-invariant architecture exploiting a transformer network, which boosts the place recognition performance of our method. We evaluate our approach on the KITTI and Ford Campus datasets. The experimental results show that our method can effectively detect loop closures compared to the state-of-the-art methods and generalizes well across different environments. To evaluate long-term place recognition performance, we provide a novel dataset containing LiDAR sequences recorded by a mobile robot in repetitive places at different times.",IEEE Robotics and Automation Letters,30 May 2022,6958 - 6965,,,10.1109/LRA.2022.3178797,https://doi.org/10.1109/LRA.2022.3178797,IEEE
Anywhere Is Possible: An Avatar Platform for Social Telepresence With Full Perception of Physical Interaction,Giancarlo Santamato; Daniele Leonardis; Simone Marcheschi; Salvatore D’Avella; Tommaso Bagneschi; Cristian Camardella; Domenico Chiaradia; Massimiliano Gabardi; Angela Mazzeo; Marcello Palagi; Francesco Porcini; Massimiliano Solazzi; Luca Tiseni; Paolo Tripicchio; Marco Controzzi; Claudio Loconsole; Antonio Frisoli; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10531290/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10531290,"Robotic avatar technology has the potential to impact the future of human connectivity, transporting the sense of a human’s presence to a remote location anywhere and in real-time. In this regard, the recent ANA Avatar XPRIZE challenge fostered the development of the ultimate generation of non-autonomous robotic avatar designs. This paper is devoted to introducing our system proposal, allowing intuitive motion-based control and multi-modal feedback. The teleoperated robot endorses an anthropomorphic upper body with dual arms and dexterous hands for fine manipulation of even small objects, as well as an omnidirectional platform for improved and safe locomotion. Special focus is pointed at the crucial challenge of providing self-body perception to the operator, in particular regarding control of the arms and rendering of haptic sensations. To this end, we propose an upper-limb exoskeleton and a teleoperation architecture allowing retargeting of the operator’s skills and receiving tactile and kinesthetic force feedback with realistic and informative perception of the own’s arms. Lastly, the platform was validated during laboratory and challenge missions mimicking several social, cooperative, and cultural scenarios from which we report on the lesson learned and future improvements.",IEEE Access,16 May 2024,70926 - 70945,2169-3536,,10.1109/ACCESS.2024.3402090,https://doi.org/10.1109/ACCESS.2024.3402090,IEEE
The State of AI-Empowered Backscatter Communications: A Comprehensive Survey,Fang Xu; Touseef Hussain; Manzoor Ahmed; Khurshed Ali; Muhammad Ayzed Mirza; Wali Ullah Khan; Asim Ihsan; Zhu Han; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10195838/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10195838,"The Internet of Things (IoT) is undergoing significant advancements, driven by the emergence of backscatter communication (BC) and artificial intelligence (AI). BC is an energy-saving and cost-effective communication method where passive backscatter devices (BDs) communicate by modulating ambient radio-frequency (RF) carriers. AI has the potential to transform our way of communicating and interacting and represents a powerful tool for enabling the next generation of IoT devices and networks. By integrating AI with BC, we can create new opportunities for energy-efficient and low-cost communication and open the door to a range of innovative applications that were previously not possible. This article brings these two technologies together to investigate the current state of AI-powered BC. We begin with an introduction to BC and an overview of the AI algorithms employed in BC. Then, we delve into the recent advances in AI-based BC, covering key areas, such as backscatter signal detection, channel estimation, and jammer control to ensure security, mitigate interference, and improve throughput and latency. We also explore the exciting frontiers of AI in BC using B5G/6G technologies, including backscatter-assisted relay and cognitive communication networks, backscatter-assisted MEC networks, and BC with reconfigurable intelligent surfaces (RISs), UAV, and vehicular networks. Finally, in the discussion section, we summarize the solutions, provide lessons learned and challenges, and present new research opportunities in AI-powered BC. This survey provides a comprehensive overview of the potential of AI-powered BC and its insightful impact on the future of IoT.",IEEE Internet of Things Journal,26 July 2023,21763 - 21786,,,10.1109/JIOT.2023.3299210,https://doi.org/10.1109/JIOT.2023.3299210,IEEE
Explainable AI Using the Wasserstein Distance,Shion Samadder Chaudhury; Payel Sadhukhan; Kausik Sengupta; ; ; ,https://ieeexplore.ieee.org/document/10418081/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10418081,"AI-based decision systems often lack transparency due to their black-box nature and lack explanations of their decisions, which are crucial for life-changing applications such as disease diagnosis, financial investments, and military decisions. Explainable AI (XAI) deals with explanations, justifications, and accountability of AI applications and has become the call of the present time. However, there is a dearth of XAI protocols which associate technicality and usability. In this paper, novel, usable XAI definitions are introduced, where Wasserstein distance serves as the backbone. The key essence of our work is to integrate the mathematical formulation with the performances of the model. Our work provides definitions in three contexts — i) the explainability of a model, ii) the explainability of the features, and iii) the explainability of the decisions rendered by a model. In this work, the proposed constructions are validated through experiments done on finitely many different models. The empirical results on synthetic and real-world datasets validate a positive association between proposed explainabilities and the performance of a model.",IEEE Access,31 January 2024,18087 - 18102,2169-3536,,10.1109/ACCESS.2024.3360484,https://doi.org/10.1109/ACCESS.2024.3360484,IEEE
Evaluating Explanations From AI Algorithms for Clinical Decision-Making: A Social Science-Based Approach,Suparna Ghanvatkar; Vaibhav Rajan; ; ,https://ieeexplore.ieee.org/document/10508367/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10508367,"Explainable Artificial Intelligence (XAI) techniques generate explanations for predictions from AI models. These explanations can be evaluated for (i) faithfulness to the prediction, i.e., its correctness about the reasons for prediction, and (ii) usefulness to the user. While there are metrics to evaluate faithfulness, to our knowledge, there are no automated metrics to evaluate the usefulness of explanations in the clinical context. Our objective is to develop a new metric to evaluate usefulness of AI explanations to clinicians. Usefulness evaluation needs to consider both (a) how humans generally process explanations and (b) clinicians' specific requirements from explanations presented by clinical decision support systems (CDSS). Our new scoring method can evaluate the usefulness of explanations generated by any XAI method that provides importance values for the input features of the prediction model. Our method draws on theories from social science to gauge usefulness, and uses literature-derived biomedical knowledge graphs to quantify support for the explanations from clinical literature. We evaluate our method in a case study on predicting onset of sepsis in intensive care units. Our analysis shows that the scores obtained using our method corroborate with independent evidence from clinical literature and have the required qualities expected from such a metric. Thus, our method can be used to evaluate and select useful explanations from a diverse set of XAI techniques in clinical contexts, making it a fundamental tool for future research in the design of AI-driven CDSS.",IEEE Journal of Biomedical and Health Informatics,25 April 2024,4269 - 4280,,38662559,10.1109/JBHI.2024.3393719,https://doi.org/10.1109/JBHI.2024.3393719,IEEE
Enhancing Household Energy Consumption Predictions Through Explainable AI Frameworks,Aakash Bhandary; Vruti Dobariya; Gokul Yenduri; Rutvij H. Jhaveri; Saikat Gochhait; Francesco Benedetto; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10459177/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10459177,"Effective energy management is crucial for sustainability, carbon reduction, resource conservation, and cost savings. However, conventional energy forecasting methods often lack accuracy, suggesting the need for advanced approaches. Artificial intelligence (AI) has emerged as a powerful tool for energy forecasting, but its lack of transparency and interpretability poses challenges for understanding its predictions. In response, Explainable AI (XAI) frameworks have been developed to enhance the transparency and interpretability of black-box AI models. Accordingly, this paper focuses on achieving accurate household energy consumption predictions by comparing prediction models based on several evaluation metrics, namely the Coefficient of Determination (R2), Root Mean Squared Error (RMSE), Mean Squared Error (MSE), and Mean Absolute Error (MAE). The best model is identified by comparison after making predictions on unseen data, after which the predictions are explained by leveraging two XAI frameworks: Local Interpretable Model-Agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP). These explanations help identify crucial characteristics contributing to energy consumption predictions, including insights into feature importance. Our findings underscore the significance of current consumption patterns and lagged energy consumption values in estimating energy usage. This paper further demonstrates the role of XAI in developing consistent and reliable predictive models.",IEEE Access,04 March 2024,36764 - 36777,2169-3536,,10.1109/ACCESS.2024.3373552,https://doi.org/10.1109/ACCESS.2024.3373552,IEEE
Enhancing Predictive Models to Lower Rehospitalization Risk: Utilizing Historical Medical Records for AI-Driven Interventions,Giada Confortola; Mika Takata; Naoaki Yokoi; Masashi Egi; ; ; ; ,https://ieeexplore.ieee.org/document/10547035/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10547035,"Artificial Intelligence (AI) models can predict patient readmission probabilities, aiding discharge decisions and preventing early discharges, which can lead to rehospitalization and related increased costs. EXplainable AI (XAI) methods, like SHAP, can identify important features for the predicted risk. However, the readmission risk and features importance are often considered not informative enough, as they lack in providing suggestions on how to reduce the risk when it is too high to discharge the patient. Our proposed method addresses this gap by using historical medical records of patients with profiles similar to the current case. It generates suggestions for modifying feature values to reduce the AI-predicted rehospitalization risk. By analyzing the historical data distribution of these features, our method infers optimal values and provides targeted suggestions to align current values with these ideals, offering a strategy for situations where discharge risk is deemed too high. In our approach, we explore different definitions of patient similarity to select historical cases and evaluate the effectiveness of the derived suggestions. This is compared with suggestions generated using random historical cases to determine the most effective case selection criteria. Using the MIMIC-III electronic health record dataset, our method demonstrated that two specific sets of historical cases achieved an 80% precision in suggestions, surpassing random case selections by 3%. Ultimately, this method provides recommendations to reduce the readmission risks, serving as a valuable tool in discharge planning. This contributes significantly to reducing premature discharges and the associated costs of rehospitalization.",IEEE Access,03 June 2024,78911 - 78921,2169-3536,,10.1109/ACCESS.2024.3409152,https://doi.org/10.1109/ACCESS.2024.3409152,IEEE
EID: Facilitating Explainable AI Design Discussions in Team-Based Settings,,https://ieeexplore.ieee.org/document/10159627/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10159627,"Artificial intelligence (AI) systems have many applications with tremendous current and future value to human society. As AI systems penetrate the aspects of everyday life, a pressing need arises to explain their decision-making processes to build trust and familiarity among end users. In high-stakes fields such as healthcare and self-driving cars, AI systems are required to have a minimum standard for accuracy and to provide well-designed explanations for their output, especially when they impact human life. Although many techniques have been developed to make algorithms explainable in human terms, no design methodologies that will allow software teams to systematically draw out and address explainability-related issues during AI design and conception have been established. In response to this gap, we proposed the explainability in design (EID) methodological framework for addressing explainability problems in AI systems. We explored the literature on AI explainability to narrow down the field into six major explainability principles that will aid designers in brainstorming around the metrics and guide the critical thinking process. EID is a step-by-step guide to AI design that has been refined over a series of user studies and interviews with experts in AI explainability. It is devised for software design teams to uncover and resolve potential issues in their AI products and to simply refine and explore the explainability of their products and systems. The EID methodology is a novel framework that aids in the design and conception stages of the AI pipeline and can be integrated into the form of a step-by-step card game. Empirical studies involving AI system designers have shown that EID can decrease the barrier of entry and the time and experience required to effectively make well-informed decisions for integrating explainability into their AI solutions.",International Journal of Crowd Science,22 June 2023,47 - 54,2398-7294,,10.26599/IJCS.2022.9100034,https://doi.org/10.26599/IJCS.2022.9100034,TUP
Designing Efficient and High-Performance AI Accelerators With Customized STT-MRAM,Kaniz Mishty; Mehdi Sadi; ; ,https://ieeexplore.ieee.org/document/9526872/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9526872,"We demonstrate the design of efficient and high-performance artificial intelligence (AI)/deep learning accelerators with customized spin transfer torque (STT)-MRAM (STT-MRAM) and a reconfigurable core. Based on model-driven detailed design space exploration, we present the design methodology of an innovative scratchpad-assisted on-chip STT-MRAM-based buffer system for high-performance accelerators. Using analytically derived expression of memory occupancy time of AI model weights and activation maps, the volatility of STT-MRAM is adjusted with process and temperature variation aware scaling of thermal stability factor to optimize the retention time, energy, read/write latency, and area of STT-MRAM. From the analysis of AI workloads and accelerator implementation in 14-nm technology, we verify the efficacy of our AI accelerator with STT-MRAM (STT-AI). Compared to an SRAM-based implementation, the STT-AI accelerator achieves 75% area and 3% power savings at isoaccuracy. Furthermore, with a relaxed bit error rate and negligible AI accuracy tradeoff, the designed STT-AI Ultra accelerator achieves 75.4% and 3.5% savings in area and power, respectively, over regular SRAM-based accelerators.",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,01 September 2021,1730 - 1742,,,10.1109/TVLSI.2021.3105958,https://doi.org/10.1109/TVLSI.2021.3105958,IEEE
Supporting Teachers’ Professional Development With Generative AI: The Effects on Higher Order Thinking and Self-Efficacy,Jijian Lu; Ruxin Zheng; Zikun Gong; Huifen Xu; ; ; ; ,https://ieeexplore.ieee.org/document/10444988/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10444988,"Generative artificial intelligence (AI) has emerged as a noteworthy milestone and a consequential advancement in the annals of major disciplines within the domains of human science and technology. This study aims to explore the effects of generative AI-assisted preservice teaching skills training on preservice teachers’ self-efficacy and higher order thinking. The participants of this study were 215 preservice mathematics, science, and computer teachers from a university in China. First, a pretest–post-test quasi-experimental design was implemented for an experimental group (teaching skills training by generative AI) and a control group (teaching skills training by traditional methods) by investigating the teacher self-efficacy and higher order thinking of the two groups before and after the experiment. Finally, a semistructured interview comprising open-ended questions was administered to 25 preservice teachers within the experimental group to present their views on generative AI-assisted teaching. The results showed that the scores of preservice teachers in the experimental group, who used generative AI for teachers’ professional development, were considerably higher than those of the control group, both in teacher self-efficacy ( F = 8.589, p = 0.0084 < 0.05) and higher order thinking ( F = 7.217, p = 0.008 < 0.05). It revealed that generative AI can be effective in supporting teachers’ professional development. This study produced a practical teachers’ professional development method for preservice teachers with generative AI.",IEEE Transactions on Learning Technologies,26 February 2024,1279 - 1289,,,10.1109/TLT.2024.3369690,https://doi.org/10.1109/TLT.2024.3369690,IEEE
Competitive Algorithms for Coevolving Both Game Content and AI. A Case Study: Planet Wars,Mariela Nogueira-Collazo; Carlos Cotta Porras; Antonio J. Fernández-Leiva; ; ; ,https://ieeexplore.ieee.org/document/7323804/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7323804,"The classical approach of competitive coevolution (CC) applied in games tries to exploit an arms race between coevolving populations that belong to the same species (or at least to the same biotic niche), namely strategies, rules, tracks for racing, or any other. This paper proposes the coevolution of entities belonging to different realms (namely biotic and abiotic) via a competitive approach. More precisely, we aim to coevolutionarily optimize both virtual players and game content. From a general perspective, our proposal can be viewed as a method of procedural content generation combined with a technique for generating game AI. This approach can not only help game designers in game creation but also generate content personalized to both specific players' profiles and game designer's objectives (e.g., create content that favors novice players over skillful players). As a case study we use Planet Wars, the real-time strategy (RTS) game associated with the 2010 Google AI Challenge contest, and demonstrate (via an empirical study) the validity of our approach.",IEEE Transactions on Computational Intelligence and AI in Games,10 November 2015,325 - 337,,,10.1109/TCIAIG.2015.2499281,https://doi.org/10.1109/TCIAIG.2015.2499281,IEEE
Art Innovation or Plagiarism? Chinese Students’ Attitudes Toward AI Painting Technology and Influencing Factors,Changsheng Wang; ,https://ieeexplore.ieee.org/document/10552736/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10552736,"The increasing integration of artificial intelligence (AI) in art, particularly AI painting technology, has captivated significant attention and sparked debate. However, little is understood about the attitudes of Chinese students toward this technology and the factors influencing their perspectives. This study employed a mixed-methods approach to comprehensively appraise Chinese students’ attitudes toward AI painting technology and the reasons behind these viewpoints. Data was collected from five universities and three high schools in China through questionnaire surveys and semi-structured interviews. Quantitative analysis demonstrated clear trends in students’ attitudes toward AI painting technology, with gender, educational level, and background in art and design identified as significant influencing factors. Specifically, students with higher levels of education demonstrated more favorable attitudes toward AI painting technology. This was evidenced by a strong positive correlation coefficient of 0.644 (p<0.01) between educational attainment and positive perceptions of this technology; whereas, a negative correlation with gender (coefficient of −0.263, p<0.01) indicated a difference in attitudes between male and female students, with males displaying more positive views. Specifically, background in art and design did not appear to significantly affect students’ attitudes, as presented by an insignificant correlation coefficient of −0.048 (p>0.05). In addition, regression analysis, with an R2 value of 0.419, suggests that these variables can account for 41.9% of the variance in student attitudes toward AI painting, emphasizing the significant effect of gender and education level on their perspectives. Qualitative findings further indicated that concerns about copyright ethics, job displacement anxieties, personal values and aesthetic viewpoints, and broader social and environmental implications all affected students’ attitudes toward AI painting technology. These findings offer valuable insights into the attitudes toward AI-generated technologies.",IEEE Access,11 June 2024,85795 - 85805,2169-3536,,10.1109/ACCESS.2024.3412176,https://doi.org/10.1109/ACCESS.2024.3412176,IEEE
Dynamic Game Difficulty Scaling Using Adaptive Behavior-Based AI,Chin Hiong Tan; Kay Chen Tan; Arthur Tay; ; ; ,https://ieeexplore.ieee.org/document/5783334/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5783334,"Games are played by a wide variety of audiences. Different individuals will play with different gaming styles and employ different strategic approaches. This often involves interacting with nonplayer characters that are controlled by the game AI. From a developer's standpoint, it is important to design a game AI that is able to satisfy the variety of players that will interact with the game. Thus, an adaptive game AI that can scale the difficulty of the game according to the proficiency of the player has greater potential to customize a personalized and entertaining game experience compared to a static game AI. In particular, dynamic game difficulty scaling refers to the use of an adaptive game AI that performs game adaptations in real time during the game session. This paper presents two adaptive algorithms that use ideas from reinforcement learning and evolutionary computation to improve player satisfaction by scaling the difficulty of the game AI while the game is being played. The effects of varying the learning and mutation rates are examined and a general rule of thumb for the parameters is proposed. The proposed algorithms are demonstrated to be capable of matching its opponents in terms of mean scores and winning percentages. Both algorithms are able to generalize well to a variety of opponents.",IEEE Transactions on Computational Intelligence and AI in Games,02 June 2011,289 - 301,,,10.1109/TCIAIG.2011.2158434,https://doi.org/10.1109/TCIAIG.2011.2158434,IEEE
A Survey on Approximate Edge AI for Energy Efficient Autonomous Driving Services,Dewant Katare; Diego Perino; Jari Nurmi; Martijn Warnier; Marijn Janssen; Aaron Yi Ding; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10213996/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10213996,"Autonomous driving services depends on active sensing from modules such as camera, LiDAR, radar, and communication units. Traditionally, these modules process the sensed data on high-performance computing units inside the vehicle, which can deploy intelligent algorithms and AI models. The sensors mentioned above can produce large volumes of data, potentially reaching up to 20 Terabytes. This data size is influenced by factors such as the duration of driving, the data rate, and the sensor specifications. Consequently, this substantial amount of data can lead to significant power consumption on the vehicle. Similarly, a substantial amount of data will be exchanged between infrastructure sensors and vehicles for collaborative vehicle applications or fully connected autonomous vehicles. This communication process generates an additional surge of energy consumption. Although the autonomous vehicle domain has seen advancements in sensory technologies, wireless communication, computing and AI/ML algorithms, the challenge still exists in how to apply and integrate these technology innovations to achieve energy efficiency. This survey reviews and compares the connected vehicular applications, vehicular communications, approximation and Edge AI techniques. The focus is on energy efficiency by covering newly proposed approximation and enabling frameworks. To the best of our knowledge, this survey is the first to review the latest approximate Edge AI frameworks and publicly available datasets in energy-efficient autonomous driving. The insights from this survey can benefit the collaborative driving service development on low-power and memory-constrained systems and the energy optimization of autonomous vehicles.",IEEE Communications Surveys & Tutorials,09 August 2023,2714 - 2754,,,10.1109/COMST.2023.3302474,https://doi.org/10.1109/COMST.2023.3302474,IEEE
AI-Bazaar: A Cloud-Edge Computing Power Trading Framework for Ubiquitous AI Services,Xiaoxu Ren; Chao Qiu; Xiaofei Wang; Zhu Han; Ke Xu; Haipeng Yao; Song Guo; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9866794/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9866794,"Driven by the burgeoning growth of the Internet of Everything and the substantial breakthroughs in deep learning (DL) algorithms, a booming of artificial intelligence (AI) applications keep emerging. Meanwhile, the advance in existing computing paradigms, i.e., cloud computing and edge computing, provide assorted computing solutions to satisfy the increasingly high requirements for ubiquitous AI services. Nevertheless, there are some non-trivial issues in the computing frameworks, including the underutilization of computing power, the self-interest of computing-power trading mechanism, and the inefficiency of AI services management. To tackle the above issues, we propose a computing-power trading framework based on blockchain, also named AI-Bazaar. In AI-Bazaar, the AI consumers play multiple roles and feel free to contribute the computing power rented from the computing-power provider (CPP) for blockchain mining and AI services. Accordingly, we formulate the computing trading problem as a Stackelberg game. Based on the win or learn fast principle (WoLF), we design a profit-balanced multi-agent reinforcement learning (PB-MARL) algorithm to search the AI-Bazaar equilibrium, while finding the balanced profits for AI consumers and CPP. Numerical simulations are carried out to demonstrate the satisfactory performance and effectiveness of the proposed framework.",IEEE Transactions on Cloud Computing,25 August 2022,2337 - 2348,,,10.1109/TCC.2022.3201544,https://doi.org/10.1109/TCC.2022.3201544,IEEE
When AI Meets Information Privacy: The Adversarial Role of AI in Data Sharing Scenario,Abdul Majeed; Seong Oun Hwang; ; ,https://ieeexplore.ieee.org/document/10190078/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10190078,"Artificial intelligence (AI) is a transformative technology with a substantial number of practical applications in commercial sectors such as healthcare, finance, aviation, and smart cities. AI also has strong synergy with the information privacy (IP) domain from two distinct aspects: as a protection tool (i.e., safeguarding privacy), and as a threat tool (i.e., compromising privacy). In the former case, AI techniques are amalgamated with the traditional anonymization techniques to improve various key components of the anonymity process, and therefore, privacy is safeguarded effectively. In the latter case, some adversarial knowledge is aggregated with the help of AI techniques and subsequently used to compromise the privacy of individuals. To the best of our knowledge, threats posed by AI-generated knowledge such as synthetic data (SD) to information privacy are often underestimated, and most of the existing anonymization methods do not consider/model this SD-based knowledge that can be available to the adversary, leading to privacy breaches in some cases. In this paper, we highlight the role of AI as a threat tool (i.e., AI used to compromise an individual’s privacy), with a special focus on SD that can serve as background knowledge leading to various kinds of privacy breaches. For instance, SD can encompass pertinent information (e.g., total # of attributes in data, distributions of sensitive information, category values of each attribute, minor and major values of some attributes, etc.) about real data that can offer a helpful hint to the adversary regarding the composition of anonymized data, that can subsequently lead to uncovering the identity or private information. We perform reasonable experiments on a real-life benchmark dataset to prove the pitfalls of AI in the data publishing scenario (when a database is either fully or partially released to public domains for conducting analytics).",IEEE Access,21 July 2023,76177 - 76195,2169-3536,,10.1109/ACCESS.2023.3297646,https://doi.org/10.1109/ACCESS.2023.3297646,IEEE
Empowering Glioma Prognosis With Transparent Machine Learning and Interpretative Insights Using Explainable AI,Anisha Palkar; Cifha Crecil Dias; Krishnaraj Chadaga; Niranjana Sampathila; ; ; ; ,https://ieeexplore.ieee.org/document/10445227/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10445227,"The primary objective of this research is to create a reliable technique to determine whether a patient has glioma, a specific kind of brain tumour, by examining various diagnostic markers, using a variety of machine learning as well as deep learning approaches, and involving XAI (explainable artificial intelligence) methods. Through the integration of patient data, including medical records, genetic profiles, algorithms using machine learning have the ability to predict how each individual will react to different medical interventions. To guarantee regulatory compliance and inspire confidence in AI-driven healthcare solutions, XAI is incorporated. Machine learning methods employed in this study includes Random Forest, decision trees, logistic regression, KNN, Adaboost, SVM, Catboost, LGBM classifier, and Xgboost whereas the deep learning methods include ANN and CNN. Four alternative XAI strategies, including SHAP, Eli5, LIME, and QLattice algorithm, are employed to comprehend the predictions of the model. The Xgboost, a ML model achieved accuracy, precision, recall, f1 score, and AUC of 88%, 82%, 94%, 88%, and 92%, respectively. The best characteristics according to XAI techniques are IDH1, Age at diagnosis, PIK3CA, ATRX, PTEN, CIC, EGFR and TP53. By applying data analytic techniques, the objective is to provide healthcare professionals with practical tool that enhances their capacity for decision-making, enhances resource management, and ultimately raises the bar for patient care. Medical experts can customise treatments and improve patient outcomes by taking into account patient’s particular characteristics. XAI provides justifications to foster faith amongst patients and medical professionals who must rely on AI-assisted diagnosis and treatment recommendations.",IEEE Access,26 February 2024,31697 - 31718,2169-3536,,10.1109/ACCESS.2024.3370238,https://doi.org/10.1109/ACCESS.2024.3370238,IEEE
Low-Power Scalable TSPI: A Modular Off-Chip Network for Edge AI Accelerators,Seunghyun Park; Daejin Park; ; ,https://ieeexplore.ieee.org/document/10689577/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10689577,"In this paper, we present a novel off-chip network architecture, the Tile Serial Peripheral Interface (TSPI), designed for low-power, scalable edge AI accelerators. Our approach modifies the conventional SPI to support a modular network structure that facilitates the scalable connection of multiple accelerators. The TSPI network employs a subset mapping algorithm for efficient routing and integrates the message passing interface (MPI) protocol to ensure rapid data distribution and aggregation. This modular architecture significantly reduces power consumption and improves processing speed. Experimental results demonstrate that our proposed TSPI network achieves a 54.7% reduction in power consumption and an 82.3% decrease in switching power compared to traditional SPI networks, along with a 23% increase in processing speed when utilizing 16 nodes. These advancements make the TSPI network an effective solution for enhancing AI performance in edge computing environments.",IEEE Access,24 September 2024,141448 - 141459,2169-3536,,10.1109/ACCESS.2024.3466965,https://doi.org/10.1109/ACCESS.2024.3466965,IEEE
XAI-VSDoA: An Explainable AI-Based Scheme Using Vital Signs to Assess Depth of Anesthesia,Neeraj Kumar Sharma; Sakeena Shahid; Subodh Kumar; Sanjeev Sharma; Naveen Kumar; Tanya Gupta; Rakesh Kumar Gupta; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10646331/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10646331,"Administration of anesthesia is essential in surgical procedures, ensuring patient unconsciousness and safety. Traditional Depth of Anesthesia (DoA) assessment methods rely heavily on the clinical expertise of anesthesiologists and patient physiological responses, which can vary widely due to age, weight, and ethnicity. This variability poses significant challenges in maintaining appropriate anesthesia levels and making timely decisions in critical situations. To address these challenges, we propose XAI-VSDoA, an explainable AI model using vital signs designed to augment DoA assessment by providing accurate predictions and interpretable insights. In this work, we experimented with various machine learning classifiers, including XGBoost, CatBoost, LightGBM, Random Forest, ResNet, and Feed-forward Neural Networks. Among these, the XGBoost model achieved the highest accuracy, with 99.34% on the University of Queensland dataset and 93.07% on the VitalDB dataset. Statistical testing confirmed that XGBoost outperformed the other models. We employed explainable AI techniques such as LIME and SHAP to identify the top 10 features significantly influencing the model’s predictions, ensuring the model’s transparency and reliability. These methods consistently highlighted the same influential features, reinforcing the model’s interpretability. Our proposed scheme demonstrated exceptional performance using numeric vital signs, with XAI techniques validating the key features. This interpretability boosts confidence in the model, enhancing its utility to augument and support the clininal observations of anethesiologiss in anesthesia management. Our findings underscore the potential of XAI-VSDoA as a valuable tool for clinical use, enhancing patient safety and decision-making in anesthesia.",IEEE Access,26 August 2024,119185 - 119206,2169-3536,,10.1109/ACCESS.2024.3449704,https://doi.org/10.1109/ACCESS.2024.3449704,IEEE
Analog Multiply-Accumulate Cell With Multi-Bit Resolution for All-Analog AI Inference Accelerators,Raphael Nägele; Jakob Finkbeiner; Valentin Stadtlander; Markus Grözing; Manfred Berroth; ; ; ; ; ,https://ieeexplore.ieee.org/document/10114059/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10114059,"Mixed-signal AI accelerators offer the possibility of higher energy efficiency for moderate resolution computations compared to their digital counterparts. All-analog implementations, where all operations are performed in the analog domain, can further improve this energy advantage. An energy efficient multiply-accumulate cell for all-analog neural layer processing macros is presented. The proposed analog two-quadrant multiplier circuit consists of two complementary MOSFETs where the pulse width modulated input activation is applied to the gates and the weight signal to the isolated back-gate. The analog multi-bit resolution weight is dynamically stored on a memory capacitor. The multiply-accumulate operation result is represented by charge accumulated on a summation line and drawn from or put onto a computation capacitance. Simulation results based on a 22 nm FD-SOI CMOS technology show that the cell consumes about 0.67 fJ for a circuit-level multiply-accumulate operation. An area efficiency of 166\times 10^{12} MAC/s/mm2 is achieved.",IEEE Transactions on Circuits and Systems I: Regular Papers,02 May 2023,3509 - 3521,,,10.1109/TCSI.2023.3268728,https://doi.org/10.1109/TCSI.2023.3268728,IEEE
Generative AI for Physical Layer Communications: A Survey,Nguyen Van Huynh; Jiacheng Wang; Hongyang Du; Dinh Thai Hoang; Dusit Niyato; Diep N. Nguyen; Dong In Kim; Khaled B. Letaief; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10490142/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10490142,"The recent evolution of generative artificial intelligence (GAI) leads to the emergence of groundbreaking applications such as ChatGPT, which not only enhances the efficiency of digital content production, such as text, audio, video, or even network traffic data, but also enriches its diversity. Beyond digital content creation, GAI’s capability in analyzing complex data distributions offers great potential for wireless communications, particularly amidst a rapid expansion of new physical layer communication technologies. For example, the diffusion model can learn input signal distributions and use them to improve the channel estimation accuracy, while the variational autoencoder can model channel distribution and infer latent variables for blind channel equalization. Therefore, this paper presents a comprehensive investigation of GAI’s applications for communications at the physical layer, ranging from traditional issues, including signal classification, channel estimation, and equalization, to emerging topics, such as intelligent reflecting surfaces and joint source channel coding. We also compare GAI-enabled physical layer communications with those supported by traditional AI, highlighting GAI’s inherent capabilities and unique contributions in these areas. Finally, the paper discusses open issues and proposes several future research directions, laying a foundation for further exploration and advancement of GAI in physical layer communications.",IEEE Transactions on Cognitive Communications and Networking,03 April 2024,706 - 728,,,10.1109/TCCN.2024.3384500,https://doi.org/10.1109/TCCN.2024.3384500,IEEE
Comparing the Ideation Quality of Humans With Generative Artificial Intelligence,Jan Joosten; Volker Bilgram; Alexander Hahn; Dirk Totzek; ; ; ; ,https://ieeexplore.ieee.org/document/10398283/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10398283,"Traditionally, ideating new product innovations is primarily the responsibility of marketers, engineers, and designers. However, a rapidly growing interest lies in leveraging generative artificial intelligence (AI) to brainstorm new product and service ideas. This study conducts a comparative analysis of ideas generated by human professionals and an AI system. The results of a blind expert evaluation show that AI-generated ideas score significantly higher in novelty and customer benefit, while their feasibility scores are similar to those of human ideas. Overall, AI-generated ideas comprise the majority of the top-performing ideas, while human-generated ideas scored lower than expected. The executive's emotional and cognitive reactions were measured during the evaluation to check for potential biases and showed no differences between the idea groups. These findings suggest that, under certain circumstances, companies can benefit from integrating generative AI into their traditional idea-generation processes.",IEEE Engineering Management Review,12 January 2024,153 - 164,,,10.1109/EMR.2024.3353338,https://doi.org/10.1109/EMR.2024.3353338,IEEE
The Different Faces of AI Ethics Across the World: A Principle-to-Practice Gap Analysis,Lionel Nganyewou Tidjon; Foutse Khomh; ; ,https://ieeexplore.ieee.org/document/9964285/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9964285,"Impact Statement:
The effective practical guidance of ethics in AI is the current concern of governments, national, and international organizations. However, the complexity of ethical AI principles and their context-dependency means that current practical guidances do not capture well their abstraction, leading to gaps. The work analyzes these gaps, their root causes, and formulates recommendations for their mitigation. Governments, national, and international organisations can leverage the results of this work to guide their AI initiatives, conduct ethical AI practical guidances adapted to their context, and prevent gaps in the practical guidances of ethical AI principles.",IEEE Transactions on Artificial Intelligence,28 November 2022,820 - 839,2691-4581,,10.1109/TAI.2022.3225132,https://doi.org/10.1109/TAI.2022.3225132,IEEE
STRAIT: Self-Test and Self-Recovery for AI Accelerator,Hayoung Lee; Jihye Kim; Jongho Park; Sungho Kang; ; ; ; ,https://ieeexplore.ieee.org/document/10016640/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10016640,"As the demand for data-intensive analytics has increased with the rapid advance in artificial intelligence (AI), various AI accelerators have been proposed. However, as AI-based solutions have been adapted to applications requiring accuracy and reliability, the reliability of them has become a critical issue. For this reason, self-test and self-recovery for AI accelerator (STRAIT) is proposed in this article. It facilitates self-test, self-diagnosis, and self-recovery by utilizing the structural and operational characteristics of systolic array in AI accelerator. The proposed self-test is progressed using scan chains composed of functional paths and can achieve a 100% test coverage (for both stuck-at and transition-delay faults) with a small number of test patterns and reduced test power. The proposed self-diagnosis is progressed with the proposed self-test in real time and allows accurate fault localization with fault type analysis. The proposed self-recovery is progressed using efficient pruning for faulty processing elements with weight allocation, and the reliability of AI accelerators can drastically increase with negligible performance degradation. However, STRAIT can be implemented with a small area overhead.",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,13 January 2023,3092 - 3104,,,10.1109/TCAD.2023.3236875,https://doi.org/10.1109/TCAD.2023.3236875,IEEE
Eco-Friendly Low Resource Security Surveillance Framework Toward Green AI Digital Twin,Hyunbum Kim; Jalel Ben-Othman; ; ,https://ieeexplore.ieee.org/document/9932580/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9932580,"Most intelligent systems focused on how to improve performance including accuracy, processing speed with a massive number of data sets and those performance-biased intelligent systems, Red AI systems, have been applied to digital twin in smart cities. On the other hand, it is highly reasonable to consider Green AI features covering environmental, economic, social costs for advanced digital twin services. In this letter, we propose eco-friendly low resource security surveillance toward Green AI-enabled digital twin service, which provides eco-friendly security by the active participation of low resource devices. And, we formally define a problem whose objective is to maximize the participation of low source or reusable devices such that reusable surveillance borders are created within security district. Also, a dense sub-district with low resource devices priority completion scheme is proposed to resolve the problem. Then, the devised method is performed by expanded simulations and the achieved result is evaluated with demonstrated discussions.",IEEE Communications Letters,28 October 2022,377 - 380,,,10.1109/LCOMM.2022.3218050,https://doi.org/10.1109/LCOMM.2022.3218050,IEEE
Editorial of Special Issue on AI for Health and Ageless Aging,Xuejiao Zhao; ,https://ieeexplore.ieee.org/document/10530644/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10530644,"Artificial Intelligence (AI) is increasingly being applied in the health and aging domain in recent decades. These interdisciplinary research efforts and the application of AI technologies offer potential solutions for improving healthcare, ageless aging, medicinal development, etc. These applications simplify the lives of seniors, patients, doctors, caregivers, etc., significantly by performing tasks that are typically done by humans, but in less time and at a fraction of the cost [1–3] .",International Journal of Crowd Science,14 May 2024,i - ii,2398-7294,,10.26599/IJCS.2024.9100009,https://doi.org/10.26599/IJCS.2024.9100009,TUP
Application of Dynamic Deformable Attention in Bird’s-Eye-View Detection,Weihao Gu; Rui Ai; Jinlong Liu; Lili Fan; Dongpu Cao; Kai Zhang; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9905705/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9905705,"Recently, the performance improvement of BEV visual detection task has benefited from the extensive use of deformable attention. Deformable attention can easily transfer the features of the image space to the BEV space through the cross-attention mechanism. Compared with the global attention mechanism, when the feature resolution of the graph is larger, the computational consumption of deformable attention will be much smaller, so it can support larger Bird’s-Eye-View (BEV) feature resolution. However, there are also shortcomings such as a small receptive field and insufficient information exchange. We propose a deformable attention mechanism for dynamic reference points. This module is to accumulate the reference points of each cross-attention layer on the basis of the previous layer, thereby effectively expanding the perceptual field of BEV features for querying in the image space. Extensive experiments on the nuScenes benchmark demonstrate the effectiveness of our method.",IEEE Journal of Radio Frequency Identification,29 September 2022,886 - 890,,,10.1109/JRFID.2022.3210696,https://doi.org/10.1109/JRFID.2022.3210696,IEEE
OPO-FCM: A Computational Affection Based OCC-PAD-OCEAN Federation Cognitive Modeling Approach,Feng Liu; Han-Yang Wang; Si-Yuan Shen; Xun Jia; Jing-Yi Hu; Jia-Hao Zhang; Xi-Yi Wang; Ying Lei; Ai-Min Zhou; Jia-Yin Qi; Zhi-Bin Li; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9868797/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9868797,"In recent years, it is a difficult issue to integrate the deep cross-fertilization and interpretable cognitive modeling methods from the basic theory of emotional psychology with deep learning and other algorithms. To address this problem, a cognitive model that integrates the VGG-facial action coding system (FACS)-OCC model based on fer2013 expression features and the OCC-pleasure-arousal-dominance (PAD)-openness, conscientiousness, extraversion, agreeableness, and neuroticism (OCEAN) fusion of the basic theory of emotional psychology, namely, a computational affection-based OCC-PAD-OCEAN federation cognitive modeling (OPO-FCM), is constructed. By constructing this model and performing formal proof algorithms, it is shown that the OPO-FCM can acquire expression features in video streams, complete the acquisition of expression features in videos by training a deep neural network, map expressions to the PAD emotion space through the established expression–basic emotions–emotion space mapping relationship, and finally complete the mapping of the average emotion over a period time. The information of personality space is obtained through it. Finally, the experimental simulation of the model is conducted, and the results show that the average accuracy of the valid tested personalities is 79.56%. This article takes the knowledge-driven approach of emotional psychology as a starting point and combines deep learning techniques to construct interpretable cognitive models, thus providing new ideas for future cross-innovation between computer technology and psychology theory.",IEEE Transactions on Computational Social Systems,26 August 2022,1813 - 1825,,,10.1109/TCSS.2022.3199119,https://doi.org/10.1109/TCSS.2022.3199119,IEEE
"Explainable Predictive Maintenance of Rotating Machines Using LIME, SHAP, PDP, ICE",Shreyas Gawde; Shruti Patil; Satish Kumar; Pooja Kamat; Ketan Kotecha; Sultan Alfarhood; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10440027/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10440027,"Artificial Intelligence (AI) is a key component in Industry 4.0. Rotating machines are critical components in manufacturing industries. In the vast world of Industry 4.0, where an IoT network acts as a monitoring and decision-making system, predictive maintenance is quickly gaining importance. Predictive maintenance is a method that uses AI to handle potential problems before they cause breakdowns in operations, processes or systems. However, there is a significant issue with the AI models’ (also known as “black boxes”) inability to explain their decisions. This interpretability is vital for making maintenance decisions and validating the model’s reliability, leading to improved trust and acceptance of AI-driven predictive maintenance strategies. Explainable AI is the solution because it provides human-understandable insights into how the AI model arrives at its predictions. In this regard, the paper presents Explainable AI-based predictive maintenance of Industrial rotating machines. The proposed approach unfolds in four comprehensive stages: 1) Multi-sensor based multi-fault (5 different fault classes) data acquisition; 2) frequency-domain statistical feature extraction; and c) comparison of results for multiple AI algorithms, and d) XAI integration using “Local Interpretable Model Agnostic Explanation (LIME)”, “SHapley Additive exPlanation (SHAP)”, “Partial Dependence Plot (PDP)” and “Individual Conditional Expectation (ICE)” to interpret the results.",IEEE Access,19 February 2024,29345 - 29361,2169-3536,,10.1109/ACCESS.2024.3367110,https://doi.org/10.1109/ACCESS.2024.3367110,IEEE
XAI-ADS: An Explainable Artificial Intelligence Framework for Enhancing Anomaly Detection in Autonomous Driving Systems,Sazid Nazat; Lingxi Li; Mustafa Abdallah; ; ; ,https://ieeexplore.ieee.org/document/10486915/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10486915,"The advent of autonomous driving systems has given rise to pressing cybersecurity issues regarding the vulnerability of vehicular ad hoc networks (VANETs) to potential attacks. This critical security problem necessitates the application of artificial intelligence (AI) models for anomaly detection in VANETs of autonomous vehicles (AVs). However, the lack of explainability of such AI-based anomaly detection models presents challenges. This motivates an emerging research direction of utilizing explainable AI (XAI) techniques to elucidate the behaviors of anomaly detection models in AV networks. In this work, we propose an end-to-end XAI framework to interpret and visualize the anomaly detection classifications made by AI models securing VANETs. We evaluate the framework on two real-world autonomous driving datasets. The framework furnishes both global and local explanations for the black-box AI models using two XAI methods. Moreover, we introduce two novel feature selection techniques to identify the salient features contributing to anomaly detection, derived from the popular SHAP XAI method and the accuracy of six different black-box AI models. We compare our proposed feature selection approaches with six state-of-the-art feature selection techniques (including two wrapper-based feature selection methods), demonstrating superior performance on various evaluation metrics. To generalize the impact of our feature selection methods, we apply three independent classifiers to evaluate our proposed feature selection approaches. The novel feature selection methods effectively distill the most explanatory features, enhancing model interpretability. Finally, we assess the efficiency (how quickly the XAI models can yield explanatory findings) for each of the six black-box AI models we employed on our two datasets, identifying the most efficient model. By furnishing explanations and visualizations of anomaly detection by AI models, our XAI framework can help in enabling trust and...",IEEE Access,02 April 2024,48583 - 48607,2169-3536,,10.1109/ACCESS.2024.3383431,https://doi.org/10.1109/ACCESS.2024.3383431,IEEE
Design and Performance Analysis of a Bioelectronic Controlled Hybrid Serial-Parallel Wrist Exoskeleton,Xueze Zhang; Minjie Wang; Hongbo Wang; Fuhao Wang; Li Chen; Wei Mu; Junkongshuai Wang; Xiaoyang Kang; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10145484/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10145484,"Wrist exoskeletons are increasingly being used in the rehabilitation of stroke and hand dysfunction because of its ability to assist patients in high intensity, repetitive, targeted and interactive rehabilitation training. However, the existing wrist exoskeletons cannot effectively replace the work of therapist and improve hand function, mainly because the existing exoskeletons cannot assist patients to perform natural hand movement covering the entire physiological motor space (PMS). Here, we present a bioelectronic controlled hybrid serial-parallel wrist exoskeleton HrWr-ExoSkeleton (HrWE) which is based on the PMS design guidance, the gear set can carry out forearm pronation/supination (P/S) and the 2-DoF parallel configuration fixed on the gear set can carry out wrist flexion/extension (F/E) and radial/ulnar deviation (R/U). This special configuration not only provides enough range of motion (RoM) for rehabilitation training (85F/85E, 55R/55U, and 90P/90S), but also makes it easier to provide the interface for finger exoskeletons and be adapted to upper limb exoskeletons. In addition, to further improve the rehabilitation effect, we propose a HrWE-assisted active rehabilitation training platform based on surface electromyography signals.",IEEE Transactions on Neural Systems and Rehabilitation Engineering,07 June 2023,2665 - 2675,,37285244,10.1109/TNSRE.2023.3283603,https://doi.org/10.1109/TNSRE.2023.3283603,IEEE
TRUST XAI: Model-Agnostic Explanations for AI With a Case Study on IIoT Security,Maede Zolanvari; Zebo Yang; Khaled Khan; Raj Jain; Nader Meskin; ; ; ; ; ,https://ieeexplore.ieee.org/document/9583587/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9583587,"Despite artificial intelligence (AI)’s significant growth, its “black box” nature creates challenges in generating adequate trust. Thus, it is seldom utilized as a standalone unit in IoT high-risk applications, such as critical industrial infrastructures, medical systems, financial applications, etc. Explainable AI (XAI) has emerged to help with this problem. However, designing appropriately fast and accurate XAI is still challenging, especially in numerical applications. Here, we propose a universal XAI model, named the transparency relying upon statistical theory (TRUST), which is model-agnostic, high performing, and suitable for numerical applications. Simply put, TRUST XAI models the statistical behavior of the AI’s outputs in an AI-based system. Factor analysis is used to transform the input features into a new set of latent variables. We use mutual information (MI) to rank these variables and pick only the most influential ones on the AI’s outputs and call them “representatives” of the classes. Then, we use multimodal Gaussian (MMG) distributions to determine the likelihood of any new sample belonging to each class. We demonstrate the effectiveness of TRUST in a case study on cybersecurity of the Industrial Internet of Things (IIoT) using three different cybersecurity data sets. As IIoT is a prominent application that deals with numerical data. The results show that TRUST XAI provides explanations for new random samples with an average success rate of 98%. Compared with local interpretable model-agnostic explanations (LIME), a popular XAI model, TRUST is shown to be superior in the context of performance, speed, and the method of explainability. In the end, we also show how TRUST is explained to the user.",IEEE Internet of Things Journal,21 October 2021,2967 - 2978,,,10.1109/JIOT.2021.3122019,https://doi.org/10.1109/JIOT.2021.3122019,IEEE
AIDTN: Towards a Real-Time AI Optimized DTN System With NVMeoF,Se-Young Yu; Qingyang Zeng; Jim Chen; Yan Chen; Joe Mambretti; ; ; ; ; ,https://ieeexplore.ieee.org/document/10079144/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10079144,"Large-scale data transport for data-intensive sciences is a complex multidimensional challenge. The challenge includes optimizing the end-to-end Big Data movement performance in real-time, supporting direct remote data access using NVMe over Fabrics (NVMeoF) and deploying to existing research platforms. AIDTN is the first effort to provide a unique AI system designed to incorporate NVMe over Fabrics (NVMeoF) and optimize coordination among multiple components supporting large-scale, multi-domain Wide Area Network (WAN) data-intensive science. AIDTN's research objective is to integrate next-generation storage architecture using NVMeoF, specialized network design using high-performance network appliances, Data Transfer Nodes (DTNs), catalysts in driving data transport, and a unique AI system explicitly designed for high-performance data movement challenges. AIDTN is the first system that uses network and system features to predict the end-to-end performance of high-performance data movement and further extends the model with NVMe-specific features for NVMeoF remote data access. As a result, AIDTN improves data movement performance by up to 284% while minimizing packet loss compared to other heuristics approaches. It also has a prediction error rate as low as 0.16 compared to AI models with the only network (error rate = 0.29) or network and system features (error rate = 0.19).",IEEE Transactions on Parallel and Distributed Systems,23 March 2023,1731 - 1742,,,10.1109/TPDS.2023.3260806,https://doi.org/10.1109/TPDS.2023.3260806,IEEE
"Situation Awareness in AI-Based Technologies and Multimodal Systems: Architectures, Challenges and Applications",Jieli Chen; Kah Phooi Seng; Jeremy Smith; Li-Minn Ang; ; ; ; ,https://ieeexplore.ieee.org/document/10559985/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10559985,"Situation Awareness (SA) is a process of sensing, understanding and predicting the environment and is an important component in complex systems. The reception of information from the environment tends to be continuous and of a multimodal nature. AI technologies provide a more efficient and robust support by subdividing the different stages of SA objectives into tasks such as data fusion, representation, classification, and prediction. This paper provides an overview of AI and multimodal methods used to build, enhance and evaluate SA in a variety of environments and applications. Emphasis is placed on enhancing perceptual integrity and persistence. Research indicates that the integration of artificial intelligence and multimodal approaches has significantly enhanced perception and comprehension in complex systems. However, there remains a research gap in projecting future situations and effectively fusing multimodal information. This paper summarizes some of the use cases and lessons learned where AI and multimodal techniques have been used to deliver SA. Future perspectives and challenges are proposed, including more comprehensive predictions, greater interpretability, and more advanced visual information.",IEEE Access,18 June 2024,88779 - 88818,2169-3536,,10.1109/ACCESS.2024.3416370,https://doi.org/10.1109/ACCESS.2024.3416370,IEEE
Applying Competition-Based Learning to Stimulate Students’ Practical and Competitive AI Ability in a Machine Learning Curriculum,Hui-Tzu Chang; Chia-Yu Lin; ; ,https://ieeexplore.ieee.org/document/10443953/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10443953,"Contribution: This study incorporates competition-based learning (CBL) into machine learning courses. By engaging students in innovative problem-solving challenges within information competitions, revealing that students’ participation in online problem-solving competitions can improve their information technology, and showcase competitions can enhance their competition ability. Background: The CBL model seamlessly integrates project-based learning and competition, placing a strong emphasis on both collective learning and outcomes. This approach cultivates motivation among team members, driving them to enhance their learning and translate knowledge into practical experience. Research Questions: The objective is to examine the disparities in the development of theoretical knowledge, information technology, AI practical ability, and competition ability among students participating in online problem-solving competitions and showcase competitions, and discusses the potential moderating effect of competition type on the relationships between variables in the hypothetical model. Methodology: The study involved 74 students enrolled in machine learning course at a university. The students were given theoretical knowledge and information technology pretests and posttests in the 2nd and 17th weeks, respectively. In the 18th week, the students presented their projects using slideshows and were graded by judges while also submitting their final competition proposal and slides. Findings: Students in online problem-solving competitions can enhance their information technology, while those participating in showcase competitions can improve their competitive ability. Moreover, the competition type was found to moderate the relationships among theoretical knowledge, information technology, and AI model accuracy. The findings suggest that incorporating CBL into machine learning courses effectively cultivates students’ AI practical and competitive abilities.",IEEE Transactions on Education,23 February 2024,256 - 265,,,10.1109/TE.2024.3350535,https://doi.org/10.1109/TE.2024.3350535,IEEE
FPGA-Based AI Smart NICs for Scalable Distributed AI Training Systems,Rui Ma; Evangelos Georganas; Alexander Heinecke; Sergey Gribok; Andrew Boutros; Eriko Nurvitadhi; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9817635/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9817635,"Training state-of-the-art artificial intelligence (AI) models requires scaling to many compute nodes and relies heavily on collective communication operations, such as all-reduce, to exchange the weight gradients between nodes. The overhead of these operations can bottleneck training performance as the number of nodes increases. In this paper, we first characterize the all-reduce operation overhead. Then, we propose a new smart network interface card (NIC) for distributed AI training using field-programmable gate arrays (FPGAs) to accelerate all-reduce operations and optimize bandwidth utilization via data compression. The AI smart NIC frees up the system's compute resources to perform the more compute-intensive tensor operations and increases the overall node-to-node communication efficiency. We build a prototype 6-node AI training system and show that our proposed FPGA-based AI smart NIC enhances overall training performance by 1.6×, with an estimated 2.5× performance improvement at 32 nodes.",IEEE Computer Architecture Letters,07 July 2022,49 - 52,,,10.1109/LCA.2022.3189207,https://doi.org/10.1109/LCA.2022.3189207,IEEE
A Review of Trustworthy and Explainable Artificial Intelligence (XAI),Vinay Chamola; Vikas Hassija; A Razia Sulthana; Debshishu Ghosh; Divyansh Dhingra; Biplab Sikdar; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10188681/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10188681,"The advancement of Artificial Intelligence (AI) technology has accelerated the development of several systems that are elicited from it. This boom has made the systems vulnerable to security attacks and allows considerable bias in order to handle errors in the system. This puts humans at risk and leaves machines, robots, and data defenseless. Trustworthy AI (TAI) guarantees human value and the environment. In this paper, we present a comprehensive review of the state-of-the-art on how to build a Trustworthy and eXplainable AI, taking into account that AI is a black box with little insight into its underlying structure. The paper also discusses various TAI components, their corresponding bias, and inclinations that make the system unreliable. The study also discusses the necessity for TAI in many verticals, including banking, healthcare, autonomous system, and IoT. We unite the ways of building trust in all fragmented areas of data protection, pricing, expense, reliability, assurance, and decision-making processes utilizing TAI in several diverse industries and to differing degrees. It also emphasizes the importance of transparent and post hoc explanation models in the construction of an eXplainable AI and lists the potential drawbacks and pitfalls of building eXplainable AI. Finally, the policies for developing TAI in the autonomous vehicle construction sectors are thoroughly examined and eclectic ways of building a reliable, interpretable, eXplainable, and Trustworthy AI systems are explained to guarantee safe autonomous vehicle systems.",IEEE Access,20 July 2023,78994 - 79015,2169-3536,,10.1109/ACCESS.2023.3294569,https://doi.org/10.1109/ACCESS.2023.3294569,IEEE
CollabLearn: An Uncertainty-Aware Crowd-AI Collaboration System for Cultural Heritage Damage Assessment,Yang Zhang; Ruohan Zong; Ziyi Kou; Lanyu Shang; Dong Wang; ; ; ; ; ,https://ieeexplore.ieee.org/document/9534702/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9534702,"Cultural heritage sites are precious and fragile resources that hold significant historical, esthetic, and social values in our society. However, the increasing frequency and severity of natural and man-made disasters constantly strike the cultural heritage sites with significant damages. In this article, we focus on a cultural heritage damage assessment (CHDA) problem where the goal is to accurately locate the damaged area of a cultural heritage site using the imagery data posted on social media during a disaster event by exploring the collective strengths of both AI and human intelligence from crowdsourcing systems. Unlike other infrastructure-based solutions, social media platforms provide a more pervasive and scalable solution to acquire timely cultural heritage damage information during disaster events. Our work is motivated by the limitation of current AI solutions that fail to accurately model the complex cultural heritage damage due to the lack of essential human cultural knowledge to differentiate various damage types and identify the actual causes of the damage. Two critical technical challenges exist in solving our problem: 1) it is challenging to effectively detect the problematic cultural heritage damage estimation of AI in the absence of ground truth labels and 2) it is nontrivial to acquire accurate cultural background knowledge from the potentially unreliable crowd workers to effectively address the failure cases of AI. To address the above-mentioned challenges, we develop CollabLearn, an uncertainty-aware crowd-AI collaborative assessment system that explicitly explores the human intelligence from crowdsourcing systems to identify and fix AI failure cases and boost the damage assessment accuracy in CHDA applications. The evaluation results on real-world datasets show that CollabLearn consistently outperforms both the state-of-the-art AI-only and crowd-AI hybrid baselines in accurately assessing the damage of several world-renowned cultural heritage ...",IEEE Transactions on Computational Social Systems,09 September 2021,1515 - 1529,,,10.1109/TCSS.2021.3109143,https://doi.org/10.1109/TCSS.2021.3109143,IEEE
An Open API Architecture to Discover the Trustworthy Explanation of Cloud AI Services,Zerui Wang; Yan Liu; Jun Huang; ; ; ,https://ieeexplore.ieee.org/document/10529172/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10529172,"This article presents the design of an open-API-based explainable AI (XAI) service to provide feature contribution explanations for cloud AI services. Cloud AI services are widely used to develop domain-specific applications with precise learning metrics. However, the underlying cloud AI services remain opaque on how the model produces the prediction. We argue that XAI operations are accessible as open APIs to enable the consolidation of the XAI operations into the cloud AI services assessment. We propose a design using a microservice architecture that offers feature contribution explanations for cloud AI services without unfolding the network structure of the cloud models. We can also utilize this architecture to evaluate the model performance and XAI consistency metrics showing cloud AI services’ trustworthiness. We collect provenance data from operational pipelines to enable reproducibility within the XAI service. Furthermore, we present the discovery scenarios for the experimental tests regarding model performance and XAI consistency metrics for the leading cloud vision AI services. The results confirm that the architecture, based on open APIs, is cloud-agnostic. Additionally, data augmentations result in measurable improvements in XAI consistency metrics for cloud AI services.",IEEE Transactions on Cloud Computing,10 May 2024,762 - 776,,,10.1109/TCC.2024.3398609,https://doi.org/10.1109/TCC.2024.3398609,IEEE
Reconceptualizing Self-Directed Learning in the Era of Generative AI: An Exploratory Analysis of Language Learning,Belle Li; Curtis J. Bonk; Chaoran Wang; Xiaojing Kou; ; ; ; ,https://ieeexplore.ieee.org/document/10496545/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10496545,"This exploratory analysis investigates the integration of ChatGPT in self-directed learning (SDL). Specifically, this study examines YouTube content creators’ language-learning experiences and the role of ChatGPT in their SDL, building upon Song and Hill's conceptual model of SDL in online contexts. Thematic analysis of interviews with 19 YouTubers and relevant video contents reveals distinct constructs of ChatGPT-integrated SDL, suggesting a reconceptualization and refinement of the SDL framework in the consideration of generative artificial intelligence (AI). This framework emphasizes critical aspects of utilizing ChatGPT as an SDL tool on two distinct levels: 1) the interactive relationships and interplay between learners’ personal traits and their ongoing learning processes (local) and 2) the evolving nature of SDL in the rapidly advancing landscape of generative AI, with socio-political-cultural foundations of AI constantly shaping the learning environment where SDL occurs (global). The study highlights the potential of ChatGPT as a tool for promoting self-directed language learning (SDLL) and provides implications for the development of learning technologies and research on AI-facilitated SDL.",IEEE Transactions on Learning Technologies,10 April 2024,1515 - 1529,,,10.1109/TLT.2024.3386098,https://doi.org/10.1109/TLT.2024.3386098,IEEE
Automatic Generation of Multimedia Teaching Materials Based on Generative AI: Taking Tang Poetry as an Example,Xu Chen; Di Wu; ; ,https://ieeexplore.ieee.org/document/10474169/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10474169,"Generative artificial intelligence (AI) is widely recognized as one of the most influential technologies for the future, having sparked a paradigm shift in scientific research. The field of education has also been greatly impacted by this transformative technology, with researchers exploring the applications of generative AI, particularly ChatGPT, in education. However, existing research primarily focuses on generating text from text, and there remains a relative scarcity of studies on leveraging multimodal generation capabilities to address key challenges in multimodal data supported instruction. In this article, we present a technical framework for generating Tang poetry situational videos, emphasizing the utilization of generative AI to address the need for multimedia teaching resources. Our framework comprises three main modules: textual situational comprehension, image creation, and video generation. Moreover, we have developed a situational video generation system that incorporates various technologies, including text-to-text generation models, text-to-image generation models, image interpolation, text-to-speech synthesis, and video synthesis. To ascertain the efficacy of the modules within the Tang poetry situational video generation system, we undertook a comparative analysis utilizing the prevalent text-to-image and text-to-video generation models. The empirical findings indicate that our approach is capable of generating images that exhibit greater semantic similarity with the poems, thereby enabling a better comprehension of the poem's connotations and its key components. Concurrently, the Tang poetry videos generated can significantly contribute to the reduction of cognitive load and the enhancement of understanding during the learning process. Our research showcases the potential of generative AI in the education field, specifically in the domain of multimodal teaching resources.",IEEE Transactions on Learning Technologies,18 March 2024,1353 - 1366,,,10.1109/TLT.2024.3378279,https://doi.org/10.1109/TLT.2024.3378279,IEEE
Toward Green AI: A Methodological Survey of the Scientific Literature,Enrico Barbierato; Alice Gatti; ; ,https://ieeexplore.ieee.org/document/10418137/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10418137,"The pervasive deployment of Deep Learning models has recently prompted apprehensions regarding their ecological footprint, owing to the exorbitant levels of energy consumption necessitated by the training and inference processes. The term “Red AI” is employed to denote artificial intelligence (AI) models that undergo training using resource-intensive methodologies on very large datasets. This practice can engender substantial energy usage and emissions of carbon, thereby opposing “Green AI. ” The latter concept alludes to AI models designed for similar efficiency and reduced environmental impact. This objective is realized through the utilization of smaller datasets, less computationally intensive training techniques, or sustainable energy resources. While Red AI prioritizes accuracy and performance, Green AI emphasizes efficiency and sustainability. Given that both paradigms exhibit advantages and limitations, the debates around the topics have burgeoned in the scientific arena, delving into novel algorithms, hardware innovations, and improved data utilization techniques aimed at mitigating the ecological consequences of intricate applications such as GPT and BERT. Nevertheless, due to the relative novelty of this debate, not much effort has been dedicated yet to contextualizing the essence of Red AI and the prospects of Green AI in a coherent framework. Within this context, the present work contributes by meticulously delineating both domains through a multifaceted analysis of their causes and ramifications, described from the points of computer architectures, data structures, and algorithms. Additionally, the study reviews notable instances of study cases based on complex Red AI models. The primary contribution of this article encompasses a comprehensive survey of Red and Green AI, stemming from a selection of the literature performed by the authors, subsequently organized into distinct clusters. These clusters encompass i) articles that qualitatively or quantita...",IEEE Access,31 January 2024,23989 - 24013,2169-3536,,10.1109/ACCESS.2024.3360705,https://doi.org/10.1109/ACCESS.2024.3360705,IEEE
Explainable Artificial Intelligence (XAI) for Methods Working on Point Cloud Data: A Survey,Raju Ningappa Mulawade; Christoph Garth; Alexander Wiebel; ; ; ,https://ieeexplore.ieee.org/document/10704781/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10704781,"In this work, we provide an overview of the XAI (Explainable Artificial Intelligence) works related to explaining the methods working on point cloud (PC) data. The recent decade has seen a surge in artificial intelligence (AI) and machine learning (ML) algorithms finding applications in various fields dealing with a wide variety of data types such as image and text data. Point cloud data is one of these datatypes that has seen an upward trend in the use of AI/ML algorithms. However, not all these AI algorithms are “white box” models that can be understood by humans easily. Many of them are hard to interpret or understand and thus, require methods to provide explanations for the decision-making process. These methods that attempt to provide explanations or insights into the working of AI models working on various datatypes are grouped under XAI. Even though the use of datatypes such as point clouds for AI models has seen an upward trajectory, we see a lack of survey works documenting the developments in the corresponding XAI field. This issue is addressed through our contribution. We classify the literature based on different criteria such as XAI mechanism used, AI models, their tasks, type of model learning and the type of point cloud data taken into consideration. This can help readers identify works that address specific tasks and obtain corresponding details easily. We also provide useful insights regarding the surveyed papers that highlight interesting aspects of the surveyed literature.",IEEE Access,03 October 2024,146830 - 146851,2169-3536,,10.1109/ACCESS.2024.3472872,https://doi.org/10.1109/ACCESS.2024.3472872,IEEE
"Testing and Quality Validation for AI Software–Perspectives, Issues, and Practices",Chuanqi Tao; Jerry Gao; Tiexin Wang; ; ; ,https://ieeexplore.ieee.org/document/8811507/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8811507,"With the fast growth of artificial intelligence and big data computing technologies, more and more software service systems have been developed using diverse machine learning models and technologies to make business and intelligent decisions based on their multimedia input to achieve intelligent features, such as image recognition, recommendation, decision making, prediction, etc. Nevertheless, there are increasing quality problems resulting in erroneous testing costs in enterprises and businesses. Existing work seldom discusses how to perform testing and quality validation for AI software. This paper focuses on quality validation for AI software function features. The paper provides our understanding of AI software testing for new features and requirements. In addition, current AI software testing categories are presented and different testing approaches are discussed. Moreover, test quality assessment and criteria analysis are illustrated. Furthermore, a practical study on quality validation for an image recognition system is performed through a metamorphic testing method. Study results show the feasibility and effectiveness of the approach.",IEEE Access,23 August 2019,120164 - 120175,2169-3536,,10.1109/ACCESS.2019.2937107,https://doi.org/10.1109/ACCESS.2019.2937107,IEEE
"CAVIAR: Co-Simulation of 6G Communications, 3-D Scenarios, and AI for Digital Twins",João Borges; Felipe Bastos; Ilan Correa; Pedro Batista; Aldebaro Klautau; ; ; ; ; ,https://ieeexplore.ieee.org/document/10571791/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10571791,"Digital twins are an important technology for advancing mobile communications, specially in use cases that require simultaneously simulating the wireless channel, 3-D scenes and machine learning (ML). Aiming at contributing towards a solution to this demand, this work describes a modular co-simulation methodology called CAVIAR, for implementing the virtual counterpart of a digital twin (DT) system. Here, CAVIAR is upgraded to support a message passing library and facilitate using different 6G-related simulators. The main contributions of this work are the detailed description of different CAVIAR architectures, the implementation of this methodology to assess a 6G use case of unmanned aerial vehicle (UAV)-based search and rescue (SAR), and the generation of benchmarking data about the computational resource usage. For executing the SAR co-simulation we adopt five open-source solutions: 1) the physical and link level network simulator Sionna; 2) the simulator for autonomous vehicles AirSim; 3) scikit-learn for training a decision tree for multiple input–multiple output (MIMO) beam selection; 4) Yolov8 for the detection of rescue targets; and 5) neural autonomic transport system (NATS) for message passing. Results for the implemented SAR use case suggest that the methodology can run in a single machine, with the main demanded resources being the CPU processing and the GPU memory.",IEEE Internet of Things Journal,25 June 2024,31287 - 31300,,,10.1109/JIOT.2024.3418675,https://doi.org/10.1109/JIOT.2024.3418675,IEEE
The Mario AI Benchmark and Competitions,Sergey Karakovskiy; Julian Togelius; ; ,https://ieeexplore.ieee.org/document/6156425/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6156425,"This paper describes the Mario AI benchmark, a game-based benchmark for reinforcement learning algorithms and game AI techniques developed by the authors. The benchmark is based on a public domain clone of Nintendo's classic platform game Super Mario Bros, and completely open source. During the last two years, the benchmark has been used in a number of competitions associated with international conferences, and researchers and students from around the world have contributed diverse solutions to try to beat the benchmark. The paper summarizes these contributions, gives an overview of the state of the art in Mario-playing AIs, and chronicles the development of the benchmark. This paper is intended as the definitive point of reference for those using the benchmark for research or teaching.",IEEE Transactions on Computational Intelligence and AI in Games,22 February 2012,55 - 67,,,10.1109/TCIAIG.2012.2188528,https://doi.org/10.1109/TCIAIG.2012.2188528,IEEE
Applicability of GPGPU Computing to Real-Time AI Solutions in Games,William Blewitt; Gary Ushaw; Graham Morgan; ; ; ,https://ieeexplore.ieee.org/document/6502211/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6502211,"This paper reviews developments in general purpose computing on graphics processor units (GPGPU computing) from the perspective of video-game-related artificial intelligence (AI). We present an overview of the field, beginning with early shader language solutions and continuing to discuss three accessible platforms for GPGPU development: CUDA, OpenCL, and Direct Compute. Consideration is given to the commercial and practical realities which hinder the adoption of GPGPU solutions within video game AI, and developments in GPGPU computing directly relevant to common AI practices within the video games industry are reviewed in depth.",IEEE Transactions on Computational Intelligence and AI in Games,15 April 2013,265 - 275,,,10.1109/TCIAIG.2013.2258156,https://doi.org/10.1109/TCIAIG.2013.2258156,IEEE
Collaborative Edge AI Inference Over Cloud-RAN,Pengfei Zhang; Dingzhu Wen; Guangxu Zhu; Qimei Chen; Kaifeng Han; Yuanming Shi; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10499876/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10499876,"In this paper, a cloud radio access network (Cloud-RAN) based collaborative edge AI inference architecture is proposed. Specifically, geographically distributed devices capture real-time noise-corrupted sensory data samples and extract the noisy local feature vectors, which are then aggregated at each remote radio head (RRH) to suppress sensing noise. To realize efficient uplink feature aggregation, we allow each RRH receives local feature vectors from all devices over the same resource blocks simultaneously by leveraging an over-the-air computation (AirComp) technique. Thereafter, these aggregated feature vectors are quantized and transmitted to a central processor (CP) for further aggregation and downstream inference tasks. Our aim in this work is to maximize the inference accuracy via a surrogate accuracy metric called discriminant gain, which measures the discernibility of different classes in the feature space. The key challenges lie on simultaneously suppressing the coupled sensing noise, AirComp distortion caused by hostile wireless channels, and the quantization error resulting from the limited capacity of fronthaul links. To address these challenges, this work proposes a joint transmit precoding, receive beamforming, and quantization error control scheme to enhance the inference accuracy. Extensive numerical experiments demonstrate the effectiveness and superiority of our proposed optimization algorithm compared to various baselines.",IEEE Transactions on Communications,15 April 2024,5641 - 5656,,,10.1109/TCOMM.2024.3388488,https://doi.org/10.1109/TCOMM.2024.3388488,IEEE
Compressing Features for Learning With Noisy Labels,Yingyi Chen; Shell Xu Hu; Xi Shen; Chunrong Ai; Johan A. K. Suykens; ; ; ; ; ,https://ieeexplore.ieee.org/document/9819959/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9819959,"Supervised learning can be viewed as distilling relevant information from input data into feature representations. This process becomes difficult when supervision is noisy as the distilled information might not be relevant. In fact, recent research shows that networks can easily overfit all labels including those that are corrupted, and hence can hardly generalize to clean datasets. In this article, we focus on the problem of learning with noisy labels and introduce compression inductive bias to network architectures to alleviate this overfitting problem. More precisely, we revisit one classical regularization named Dropout and its variant Nested Dropout. Dropout can serve as a compression constraint for its feature dropping mechanism, while Nested Dropout further learns ordered feature representations with respect to feature importance. Moreover, the trained models with compression regularization are further combined with co-teaching for performance boost. Theoretically, we conduct bias variance decomposition of the objective function under compression regularization. We analyze it for both single model and co-teaching. This decomposition provides three insights: 1) it shows that overfitting is indeed an issue in learning with noisy labels; 2) through an information bottleneck formulation, it explains why the proposed feature compression helps in combating label noise; and 3) it gives explanations on the performance boost brought by incorporating compression regularization into co-teaching. Experiments show that our simple approach can have comparable or even better performance than the state-of-the-art methods on benchmarks with real-world label noise including Clothing1M and ANIMAL-10N. Our implementation is available at https://yingyichen-cyy.github.io/CompressFeatNoisyLabels/ .",IEEE Transactions on Neural Networks and Learning Systems,08 July 2022,2124 - 2138,,35802546,10.1109/TNNLS.2022.3186930,https://doi.org/10.1109/TNNLS.2022.3186930,IEEE
Advancing Fake News Detection: Hybrid Deep Learning With FastText and Explainable AI,Ehtesham Hashmi; Sule Yildirim Yayilgan; Muhammad Mudassar Yamin; Subhan Ali; Mohamed Abomhara; ; ; ; ; ,https://ieeexplore.ieee.org/document/10477989/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10477989,"The widespread propagation of misinformation on social media platforms poses a significant concern, prompting substantial endeavors within the research community to develop robust detection solutions. Individuals often place unwavering trust in social networks, often without discerning the origins and authenticity of the information disseminated through these platforms. Hence, the identification of media-rich fake news necessitates an approach that adeptly leverages multimedia elements and effectively enhances detection accuracy. The ever-changing nature of cyberspace highlights the need for measures that may effectively resist the spread of media-rich fake news while protecting the integrity of information systems. This study introduces a robust approach for fake news detection, utilizing three publicly available datasets: WELFake, FakeNewsNet, and FakeNewsPrediction. We integrated FastText word embeddings with various Machine Learning and Deep Learning methods, further refining these algorithms with regularization and hyperparameter optimization to mitigate overfitting and promote model generalization. Notably, a hybrid model combining Convolutional Neural Networks and Long Short-Term Memory, enriched with FastText embeddings, surpassed other techniques in classification performance across all datasets, registering accuracy and F1-scores of 0.99, 0.97, and 0.99, respectively. Additionally, we utilized state-of-the-art transformer-based models such as BERT, XLNet, and RoBERTa, enhancing them through hyperparameter adjustments. These transformer models, surpassing traditional RNN-based frameworks, excel in managing syntactic nuances, thus aiding in semantic interpretation. In the concluding phase, explainable AI modeling was employed using Local Interpretable Model-Agnostic Explanations, and Latent Dirichlet Allocation to gain deeper insights into the model’s decision-making process.",IEEE Access,25 March 2024,44462 - 44480,2169-3536,,10.1109/ACCESS.2024.3381038,https://doi.org/10.1109/ACCESS.2024.3381038,IEEE
Explainable AI for Cyber-Physical Systems: Issues and Challenges,Amber Hoenig; Kaushik Roy; Yaa Takyiwaa Acquaah; Sun Yi; Salil S. Desai; ; ; ; ; ,https://ieeexplore.ieee.org/document/10516690/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10516690,"Artificial intelligence and cyber-physical systems (CPS) are two of the key technologies of the future that are enabling major global shifts. However, most of the current implementations of AI in CPS are not explainable, which creates serious problems in ethical, legal, regulatory, and other domains. Therefore, it is necessary for explainable artificial intelligence (XAI) to be integrated with cyber-physical systems to meet the vital needs for control, fairness, accountability, safety, cyber-resilience, and cybersecurity. The goal of this review is to demonstrate the need, benefits, challenges, and implementation of XAI for CPS. We review the existing literature about XAI and CPS, discuss the current state of the art, examine applications in different domains, and make recommendations for future research directions. To the best of our knowledge, this is the first peer-reviewed academic article to provide a comprehensive review of general XAI for CPS. We also contribute new research ideas including development of multisensory explanations and outputs for these systems, application of XAI to CPS to decrease occupational burnout and increase employee engagement, and enumeration of the multidisciplinary goals and benefits of XAI as applied to cyber-physical systems.",IEEE Access,01 May 2024,73113 - 73140,2169-3536,,10.1109/ACCESS.2024.3395444,https://doi.org/10.1109/ACCESS.2024.3395444,IEEE
Advancing Ovarian Cancer Diagnosis Through Deep Learning and eXplainable AI: A Multiclassification Approach,Meera Radhakrishnan; Niranjana Sampathila; H. Muralikrishna; K. S. Swathi; ; ; ; ,https://ieeexplore.ieee.org/document/10643508/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10643508,"Ovarian cancer is a dangerous gynaecological malignancy, and the presence of many subtypes causes significant diagnostic difficulties. In general, the high accuracy of classification results in adequate prognosis and effectiveness of treatment. This work aims at the development of a Deep Learning (DL) approach for subtypes of ovarian cancer multiclassification, which tries to solve the problem of the creation of precise and reliable diagnostic methods. In the work, we have used and explored various DL models such as MobileNetV2, VGG19, ResNet18, ResNeXt, Xception, EfficientNet, and InceptionV3 to perform the classification task. Further, we used the state-of-the-art eXplainable Artificial Intelligence methods, including integrated gradient, saliency map, Grad-CAM, and DeepLift, to improve model interpretability. From our experiments, we inferred that the highest accuracy was achieved by InceptionV3, with a value of 97.96%. XAI techniques incorporated provide transparent insights into the model’s operations during the decision-making process, thus increasing the level of trust and clinical usability. The proposed DL approach, by leveraging InceptionV3 as its top performer, has convincingly demonstrated the potential of AI to revolutionize the diagnosis of ovarian cancer through a high level of accuracy in subtype classification. XAI techniques integrated allow transparency support for the model and further enable its clinical adoption. All of these developments have significant potential for improved patient outcomes within the scope of personalized medicine in ovarian cancer treatment.",IEEE Access,22 August 2024,116968 - 116986,2169-3536,,10.1109/ACCESS.2024.3448219,https://doi.org/10.1109/ACCESS.2024.3448219,IEEE
Blockchain and AI-Based Solutions to Combat Coronavirus (COVID-19)-Like Epidemics: A Survey,Dinh C. Nguyen; Ming Ding; Pubudu N. Pathirana; Aruna Seneviratne; ; ; ; ,https://ieeexplore.ieee.org/document/9468676/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9468676,"The beginning of 2020 has seen the emergence of coronavirus outbreak caused by a novel virus called SARS-CoV-2. The sudden explosion and uncontrolled worldwide spread of COVID-19 show the limitations of existing healthcare systems in timely handling public health emergencies. In such contexts, innovative technologies such as blockchain and Artificial Intelligence (AI) have emerged as promising solutions for fighting coronavirus epidemic. In particular, blockchain can combat pandemics by enabling early detection of outbreaks, ensuring the ordering of medical data, and ensuring reliable medical supply chain during the outbreak tracing. Moreover, AI provides intelligent solutions for identifying symptoms caused by coronavirus for treatments and supporting drug manufacturing. Therefore, we present an extensive survey on the use of blockchain and AI for combating COVID-19 epidemics. First, we introduce a new conceptual architecture which integrates blockchain and AI for fighting COVID-19. Then, we survey the latest research efforts on the use of blockchain and AI for fighting COVID-19 in various applications. The newly emerging projects and use cases enabled by these technologies to deal with coronavirus pandemic are also presented. A case study is also provided using federated AI for COVID-19 detection. Finally, we point out challenges and future directions that motivate more research efforts to deal with future coronavirus-like epidemics.",IEEE Access,30 June 2021,95730 - 95753,2169-3536,34812398,10.1109/ACCESS.2021.3093633,https://doi.org/10.1109/ACCESS.2021.3093633,IEEE
AI Agent in Software-Defined Network: Agent-Based Network Service Prediction and Wireless Resource Scheduling Optimization,Yong Cao; Rui Wang; Min Chen; Ahmed Barnawi; ; ; ; ,https://ieeexplore.ieee.org/document/8888257/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8888257,"With the development of software-defined network (SDN), there will be a large number of devices to access network, which may cause an incalculable burden to the communication network. In addition, due to the high bandwidth in the fifth-generation (5G) era, innovation will occur in different fields. There are not only strict requirements on the communication capability of SDN for these application scenarios but also a lot of computing resources. For massive access devices, it is difficult for the traditional service resource scheduling and the allocation system to meet user demand growth. To address the above-stated problems, an artificial intelligence agent (AI Agent) system is put forth in this article. AI Agents can be deployed in different layers of the SDN, thus realizing functions like network service prediction and resource scheduling. A brand new AI Agent framework is designed, and an AI algorithm is adopted to replace the traditional service prediction and resource scheduling strategies. In the meantime, a relevant agent deployment scheme is put forward. Finally, an AI Agent-based simulation experiment for resource scheduling is designed, and the accuracy in network service prediction and rationality in resource allocation based on this framework are tested. The experimental result showed that the operation efficiency of the SDN can be effectively improved, and the resource hit ratio and user service quality may be improved with AI-agent-based traffic prediction and resource allocation model.",IEEE Internet of Things Journal,31 October 2019,5816 - 5826,,,10.1109/JIOT.2019.2950730,https://doi.org/10.1109/JIOT.2019.2950730,IEEE
Employing Hybrid AI Systems to Trace and Document Bias in ML Pipelines,Mayra Russo; Yasharajsinh Chudasama; Disha Purohit; Sammy Sawischa; Maria-Esther Vidal; ; ; ; ; ,https://ieeexplore.ieee.org/document/10596297/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10596297,"Artificial Intelligence (AI) systems can introduce biases that lead to unreliable outcomes and, in the worst-case scenarios, perpetuate systemic and discriminatory results when deployed in the real world. While significant efforts have been made to create bias detection methods, developing reliable and comprehensive documentation artifacts also makes for valuable resources that address bias and aid in minimizing the harms associated with AI systems. Based on compositional design patterns, this paper introduces a documentation approach using a hybrid AI system to prompt the identification and traceability of bias in datasets and predictive AI models. To demonstrate the effectiveness of our approach, we instantiate our pattern in two implementations of a hybrid AI system. One follows an integrated approach and performs fine-grained tracing and documentation of the AI model. In contrast, the other hybrid system follows a principled approach and enables the documentation and comparison of bias in the input data and the predictions generated by the model. Through a use-case based on Fake News detection and an empirical evaluation, we show how biases detected during data ingestion steps (e.g., label, over-representation, activity bias) affect the training and predictions of the classification models. Concretely, we report a stark skewness in the distribution of input variables towards the Fake News label, we uncover how a predictive variable leads to more constraints in the learning process, and highlight open challenges of training models with unbalanced datasets. A video summarizing this work is available online ( https://youtu.be/v2GfIQPAy_4?si=BXtWOf97cLiZavyu ),and the implementation is publicly available on GitHub ( https://github.com/SDM-TIB/DocBiasKG ).",IEEE Access,12 July 2024,96821 - 96847,2169-3536,,10.1109/ACCESS.2024.3427388,https://doi.org/10.1109/ACCESS.2024.3427388,IEEE
Diffusion-Based Reinforcement Learning for Edge-Enabled AI-Generated Content Services,Hongyang Du; Zonghang Li; Dusit Niyato; Jiawen Kang; Zehui Xiong; Huawei Huang; Shiwen Mao; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10409284/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10409284,"As Metaverse emerges as the next-generation Internet paradigm, the ability to efficiently generate content is paramount. AI-Generated Content (AIGC) emerges as a key solution, yet the resource-intensive nature of large Generative AI (GAI) models presents challenges. To address this issue, we introduce an AIGC-as-a-Service (AaaS) architecture, which deploys AIGC models in wireless edge networks to ensure broad AIGC services accessibility for Metaverse users. Nonetheless, an important aspect of providing personalized user experiences requires carefully selecting AIGC Service Providers (ASPs) capable of effectively executing user tasks, which is complicated by environmental uncertainty and variability. Addressing this gap in current research, we introduce the AI-Generated Optimal Decision (AGOD) algorithm, a diffusion model-based approach for generating the optimal ASP selection decisions. Integrating AGOD with Deep Reinforcement Learning (DRL), we develop the Deep Diffusion Soft Actor-Critic (D2SAC) algorithm, enhancing the efficiency and effectiveness of ASP selection. Our comprehensive experiments demonstrate that D2SAC outperforms seven leading DRL algorithms. Furthermore, the proposed AGOD algorithm has the potential for extension to various optimization problems in wireless networks, positioning it as a promising approach for future research on AIGC-driven services.",IEEE Transactions on Mobile Computing,19 January 2024,8902 - 8918,,,10.1109/TMC.2024.3356178,https://doi.org/10.1109/TMC.2024.3356178,IEEE
ARTS: A Framework for AI-Rooted IoT System Design Automation,Prabuddha Chakraborty; Reiner N. Dizon-Paradis; Swarup Bhunia; ; ; ,https://ieeexplore.ieee.org/document/9732465/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9732465,"IoT systems are used for performing a variety of essential tasks in wide-ranging sectors, such as healthcare, smart cities, agriculture, and industrial automation. Most of these systems incorporate smartness for intelligent decision making using artificial intelligence (AI) approaches. To reduce the network bandwidth usage and load on the cloud server, there is a push to relegate most of these AI-related computations to edge IoT devices/systems. Hence, to ensure good performance, the edge devices must be systematically designed with an emphasis on the respective AI requirements from exploration to deployment. State-of-the-art IoT device and system design practices place little importance on the AI specifications during the early stages of the system development resulting in systems, which are unable to meet the AI specifications without additional redesigning and optimization efforts. In this letter, we propose an automated framework for AI-rooted IoT system design approach, where the AI specifications play a vital role in deciding the system components, design, and implementation from a very early stage of the design life cycle. The proposed framework employs an expert system and a machine-readable knowledge-base to automate the design process. Using a set of case studies, we demonstrate the benefits of the proposed framework.",IEEE Embedded Systems Letters,10 March 2022,151 - 154,,,10.1109/LES.2022.3158565,https://doi.org/10.1109/LES.2022.3158565,IEEE
Letter to the Editor: “How Can Biomedical Engineers Help Empower Individuals With Intellectual Disabilities? The Potential Benefits and Challenges of AI Technologies to Support Inclusivity and Transform Lives”,Alessandro Di Nuovo; ,https://ieeexplore.ieee.org/document/10314515/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10314515,"The rapid advancement of Artificial Intelligence (AI) is transforming healthcare and daily life, offering great opportunities but also posing ethical and societal challenges. To ensure AI benefits all individuals, including those with intellectual disabilities, the focus should be on adaptive technology that can adapt to the unique needs of the user. Biomedical engineers have an interdisciplinary background that helps them to lead multidisciplinary teams in the development of human-centered AI solutions. These solutions can personalize learning, enhance communication, and improve accessibility for individuals with intellectual disabilities. Furthermore, AI can aid in healthcare research, diagnostics, and therapy. The ethical use of AI in healthcare and the collaboration of AI with human expertise must be emphasized. Public funding for inclusive research is encouraged, promoting equity and economic growth while empowering those with intellectual disabilities in society.",IEEE Journal of Translational Engineering in Health and Medicine,09 November 2023,256 - 257,2168-2372,38196818,10.1109/JTEHM.2023.3331977,https://doi.org/10.1109/JTEHM.2023.3331977,IEEE
Filling the Missing: Exploring Generative AI for Enhanced Federated Learning Over Heterogeneous Mobile Edge Devices,Peichun Li; Hanwen Zhang; Yuan Wu; Liping Qian; Rong Yu; Dusit Niyato; Xuemin Shen; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10454003/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10454003,"Distributed Artificial Intelligence (AI) model training over mobile edge networks encounters significant challenges due to the data and resource heterogeneity of edge devices. The former hampers the convergence rate of the global model, while the latter diminishes the devices’ resource utilization efficiency. In this paper, we propose a generative AI-empowered federated learning to address these challenges by leveraging the idea of FIlling the MIssing (FIMI) portion of local data. Specifically, FIMI can be considered as a resource-aware data augmentation method that effectively mitigates the data heterogeneity while ensuring efficient FL training. We first quantify the relationship between the training data amount and the learning performance. We then study the FIMI optimization problem with the objective of minimizing the device-side overall energy consumption subject to required learning performance constraints. The decomposition-based analysis and the cross-entropy searching method are leveraged to derive the solution, where each device is assigned suitable AI-synthetic data and resource utilization policy. Experiment results demonstrate that FIMI can save up to 50% of the device-side energy to achieve the target global test accuracy in comparison with the existing methods. Meanwhile, FIMI can significantly enhance the converged global accuracy under the non-independently-and-identically distribution (non-IID) data.",IEEE Transactions on Mobile Computing,29 February 2024,10001 - 10015,,,10.1109/TMC.2024.3371772,https://doi.org/10.1109/TMC.2024.3371772,IEEE
Hybrid Signed Convolution Module With Unsigned Divide-and-Conquer Multiplier for Energy-Efficient STT-MRAM-Based AI Accelerator,Tao Li; Yitao Ma; Ko Yoshikawa; Tetsuo Endoh; ; ; ; ,https://ieeexplore.ieee.org/document/10050403/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10050403,"A hybrid signed convolution module with the architecture of an unsigned divide-and-conquer (UDC) multiplier is proposed to improve the functional diversity and energy efficiency of artificial intelligence (AI) accelerators based on spin-transfer-torque magnetic random access memory (STT-MRAM). The proposed UDC multiplier framework enables three multiplication modes ( n \times n , n \times n /2, and n/2\times n /2 bit), considerably enhancing the multiplier’s versatility for next-generation AI accelerators. Compared to the state-of-the-art convolution accelerators, the UDC multiplier-based convolution module offers the lowest average power consumption for 8\times8 bit convolution. By deploying power-gating technology on STT-MRAM, the proposed convolution module preserves sufficient accuracy in high-bit multiplication while decreasing energy consumption by a factor of 22. Furthermore, incorporating a hybrid convolution module improves power efficiency by an additional 8\times , culminating in a 175\times decrease in power efficiency for an STT-MRAM-based AI accelerator.",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,22 February 2023,1078 - 1082,,,10.1109/TVLSI.2023.3245099,https://doi.org/10.1109/TVLSI.2023.3245099,IEEE
Design of Efficient AI Accelerator Building Blocks in Quantum-Dot Cellular Automata (QCA),Ahmed Mamdouh; Mbonea Mjema; Gurtac Yemiscioglu; Satoshi Kondo; Ali Muhtaroglu; ; ; ; ; ,https://ieeexplore.ieee.org/document/9868024/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9868024,"Digital circuit design technologies based on Quantum-Dot Cellular Automata (QCA) have many advantages over CMOS, such as higher intrinsic switching speed up to Terahertz, lower power consumption, smaller circuit footprint, and higher throughput due to compatibility of the inherent signal propagation scheme with pipelining. Hence, QCA is a perfect candidate to provide a circuit design framework for applications such as Artificial Intelligence (AI) accelerators, where real-time energy-efficient performance needs to be delivered at low cost. A novel QCA design approach based on optimal mix of Majority and NAND-NOR-INVERTER (NNI) gates with USE (Universal, Scalable, Efficient) clocking scheme, has been investigated in this work for latency and energy consumption improvements to fundamental building blocks in AI-accelerators, including multipliers, adders, accumulators and SRAMs. The common $4\times 4$ Vedic multiplier has been redesigned using the proposed approach, and simulated to yield 62.8% reduction in cell count, 82.2% reduction in area, and 71.2% reduction in latency. 83% reduction in cell count, 94.5% reduction in area, and 94.6% reduction in latency was simulated for the proposed 8-bit PIPO register. The proposed SRAM cell design is estimated to have similar improvement figures to those achieved by the sub-blocks, such as the D-Latch, which has been simulated to exhibit 44.4% reduction in cell count, 50% reduction in both area and latency, and 73% reduction in energy dissipation. The contributions from this work can be directly applied to low cost, high throughput, energy efficient AI-accelerators that can potentially deliver orders of magnitude better energy-delay characteristics than their CMOS counterparts, and significantly better energy-delay characteristics than state-of-the-art QCA implementations.",IEEE Journal on Emerging and Selected Topics in Circuits and Systems,26 August 2022,703 - 712,,,10.1109/JETCAS.2022.3202043,https://doi.org/10.1109/JETCAS.2022.3202043,IEEE
A Canonical Data Transformation for Achieving Inter- and Within-Group Fairness,Zachary McBride Lazri; Ivan Brugere; Xin Tian; Dana Dachman-Soled; Antigoni Polychroniadou; Danial Dervovic; Min Wu; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10559875/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10559875,"Increases in the deployment of machine learning algorithms for applications that deal with sensitive data have brought attention to the issue of fairness in machine learning. Many works have been devoted to applications that require different demographic groups to be treated fairly. However, algorithms that aim to satisfy inter-group fairness (also called group fairness) may inadvertently treat individuals within the same demographic group unfairly. To address this issue, this article introduces a formal definition of within-group fairness that maintains fairness among individuals from within the same group. A pre-processing framework is proposed to meet both inter- and within-group fairness criteria with little compromise in performance. The framework maps the feature vectors of members from different groups to an inter-group fair canonical domain before feeding them into a scoring function. The mapping is constructed to preserve the relative relationship between the scores obtained from the unprocessed feature vectors of individuals from the same demographic group, guaranteeing within-group fairness. This framework has been applied to the Adult, COMPAS risk assessment, and Law School datasets, and its performance is demonstrated and compared with two regularization-based methods in achieving inter-group and within-group fairness.",IEEE Transactions on Information Forensics and Security,17 June 2024,7449 - 7464,,,10.1109/TIFS.2024.3416040,https://doi.org/10.1109/TIFS.2024.3416040,IEEE
Flight Price Prediction Web-Based Platform: Leveraging Generative AI for Real-Time Airfare Forecasting,Yuanyuan Guan; ,https://ieeexplore.ieee.org/document/10504110/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10504110,"The aviation business encounters difficulties in correctly and swiftly predicting flight fares due to the dynamic nature of the sector. Factors such as variations in demand, fuel costs, and the intricacies of various routes have an impact on this. This work presents a new method to tackle this issue by utilizing generative artificial intelligence (GAI) approaches to accurately forecast airfares in real-time. This paper presents a novel framework that integrates generative models, deep learning architectures, and historical pricing data to improve the precision of future flight price predictions. The study employs a GAI within a cutting-edge web engineering framework. This approach is designed primarily to gather knowledge about complex patterns and relationships present in historical airline data. Through the utilization of this methodology, the model is able to accurately perceive complex connections and adjust to ever-changing market conditions. Our model utilizes deep neural networks to effectively handle various circumstances and extract vital information, so facilitating a comprehensive comprehension of the intricate elements that impact flight cost. Moreover, the suggested approach places significant emphasis on precisely predicting upcoming occurrences in real-time, facilitating prompt reactions to market volatility and offering a valuable resource for airlines, travel agents, and customers alike. In order to enhance the accuracy of real-time forecasts, we utilize a web-based platform that allows for smooth interaction with live data streams and guarantees swift updates. The results demonstrate the model's capacity to adjust to dynamic market conditions, rendering it an attractive option for stakeholders in search of precise and current forecasts of flight prices.",Journal of Web Engineering,March 2024,299 - 314,,,10.13052/jwe1540-9589.2325,https://doi.org/10.13052/jwe1540-9589.2325,River Publishers
Generative Artificial Intelligence Assisted Wireless Sensing: Human Flow Detection in Practical Communication Environments,Jiacheng Wang; Hongyang Du; Dusit Niyato; Zehui Xiong; Jiawen Kang; Bo Ai; Zhu Han; Dong In Kim; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10557650/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10557650,"Groundbreaking applications such as ChatGPT have heightened research interest in generative artificial intelligence (GAI). Essentially, GAI excels not only in content generation but also signal processing, offering support for wireless sensing. Hence, we introduce a novel GAI-assisted human flow detection system (G-HFD). Rigorously, G-HFD first uses the channel state information (CSI) to estimate the velocity and acceleration of propagation path length change of the human induced reflection (HIR). Then, given the strong inference ability of the diffusion model, we propose a unified weighted conditional diffusion model (UW-CDM) to denoise the estimation results, enabling detection of the number of targets. Next, we use the CSI obtained by a uniform linear array with wavelength spacing to estimate the HIR’s time of flight and direction of arrival (DoA). In this process, UW-CDM solves the problem of ambiguous DoA spectrum, ensuring accurate DoA estimation. Finally, through clustering, G-HFD determines the number of subflows and the number of targets in each subflow, i.e., the subflow size. The evaluation based on practical downlink communication signals shows G-HFD’s accuracy of subflow size detection can reach 91%. This validates its effectiveness and underscores the significant potential of GAI in the context of wireless sensing.",IEEE Journal on Selected Areas in Communications,14 June 2024,2737 - 2753,,,10.1109/JSAC.2024.3414628,https://doi.org/10.1109/JSAC.2024.3414628,IEEE
Transformer Network Based Channel Prediction for CSI Feedback Enhancement in AI-Native Air Interface,Tao Zhou; Xiangping Liu; Zuowei Xiang; Haitong Zhang; Bo Ai; Liu Liu; Xiaorong Jing; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10480335/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10480335,"With the development of artificial intelligence (AI), wireless channel prediction based on deep learning (DL) has become a hot research issue. Channel prediction plays an important role in channel state information (CSI) feedback enhancement in AI-native air interface. To better predict the CSI, this paper investigates the Transformer network based channel prediction. Firstly, real channel data are obtained in Beijing-Tianjin railway line, and the channel prediction datasets are constructed through preprocessing. After formulating the channel prediction problem, a channel prediction model based on the Transformer network is newly proposed. The unique multi-head attention mechanism and position encoding of the Transformer network enable the proposed model to have more powerful parallel computation capability and better global information capture capability. Then, the hyper-parameters of the model are determined by autocorrelation analysis and cross-validation. Finally, the performance of the proposed model is evaluated in terms of prediction accuracy and space and time computational complexity using several evaluation metrics, and is compared with classical DL models. It is shown that the proposed model possesses higher prediction performance in the appropriate range of computational complexity.",IEEE Transactions on Wireless Communications,26 March 2024,11154 - 11167,,,10.1109/TWC.2024.3379123,https://doi.org/10.1109/TWC.2024.3379123,IEEE
Explainable AI for Healthcare 5.0: Opportunities and Challenges,Deepti Saraswat; Pronaya Bhattacharya; Ashwin Verma; Vivek Kumar Prasad; Sudeep Tanwar; Gulshan Sharma; Pitshou N. Bokoro; Ravi Sharma; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9852458/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9852458,"In the healthcare domain, a transformative shift is envisioned towards Healthcare 5.0. It expands the operational boundaries of Healthcare 4.0 and leverages patient-centric digital wellness. Healthcare 5.0 focuses on real-time patient monitoring, ambient control and wellness, and privacy compliance through assisted technologies like artificial intelligence (AI), Internet-of-Things (IoT), big data, and assisted networking channels. However, healthcare operational procedures, verifiability of prediction models, resilience, and lack of ethical and regulatory frameworks are potential hindrances to the realization of Healthcare 5.0. Recently, explainable AI (EXAI) has been a disruptive trend in AI that focuses on the explainability of traditional AI models by leveraging the decision-making of the models and prediction outputs. The explainability factor opens new opportunities to the black-box models and brings confidence in healthcare stakeholders to interpret the machine learning (ML) and deep learning (DL) models. EXAI is focused on improving clinical health practices and brings transparency to the predictive analysis, which is crucial in the healthcare domain. Recent surveys on EXAI in healthcare have not significantly focused on the data analysis and interpretation of models, which lowers its practical deployment opportunities. Owing to the gap, the proposed survey explicitly details the requirements of EXAI in Healthcare 5.0, the operational and data collection process. Based on the review method and presented research questions, systematically, the article unfolds a proposed architecture that presents an EXAI ensemble on the computerized tomography (CT) image classification and segmentation process. A solution taxonomy of EXAI in Healthcare 5.0 is proposed, and operational challenges are presented. A supported case study on electrocardiogram (ECG) monitoring is presented that preserves the privacy of local models via federated learning (FL) and EXAI for metric vali...",IEEE Access,08 August 2022,84486 - 84517,2169-3536,,10.1109/ACCESS.2022.3197671,https://doi.org/10.1109/ACCESS.2022.3197671,IEEE
Data-Driven Early Diagnosis of Chronic Kidney Disease: Development and Evaluation of an Explainable AI Model,Pedro A. Moreno-Sánchez; ,https://ieeexplore.ieee.org/document/10091536/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10091536,"Chronic Kidney Disease (CKD) is currently experiencing a growing worldwide incidence and can lead to premature mortality if diagnosed late, resulting in rising costs to healthcare systems. Artificial Intelligence (AI) and Machine Learning (ML) offer the possibility of an early diagnosis of CKD that could revert further kidney damage. However, clinicians may be hesitant to adopt AI models if the reasoning behind the predictions is not understandable. Since eXplainable AI (XAI) addresses the clinicians’ requirement of understanding AI models’ output, this work presents the development and evaluation of an explainable CKD prediction model that provides information about how different patient’s clinical features contribute to CKD early diagnosis. The model was developed using an optimization framework that balances classification accuracy and explainability. The main contribution of the paper lies in an explainable data-driven approach to offer quantitative information about the contribution of certain clinical features in the early diagnosis of CKD. As a result, the optimal explainable prediction model implements an extreme gradient boosting classifier using 3 features (hemoglobin, specific gravity, and hypertension) with an accuracy of 99.2% (standard deviation 0.8) and 97.5% with a 5-fold cross-validation and with new unseen data respectively. In addition, an explainability analysis shows that hemoglobin is the most relevant feature that influences the prediction, followed by specific gravity and hypertension. This small number of features selected results in a reduced cost of the early diagnosis of CKD implying a promising solution for developing countries.",IEEE Access,03 April 2023,38359 - 38369,2169-3536,,10.1109/ACCESS.2023.3264270,https://doi.org/10.1109/ACCESS.2023.3264270,IEEE
AI Ethics: Algorithmic Determinism or Self-Determination? The GPDR Approach,Maria Milossi; Eugenia Alexandropoulou-Egyptiadou; Konstantinos E. Psannis; ; ; ,https://ieeexplore.ieee.org/document/9400809/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9400809,"Artificial Intelligence (AI) refers to systems designed by humans, interpreting the already collected data and deciding the best action to take, according to the pre-defined parameters, in order to achieve the given goal. Designing, trial and error while using AI, brought ethics to the center of the dialogue between tech giants, enterprises, academic institutions as well as policymakers. Ethical challenges in AI brought ethical AI framework in place in an attempt to regulate people’s lives and interactions, used for the benefit of society, for the human rights’ protection as well as for the respect of individual’s privacy and autonomy. The paper aims to summarize and critically evaluate the basic principles for the use of AI, with emphasis to the General Data Protection Regulation’s (GDPR) approach, concerning data subject’s consent, data protection principles and data subject’s rights in a context of ‘privacy by design’ architecture.",IEEE Access,12 April 2021,58455 - 58466,2169-3536,,10.1109/ACCESS.2021.3072782,https://doi.org/10.1109/ACCESS.2021.3072782,IEEE
Toward Efficient Data Trading in AI Enabled Reconfigurable Wireless Sensor Network Using Contract and Game Theories,Xumin Huang; Sahil Garg; Jiangtian Nie; Wei Yang Bryan Lim; Yuanhang Qi; Yang Zhang; M. Shamim Hossain; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9153170/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9153170,"Reconfigurable Wireless Sensor Network (RWSN) schedules a set of devices with reconfigurable wireless interface to accomplish different data collection plans in a cost-effective way. AI technologies are applied to optimize decision making for high-level network reconfiguration. Besides, AI based data mining tools are exploited by third parities to extract useful information underlying raw data. This leads to the emergence of AI enabled RWSN. We further study a data trading market to provide the data-centric environment for large-scale applications of AI enabled RWSN. A network operator employs the devices to gather environmental data, and sells the collected data to interested third parities as data consumers. After that, two-level optimizations are performed to ensure efficient data trading. In data collection, a contract based incentive mechanism is presented for the network operator to stimulate the devices and simultaneously achieve the contractor's goal subject to feasible constraints. In data selling, a non-cooperative game is formulated among multiple data consumers. They balance the data demand since the final data price is correlated with the total data demand. Nash equilibrium is analyzed and solved under different conditions. Finally, numerical results are provided to demonstrate the effectiveness of our scheme.",IEEE Transactions on Network Science and Engineering,31 July 2020,98 - 108,,,10.1109/TNSE.2020.3013064,https://doi.org/10.1109/TNSE.2020.3013064,IEEE
Making a Bird AI Expert Work for You and Me,Dongliang Chang; Kaiyue Pang; Ruoyi Du; Yujun Tong; Yi-Zhe Song; Zhanyu Ma; Jun Guo; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10122150/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10122150,"As powerful as fine-grained visual classification (FGVC) is, responding your query with a bird name of “Whip-poor-will” or “Mallard” probably does not make much sense. This however commonly accepted in the literature, underlines a fundamental question interfacing AI and human – what constitutes transferable knowledge for human to learn from AI? This paper sets out to answer this very question using FGVC as a test bed. Specifically, we envisage a scenario where a trained FGVC model (the AI expert) functions as a knowledge provider in enabling average people (you and me) to become better domain experts ourselves. Assuming an AI expert trained using expert human labels, we anchor our focus on asking and providing solutions for two questions: (i) what is the best transferable knowledge we can extract from AI, and (ii) what is the most practical means to measure the gains in expertise given that knowledge? We propose to represent knowledge as highly discriminative visual regions that are expert-exclusive and instantiate it via a novel multi-stage learning framework. A human study of 15,000 trials shows our method is able to consistently improve people of divergent bird expertise to recognise once unrecognisable birds. We further propose a crude but benchmarkable metric TEMI and therefore allow future efforts in this direction to be comparable to ours without the need of large-scale human studies.",IEEE Transactions on Pattern Analysis and Machine Intelligence,09 May 2023,12068 - 12084,,37159309,10.1109/TPAMI.2023.3274593,https://doi.org/10.1109/TPAMI.2023.3274593,IEEE
"Using Knowledge Graphs to Unlock Practical Collection, Integration, and Audit of AI Accountability Information",Iman Naja; Milan Markovic; Peter Edwards; Wei Pang; Caitlin Cottrill; Rebecca Williams; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9815594/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9815594,"To enhance trustworthiness of AI systems, a number of solutions have been proposed to document how such systems are built and used. A key facet of realizing trust in AI is how to make such systems accountable - a challenging task, not least due to the lack of an agreed definition of accountability and differing perspectives on what information should be recorded and how it should be used (e.g., to inform audit). Information originates across the life cycle stages of an AI system and from a variety of sources (individuals, organizations, systems), raising numerous challenges around collection, management, and audit. In our previous work, we argued that semantic Knowledge Graphs (KGs) are ideally suited to address those challenges and we presented an approach utilizing KGs to aid in the tasks of modelling, recording, viewing, and auditing accountability information related to the design stage of AI system development. Moreover, as KGs store data in a structured format understandable by both humans and machines, we argued that this approach provides new opportunities for building intelligent applications that facilitate and automate such tasks. In this paper, we expand our earlier work by reporting additional detailed requirements for knowledge representation and capture in the context of AI accountability; these extend the scope of our work beyond the design stage, to also include system implementation. Furthermore, we present the RAInS ontology which has been extended to satisfy these requirements. We evaluate our approach against three popular baseline frameworks, namely, Datasheets, Model Cards, and FactSheets, by comparing the range of information that can be captured by our KGs against these three frameworks. We demonstrate that our approach subsumes and extends the capabilities of the baseline frameworks and discuss how KGs can be used to integrate and enhance accountability information collection processes.",IEEE Access,06 July 2022,74383 - 74411,2169-3536,,10.1109/ACCESS.2022.3188967,https://doi.org/10.1109/ACCESS.2022.3188967,IEEE
An Interrogative Survey of Explainable AI in Manufacturing,Zoe Alexander; Duen Horng Chau; Christopher Saldaña; ; ; ,https://ieeexplore.ieee.org/document/10449717/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10449717,"Artificial intelligence (AI) is a driving force behind Industry 4.0 in manufacturing. Specifically, machine learning has been applied to all parts of the manufacturing process: from product design optimization to anomaly detection for quality control. Explainable AI (XAI) and interpretable AI (IAI) methods have been developed to provide transparency into how models make decisions. This survey presents a thorough review of who, what, when, where, why, and how both IAI and XAI methods have been used in manufacturing. Due to the multidisciplinary nature of manufacturing, this work provides the results from a systematic literature review that surveyed papers from highly rated venues in multiple manufacturing and AI-related fields to give the reader a holistic view of the space. This survey is intended to help both individuals from academia and industry quickly understand the applications, areas of research, and future work involved with creating explainable industrial solutions.",IEEE Transactions on Industrial Informatics,27 February 2024,7069 - 7081,,,10.1109/TII.2024.3361489,https://doi.org/10.1109/TII.2024.3361489,IEEE
Optimal Neighborhood Contexts in Explainable AI: An Explanandum-Based Evaluation,Urja Pawar; Donna O'Shea; Ruairi O'Reilly; Maebh Costello; Christian Beder; ; ; ; ; ,https://ieeexplore.ieee.org/document/10504877/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10504877,"Over the years, several frameworks have been proposed in the domain of Explainable AI (XAI), however their practical applicability and utility need to be clarified. The neighbourhood contexts are shown to significantly impact the explanations generated by XAI frameworks, thus directly affecting their utility in addressing specific questions, or “explananda”. This work introduces a methodology that use a comprehensive range of neighbourhood contexts to evaluate and enhance the utility of specific XAI techniques, particularly Feature Importance and CounterFactuals. In this evaluation, two explananda are targeted. The first one examines whether features' collection should be halted as per the AI model based on the sufficiency of the current set of information. Here, the information refers to the features present in the data used to train the AI-based system. The second one explores what is the most effective information (features) that should be collected next to ensure that the AI outputs the same classification as it would have generated with all the information present. These questions serve as a platform to demonstrate our methodology's ability to assess the impact of customised neighbourhood contexts on the utility of XAI.",IEEE Open Journal of the Computer Society,18 April 2024,181 - 194,2644-1268,,10.1109/OJCS.2024.3389781,https://doi.org/10.1109/OJCS.2024.3389781,IEEE
A Critical Review of Inductive Logic Programming Techniques for Explainable AI,Zheng Zhang; Levent Yilmaz; Bo Liu; ; ; ,https://ieeexplore.ieee.org/document/10092808/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10092808,"Despite recent advances in modern machine learning algorithms, the opaqueness of their underlying mechanisms continues to be an obstacle in adoption. To instill confidence and trust in artificial intelligence (AI) systems, explainable AI (XAI) has emerged as a response to improve modern machine learning algorithms’ explainability. Inductive logic programming (ILP), a subfield of symbolic AI, plays a promising role in generating interpretable explanations because of its intuitive logic-driven framework. ILP effectively leverages abductive reasoning to generate explainable first-order clausal theories from examples and background knowledge. However, several challenges in developing methods inspired by ILP need to be addressed for their successful application in practice. For example, the existing ILP systems often have a vast solution space, and the induced solutions are very sensitive to noises and disturbances. This survey paper summarizes the recent advances in ILP and a discussion of statistical relational learning (SRL) and neural-symbolic algorithms, which offer synergistic views to ILP. Following a critical review of the recent advances, we delineate observed challenges and highlight potential avenues of further ILP-motivated research toward developing self-explanatory AI systems.",IEEE Transactions on Neural Networks and Learning Systems,05 April 2023,10220 - 10236,,37018093,10.1109/TNNLS.2023.3246980,https://doi.org/10.1109/TNNLS.2023.3246980,IEEE
Revealing Hidden Defects in Electronic Components With an AI-Based Inspection Method: A Corrosion Case Study,E. Weiss; ,https://ieeexplore.ieee.org/document/10175601/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10175601,"Corrosion on electronic component terminations during assembly can lead to the failure of electronic devices. The terminations of electronic components are susceptible to corrosion when exposed to moisture and other corrosive agents during and before the assembly process. This corrosion can cause physical damage to the terminations, resulting in poor electrical contact and possible failure of the electronic component. In this letter, we present a case study where an automotive production line utilized Cybord’s AI-based inspection system to detect and prevent contamination in the soldering terminations of electronic components. The system interfaced with the vision system of pick-and-place machines in real time and collected bottom-side images of all components placed on printed circuit boards (PCBs). The AI algorithm, based on a 3 billion component database, detected evidence of corrosion, mold, and other contaminants on each component and allowed the removal of poor-quality components from production. The reel was disqualified and sent to a lab for scanning electron microscopy with energy-dispersive X-ray spectroscopy (SEM-EDX) analysis, which confirmed the findings of the AI algorithm that the issue was evidence of oxidation contamination. The results of this case study demonstrate the effectiveness of using AI-based inspection in detecting and preventing contamination in electronic assembly, boosting the overall quality and reliability of the final product.","IEEE Transactions on Components, Packaging and Manufacturing Technology",07 July 2023,1078 - 1080,,,10.1109/TCPMT.2023.3293005,https://doi.org/10.1109/TCPMT.2023.3293005,IEEE
Aligned Intra Prediction and Hyper Scale Decoder Under Multistage Context Model for JPEG AI,Shuai Li; Yanbo Gao; Chuankun Li; Hui Yuan; ; ; ; ,https://ieeexplore.ieee.org/document/10542332/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10542332,"Learning-based image compression has raised increasing interests in the last few years. Currently, Joint Photographic Experts Group (JPEG) is working on the standardization of learning-based image compression as JPEG AI. It adopts a deep neural network based encoder-decoder architecture with hyperprior based probability formulation for entropy coding. JPEG AI currently contains two coding profiles: Base Operating Point (BaseOP) and High Operating Point (HighOP). Among the various techniques developed in JPEG AI, Multistage Context Model (MCM) was adopted as the context model to perform intra prediction in HighOP. It transforms the spatially progressive context prediction into sub-image feature prediction among channels via feature down-shuffling. However, in this prediction process, sub-image features are not spatially aligned to each other, and directly using the neighboring sub-image features cannot provide accurate prediction. Moreover, the distributions of residual features generated by MCM are also not consistent with that of the hyper scale decoder, which is used to construct the probability model in the entropy coding of residual features, leading to suboptimal residual coding. To address the above problems, we propose an Aligned Intra Prediction (AIP) and Aligned Hyper Scale Decoder (AHSD) under MCM for JPEG AI coding. AIP aligns the reference sub-image features to the to-be-predicted feature in MCM. AHSD further generates hyper scale features with matched distributions to the residual features. Experimental results demonstrate that the proposed method improves the coding performance by 1.3% in terms of BD-rate saving over the JPEG AI reference software.",IEEE Signal Processing Letters,30 May 2024,1545 - 1549,,,10.1109/LSP.2024.3407597,https://doi.org/10.1109/LSP.2024.3407597,IEEE
AI-Native for 6G Core Network Configuration,Abdullah Ridwan Hossain; Weiqi Liu; Nirwan Ansari; Abbas Kiani; Tony Saboorian; ; ; ; ; ,https://ieeexplore.ieee.org/document/10210204/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10210204,"3GPP envisions exploiting AI-Native for the day-to-day operations of 6G core networks (CNs). As opposed to 5G CNs whose uses for artificial intelligence (AI) are limited and not yet standardized, 6G CNs seek a revolutionary redesign where AI will no longer simply be an overlaid service but rather the foundation upon which all network functions run, i.e., AI-Native. By leveraging knowledge of the CN control plane, we utilize an AI framework to optimize our three proposed CN configurations and minimize the CN execution time which is imperative for end-to-end routing in the user plane.",IEEE Networking Letters,07 August 2023,255 - 259,2576-3156,,10.1109/LNET.2023.3302833,https://doi.org/10.1109/LNET.2023.3302833,IEEE
C-Testing and Efficient Fault Localization for AI Accelerators,Arjun Chaudhuri; Chunsheng Liu; Xiaoxin Fan; Krishnendu Chakrabarty; ; ; ; ,https://ieeexplore.ieee.org/document/9521587/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9521587,"Accelerators for machine learning [artificial intelligence (AI)] inferencing applications are homogeneous designs composed of identical cores. Each core or processing element (PE) contains multiply-and-accumulate units, control logic, and registers for storing and forwarding weights and activations. Testing homogeneous array-based AI accelerator chips by running automatic test pattern generation (ATPG) at the array level results in a high CPU time and pattern count. We propose a constant-testable (C-testable) method for test generation at the PE level such that the ATPG effort does not increase with the number of PEs. Our results show that compared to the traditional array-level testing, the proposed method achieves up to $4.2\times $ ( $3.5\times $ ), $1530\times $ ( $2388\times $ ), and $170\times $ ( $142\times $ ) reduction in the test pattern count, ATPG runtime, and test cycle count, respectively, for stuck-at (transition) faults in a $256\times 256$ array, while preserving the test coverage. A reconfigurable scan architecture is introduced to enable the proposed C-testable solution for the entire accelerator array. The design-space exploration of a hierarchical test-compaction framework is presented. We also describe four debug solutions for fault localization and diagnosis.",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,24 August 2021,2348 - 2361,,,10.1109/TCAD.2021.3107401,https://doi.org/10.1109/TCAD.2021.3107401,IEEE
"A 7-nm Four-Core Mixed-Precision AI Chip With 26.2-TFLOPS Hybrid-FP8 Training, 104.9-TOPS INT4 Inference, and Workload-Aware Throttling",Sae Kyu Lee; Ankur Agrawal; Joel Silberman; Matthew Ziegler; Mingu Kang; Swagath Venkataramani; Nianzheng Cao; Bruce Fleischer; Michael Guillorn; Matthew Cohen; Silvia M. Mueller; Jinwook Oh; Martin Lutz; Jinwook Jung; Siyu Koswatta; Ching Zhou; Vidhi Zalani; Monodeep Kar; James Bonanno; Robert Casatuta; Chia-Yu Chen; Jungwook Choi; Howard Haynie; Alyssa Herbert; Radhika Jain; Kyu-Hyoun Kim; Yulong Li; Zhibin Ren; Scot Rider; Marcel Schaal; Kerstin Schelm; Michael R. Scheuermann; Xiao Sun; Hung Tran; Naigang Wang; Wei Wang; Xin Zhang; Vinay Shah; Brian Curran; Vijayalakshmi Srinivasan; Pong-Fei Lu; Sunil Shukla; Kailash Gopalakrishnan; Leland Chang; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9610618/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9610618,"Reduced precision computation is a key enabling factor for energy-efficient acceleration of deep learning (DL) applications. This article presents a 7-nm four-core mixed-precision artificial intelligence (AI) chip that supports four compute precisions—FP16, Hybrid-FP8 (HFP8), INT4, and INT2—to support diverse application demands for training and inference. The chip leverages cutting-edge algorithmic advances to demonstrate leading-edge power efficiency for 8-bit floating-point (FP8) training and INT4 inference without model accuracy degradation. A new HFP8 format combined with separation of the floating- and fixed-point pipelines and aggressive circuit/architecture optimization enables performance improvements while maintaining high compute utilization. A high-bandwidth ring protocol enables efficient data communication, while power management using workload-aware clock throttling maximizes performance within a given power budget. The AI chip demonstrates 3.58-TFLOPS/W peak energy efficiency and 26.2-TFLOPS peak performance for HFP8 iso-accuracy training, and 16.9-TOPS/W peak energy efficiency and 104.9-TOPS peak performance for INT4 iso-accuracy inference.",IEEE Journal of Solid-State Circuits,10 November 2021,182 - 197,,,10.1109/JSSC.2021.3120113,https://doi.org/10.1109/JSSC.2021.3120113,IEEE
Functional Criticality Analysis of Structural Faults in AI Accelerators,Arjun Chaudhuri; Jonti Talukdar; Fei Su; Krishnendu Chakrabarty; ; ; ; ,https://ieeexplore.ieee.org/document/9751719/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9751719,"The ubiquitous application of deep neural networks (DNNs) has led to a rise in demand for artificial intelligence (AI) accelerators. For example, the tensor processing unit from Google–based on a systolic array–and its variants are of considerable interest for DNN inferencing using AI accelerators. This article studies the problem of classifying structural faults in such an accelerator based on their functional criticality. We first analyze pin-level faults in the processing elements (PEs) of a systolic array. Simulation results for the LeNet network with 8-bit fixed-point, 16-bit floating-point (FP), and 32-bit FP data paths applied to the MNIST dataset show that over 93% of the pin-level structural faults in a PE are functionally benign. We present a greedy iterative framework for determining the criticality of stuck-at faults in a PE netlist and analyze the limitations of criticality analysis methods based on repeated fault simulations. We next present a scalable two-tier machine-learning (ML)-based method to assess the functional criticality of stuck-at faults in a computationally efficient manner. We address the problem of minimizing misclassification by utilizing generative adversarial networks (GANs). Two-tier ML/GAN-based criticality assessment leads to less than 1% test escapes during functional criticality evaluation of structural faults.",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,08 April 2022,5657 - 5670,,,10.1109/TCAD.2022.3166108,https://doi.org/10.1109/TCAD.2022.3166108,IEEE
System and Design Technology Co-Optimization of SOT-MRAM for High-Performance AI Accelerator Memory System,Kaniz Mishty; Mehdi Sadi; ; ,https://ieeexplore.ieee.org/document/10319731/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10319731,"System on chips (SoCs) are now designed with their own artificial intelligence (AI) accelerator segment to accommodate the ever-increasing demand of deep learning (DL) applications. With powerful multiply and accumulate (MAC) engines for matrix multiplications, these accelerators show high computing performance. However, because of limited memory resources (i.e., bandwidth and capacity), they fail to achieve optimum system performance during large batch training and inference. In this work, we propose a memory system with high on-chip capacity and bandwidth to shift the gear of AI accelerators from memory-bound to achieving system-level peak performance. We develop the memory system with design technology co-optimization (DTCO)-enabled customized spin-orbit torque (SOT)-MRAM as large on-chip memory through system technology co-optimization (STCO) and detailed characterization of the DL workloads. Our workload-aware memory system achieves $8\times $ energy and $9\times $ latency improvement on computer vision (CV) benchmarks in training and $8\times $ energy and $4.5\times $ latency improvement on natural language processing (NLP) benchmarks in training while consuming only around 50% of SRAM area at iso-capacity.",IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,16 November 2023,1065 - 1078,,,10.1109/TCAD.2023.3333754,https://doi.org/10.1109/TCAD.2023.3333754,IEEE
Modular Learning: Agile Development of Robust Traffic Sign Recognition,Yu-Hsun Lin; Yong-Sheng Wang; ; ,https://ieeexplore.ieee.org/document/10273429/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10273429,"Autonomous driving is an important research domain with great impact for the future traffic communication. The trend of self-driving car will affect the design of vehicles that incorporates with numerous intelligent modules (e.g., traffic sign recognition). In contrast to a typical AI task (e.g., digit recognition), self-driving car will have countless situations in the real world. Therefore, the self-driving car system requires a long-term development process or even endless maintenance activities. We have to address the newly discovered image corruption rapidly for a robust recognition system. Hence, we proposed our agile development framework for AI system, which is inspired from agile software development paradigm. Our agile framework of AI system aims to speed up the development cycle for each newly discovered image corruption. We denote the training time of each incremental development cycle as the marginal cost of AI system development. We proposed an agile development paradigm called modular learning that incorporates with knowledge distillation to reduce the marginal cost. The acceleration of our method is up to 49\times while the recognition accuracy degradation is around 1%. We found that the studies for long-term AI system development are rarely addressed in the literature. We expect our preliminary and promising results can inspire more efforts in this direction.",IEEE Transactions on Intelligent Vehicles,06 October 2023,764 - 774,,,10.1109/TIV.2023.3322407,https://doi.org/10.1109/TIV.2023.3322407,IEEE
AI in Games,,https://ieeexplore.ieee.org/document/8138737/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8138737,,,,,,,,,
The best of world AI in Scotland,,https://ieeexplore.ieee.org/document/8138825/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8138825,"The UK has been involved with the development of the field of artificial intelligence (AI) since the very beginning, from the initial ideas of Alan Turing, to the development of key AI technologies such as Warren's work on Prolog.",ITNOW,July 2005,16 - 17,,,10.1093/itnow/bwi072,https://doi.org/10.1093/itnow/bwi072,OUP
AI Applying,,https://ieeexplore.ieee.org/document/8138731/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8138731,"BCS past President, Professor Sir Nigel Shadbolt from Southampton University spoke to Henry Tucker MBCS about his current AI work, Terminators and the ethics of AI.",ITNOW,December 2013,6 - 7,,,10.1093/itnow/bwt064,https://doi.org/10.1093/itnow/bwt064,OUP
AI conference on all technologies and applications,,https://ieeexplore.ieee.org/document/8142278/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8142278,"Recent technical advances in artificial intelligence (AI) technologies will be reviewed at AI-2006, the 26th conference organized by the BCS's Specialist Group on Artificial Intelligence.",ITNOW,September 2006,34 - 34,,,10.1093/itnow/bwl066,https://doi.org/10.1093/itnow/bwl066,OUP
Explicating AI Literacy of Employees at Digital Workplaces,Dilek Cetindamar; Kirsty Kitto; Mengjia Wu; Yi Zhang; Babak Abedin; Simon Knight; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9681321/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9681321,"This article aims to understand the definition and dimensions of artificial intelligence (AI) literacy. Digital technologies, including AI, trigger organizational affordances in workplaces, yet few studies have investigated employees’ AI literacy. This article uses a bibliometrics analysis of 270 articles to explore the meaning of AI literacy of employees in the extant literature. Descriptive statistics, keyword co-occurrence analysis, and a hierarchical topic tree are employed to profile the research landscape and identify the core research themes and relevant papers related to AI literacy's definition, dimensions, challenges, and future directions. Findings highlight four sets of capabilities associated with AI literacy, namely technology-related, work-related, human-machine-related, and learning-related capabilities, pointing also to the importance of operationalizing AI literacy for non AI professionals. This result contributes to the literature associated with technology management studies by offering a novel conceptualization of AI literacy and link it to the employee's role in digital workplaces. We conclude by inviting researchers to examine the effect of employee-technology interactions on employees’ AI literacy, which might improve the design and use of AI.",IEEE Transactions on Engineering Management,13 January 2022,810 - 823,,,10.1109/TEM.2021.3138503,https://doi.org/10.1109/TEM.2021.3138503,IEEE
Opportunities and Challenges in Data-Centric AI,Sushant Kumar; Sumit Datta; Vishakha Singh; Sanjay Kumar Singh; Ritesh Sharma; ; ; ; ; ,https://ieeexplore.ieee.org/document/10444552/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10444552,"Artificial intelligence (AI) systems are trained to solve complex problems and learn to perform specific tasks by using large volumes of data, such as prediction, classification, recognition, decision-making, etc. In the past three decades, AI research has focused mostly on the model-centric approach compared to the data-centric approach. In the model-centric approach, the focus is to improve the code or model architecture to enhance performance, whereas in data-centric AI, the focus is to improve the dataset to enhance performance. Data is food for AI. As a result, there has been a recent push in the AI community toward data-centric AI from model-centric AI. This paper provides a comprehensive and critical analysis of the current state of research in data-centric AI, presenting insights into the latest developments in this rapidly evolving field. By emphasizing the importance of data in AI, the paper identifies the key challenges and opportunities that must be addressed to improve the effectiveness of AI systems. Finally, this paper gives some recommendations for research opportunities in data-centric AI.",IEEE Access,23 February 2024,33173 - 33189,2169-3536,,10.1109/ACCESS.2024.3369417,https://doi.org/10.1109/ACCESS.2024.3369417,IEEE
AI Loyalty: A New Paradigm for Aligning Stakeholder Interests,Anthony Aguirre; Gaia Dempsey; Harry Surden; Peter B. Reiner; ; ; ; ,https://ieeexplore.ieee.org/document/9157977/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9157977,"When we consult a doctor, lawyer, or financial advisor, we assume that they are acting in our best interests. But what should we assume when we interact with an artificial intelligence (AI) system? AI-driven personal assistants, such as Alexa and Siri, already serve as interfaces between consumers and information on the Web, and users routinely rely upon these and similar systems to take automated actions or provide information. Superficially, they may appear to be acting according to user interests, but many are designed with embedded conflicts of interests. To address this problem, we introduce the concept of AI loyalty. AI systems are loyal to the degree that they minimize and make transparent, conflicts of interest, and act in ways that prioritize the interests of users. Loyal AI products hold obvious appeal for the end-user and could promote the alignment of the long-term interests of AI developers and customers. To this end, we suggest criteria for assessing whether an AI system is acting in a manner that is loyal to the user, and argue that AI loyalty should be deliberately considered during the technological design process alongside other important values in AI ethics, such as fairness, accountability privacy, and equity.",IEEE Transactions on Technology and Society,04 August 2020,128 - 137,2637-6415,,10.1109/TTS.2020.3013490,https://doi.org/10.1109/TTS.2020.3013490,IEEE
Trustworthiness Assurance Assessment for High-Risk AI-Based Systems,Georg Stettinger; Patrick Weissensteiner; Siddartha Khastgir; ; ; ,https://ieeexplore.ieee.org/document/10430152/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10430152,"This work proposes methodologies for ensuring the trustworthiness of high-risk artificial intelligence (AI) systems (AIS) to achieve compliance with the European Union’s (EU) AI Act. High-risk classified AIS must fulfill seven requirements to be considered trustworthy and human-centric, and subsequently be considered for deployment. These requirements are equally important, mutually supportive, and should be implemented and evaluated throughout the AI lifecycle. The assurance of trustworthiness is influenced by ethical considerations, amongst others. Hence, the operational design domain (ODD) and behavior competency (BC) concepts from the automated driving domain are utilized in risk assessment strategies to quantify different types of residual risks. The methodology presented is guided by the consistent application of the ODD and its related BC concept throughout the entire AI lifecycle, focusing on the trustworthiness assurance framework and its associated process as the main pillars for AIS certification. The achievement of the overall objective of trustworthy and human-centric AIS is divided into seven interconnected sub-goals: the formulation of use restrictions, the trustworthiness assurance/argument itself, the identification of dysfunctional cases, the utilization of scenario databases and datasets, the application of metrics for evaluation, the implementation of the proposed concept across the AI lifecycle, and sufficient consideration of human factors. The role of standards in the assurance process is discussed, considering any existing gaps and areas for improvement. The work concludes with a summary of the developed approach, highlighting key takeaways and action points. Finally, a roadmap to ensure trustworthy and human-centric behavior of future AIS is outlined.",IEEE Access,08 February 2024,22718 - 22745,2169-3536,,10.1109/ACCESS.2024.3364387,https://doi.org/10.1109/ACCESS.2024.3364387,IEEE
Explainable Artificial Intelligence for Agile Mediation Propensity Assessment,Enrico Collini; Paolo Nesi; Claudia Raffaelli; Francesco Scandiffio; ; ; ; ,https://ieeexplore.ieee.org/document/10464317/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10464317,"Italian Justice has recently added mechanisms to exploit mediation process. One of the most critical aspects is a reliable identification of litigations which can be successfully mediated outside court procedures. The decision is under responsibility of a judge/court who has to read hundreds of pages and several documents, to be able to take a decision on the basis of few statements. This paper describes both an artificial intelligence solution and a tool to provide a decision support system which could process documents and be capable to: (i) produce reliable suggestions, (ii) produce circumstantiated motivations, thus highlighting statements which could support identified suggestion focusing the work of any judge/court on actual statements and documents with relevant facts, and (iii) provide a web based tool producing suggestions and motivations on demand at service of the involved court and judges, compliant with privacy and security, as to data. To this end, AI and eXplainable AI technologies have been used and a solution has been obtained which meets the above-mentioned objectives and many other detailed requirements. Such a solution has been developed in the context of the research project “Giustizia Agile”, funded by the Italian National PON Governance and Institutional Capacity, and validated against real cases. The solution has exploited the Snap4City framework for data and AI/XAI management.",IEEE Access,11 March 2024,37782 - 37798,2169-3536,,10.1109/ACCESS.2024.3375766,https://doi.org/10.1109/ACCESS.2024.3375766,IEEE
A Novel Loss for Change Point Detection Models With Time-Invariant Representations,Zhenxiang Cao; Nick Seeuws; Maarten De Vos; Alexander Bertrand; ; ; ; ,https://ieeexplore.ieee.org/document/10328048/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10328048,"Change point detection (CPD) refers to the problem of detecting changes in the statistics of pseudo-stationary signals or time series. A recent trend in CPD research is to replace the traditional statistical tests with distribution-free autoencoder-based algorithms, which can automatically learn complex patterns in time series data. In particular, the so-called time-invariant representation (TIRE) models have gained traction, as these separately encode time-variant and time-invariant subfeatures, as opposed to traditional autoencoders. However, optimizing the trade-off between two loss terms, i.e., the reconstruction loss and the time-invariant loss, is challenging. To address this issue, we propose a novel loss function that elegantly combines both losses without the need for manually tuning a trade-off hyperparameter. We demonstrate that this new hyperparameter-free loss, in combination with a relatively simple convolutional neural network (CNN), consistently achieves superior or comparable performance compared to the manually-tuned baseline TIRE models across diverse benchmark datasets, both simulated and real-life. In addition, we present a representation analysis, demonstrating that the distribution of the time-invariant features extracted by our model is more concentrated within the same segment (more so than with previous TIRE models), which implies that these features can potentially be used for other applications, such as classification and clustering.",IEEE Signal Processing Letters,23 November 2023,1737 - 1741,,,10.1109/LSP.2023.3336258,https://doi.org/10.1109/LSP.2023.3336258,IEEE
Review of the Use of AI Techniques in Serious Games: Decision Making and Machine Learning,Maite Frutos-Pascual; Begoñya García Zapirain; ; ,https://ieeexplore.ieee.org/document/7366548/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7366548,"The video game market has become an established and ever-growing global industry. The health of the video and computer games industry, together with the variety of genres and technologies available, means that video game concepts and programmes are being applied in numerous different disciplines. One of these is the field known as serious games. The main goal of this paper is to collect all the relevant articles published during the last decade and create a trend analysis about the use of certain artificial intelligence algorithms related to decision making and learning in the field of serious games. A categorization framework was designed and outlined to classify the 129 papers that met the inclusion criteria. The authors made use of this categorization framework for drawing some conclusions regarding the actual use of intelligent serious games. The authors consider that over recent years enough knowledge has been gathered to create new intelligent serious games to consider not only the final aim but also the technologies and techniques used to provide players with a nearly real experience. However, researchers may need to improve their testing methodology for developed serious games, so as to ensure they meet their final purposes.",IEEE Transactions on Computational Intelligence and AI in Games,25 December 2015,133 - 152,,,10.1109/TCIAIG.2015.2512592,https://doi.org/10.1109/TCIAIG.2015.2512592,IEEE
Philosophical Specification of Empathetic Ethical Artificial Intelligence,Michael Timothy Bennett; Yoshihiro Maruyama; ; ,https://ieeexplore.ieee.org/document/9495946/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9495946,"In order to construct an ethical artificial intelligence (AI) two complex problems must be overcome. First, humans do not consistently agree on what is or is not ethical. Second, contemporary AI and machine learning methods tend to be blunt instruments which either search for solutions within the bounds of predefined rules or mimic behavior. An ethical AI must be capable of inferring unspoken rules, interpreting nuance and context, possess and be able to infer intent, and explain not just its actions but its intent. Using enactivism, semiotics, perceptual symbol systems, and symbol emergence, we specify an agent that learns not just arbitrary relations between signs but their meaning in terms of the perceptual states of its sensorimotor system. Subsequently it can learn what is meant by a sentence and infer the intent of others in terms of its own experiences. It has malleable intent because the meaning of symbols changes as it learns, and its intent is represented symbolically as a goal. As such it may learn a concept of what is most likely to be considered ethical by the majority within a population of humans, which may then be used as a goal. The meaning of abstract symbols is expressed using perceptual symbols of raw, multimodal sensorimotor stimuli as the weakest (consistent with Ockham’s Razor) necessary and sufficient concept, an intensional definition learned from an ostensive definition, from which the extensional definition or category of all ethical decisions may be obtained. Because these abstract symbols are the same for both situation and response, the same symbol is used when either performing or observing an action. This is akin to mirror neurons in the human brain. Mirror symbols may allow the agent to empathize, because its own experiences are associated with the symbol, which is also associated with the observation of another agent experiencing something that symbol represents.",IEEE Transactions on Cognitive and Developmental Systems,26 July 2021,292 - 300,,,10.1109/TCDS.2021.3099945,https://doi.org/10.1109/TCDS.2021.3099945,IEEE
Improving IoT Security With Explainable AI: Quantitative Evaluation of Explainability for IoT Botnet Detection,Rajesh Kalakoti; Hayretdin Bahsi; Sven Nõmm; ; ; ,https://ieeexplore.ieee.org/document/10418172/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10418172,"Detecting botnets is an essential task to ensure the security of Internet of Things (IoT) systems. Machine learning (ML)-based approaches have been widely used for this purpose, but the lack of interpretability and transparency of the models often limits their effectiveness. In this research paper, our aim is to improve the transparency and interpretability of high-performance ML models for IoT botnet detection by selecting higher quality explanations using explainable artificial intelligence (XAI) techniques. We used three data sets to induce binary and multiclass classification models for IoT botnet detection, with sequential backward selection (SBS) employed as the feature selection technique. We then use two post hoc XAI techniques such as local interpretable model-agnostic explanations (LIME) and Shapley additive explanation (SHAP), to explain the behavior of the models. To evaluate the quality of explanations generated by XAI methods, we employed faithfulness, monotonicity, complexity, and sensitivity metrics. ML models employed in this work achieve very high detection rates with a limited number of features. Our findings demonstrate the effectiveness of XAI methods in improving the interpretability and transparency of ML-based IoT botnet detection models. Specifically, explanations generated by applying LIME and SHAP to the extreme gradient boosting model yield high faithfulness, high consistency, low complexity, and low sensitivity. Furthermore, SHAP outperforms LIME by achieving better results in these metrics.",IEEE Internet of Things Journal,31 January 2024,18237 - 18254,,,10.1109/JIOT.2024.3360626,https://doi.org/10.1109/JIOT.2024.3360626,IEEE
Privacy and Security Concerns in Generative AI: A Comprehensive Survey,Abenezer Golda; Kidus Mekonen; Amit Pandey; Anushka Singh; Vikas Hassija; Vinay Chamola; Biplab Sikdar; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10478883/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10478883,"Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement.",IEEE Access,25 March 2024,48126 - 48144,2169-3536,,10.1109/ACCESS.2024.3381611,https://doi.org/10.1109/ACCESS.2024.3381611,IEEE
Explainable AI for Intrusion Detection Systems: LIME and SHAP Applicability on Multi-Layer Perceptron,Diogo Gaspar; Paulo Silva; Catarina Silva; ; ; ,https://ieeexplore.ieee.org/document/10440604/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10440604,"Machine learning-based systems have presented increasing learning performance, in a wide variety of tasks. However, the problem with some state-of-the-art models is their lack of transparency, trustworthiness, and explainability. To address this problem, eXplainable Artificial Intelligence (XAI) appeared. It is a research field that aims to make black-box models more understandable to humans. The research on this topic has increased in recent years, and many methods, such as LIME (Local Interpretable Model-Agnostic Explanations) and SHAP (SHapley Additive exPlanations) have been proposed. Machine learning-based Intrusion Detection Systems (IDS) are one of the many application domains of XAI. However, most of the works about model interpretation focus on other fields, like computer vision, natural language processing, biology, healthcare, etc. This poses a challenge for cybersecurity professionals tasked with analyzing IDS results, thereby impeding their capacity to make informed decisions. In an attempt to address this problem, we have selected two XAI methods, LIME, and SHAP. Using the methods, we have retrieved explanations for the results of a black-box model, part of an IDS solution that performs intrusion detection on IoT devices, increasing its interpretability. In order to validate the explanations, we carried out a perturbation analysis where we tried to obtain a different classification based on the features present in the explanations. With the explanations and the perturbation analysis we were able to draw conclusions about the negative impact of particular features on the model results when present in the input data, making it easier for cybersecurity experts when analyzing the model results and it serves as an aid to the continuous improvement the model. The perturbations also serve as a comparison of performance between LIME and SHAP. To evaluate the degree of interpretability increase, and the explanations provided by each XAI method of the model and ...",IEEE Access,20 February 2024,30164 - 30175,2169-3536,,10.1109/ACCESS.2024.3368377,https://doi.org/10.1109/ACCESS.2024.3368377,IEEE
Guaranteeing Correctness in Black-Box Machine Learning: A Fusion of Explainable AI and Formal Methods for Healthcare Decision-Making,Nadia Khan; Muhammad Nauman; Ahmad S. Almadhor; Nadeem Akhtar; Abdullah Alghuried; Adi Alhudhaif; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10577273/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10577273,"In recent years, Explainable Artificial Intelligence (XAI) has attracted considerable attention from the research community, primarily focusing on elucidating the opaque decision-making processes inherent in complex black-box machine learning systems such as deep neural networks. This spike in interest originates from the widespread adoption of black-box models, particularly in critical domains like healthcare and fraud detection, highlighting the pressing need to understand and validate their decision-making mechanisms rigorously. In addition, prominent XAI techniques, including LIME (Local Interpretable Model-Agnostic Explanations) and SHAP (Shapley Additive exPlanations), rely on heuristics and cannot guarantee the correctness of the explanations provided. This article systematically addresses this critical issue associated with machine learning and deep learning models, underscoring XAI’s pivotal role in promoting model transparency to enhance decision-making quality. Furthermore, this study advocates integrating Formal Methods to provide correctness guarantees for black-box internal decision-making. The proposed methodology unfolds in three pivotal stages: firstly, training black-box models using neural networks to generate synthetic datasets; secondly, employing LIME and SHAP techniques to interpret the models and visualize their internal decision-making processes; and finally, training decision trees on the synthetic datasets to implement Formal Methods for ensuring the correctness of the black-box model’s decision-making. To validate this proposed approach, experimentation was conducted on four widely recognized medical datasets, including the Wisconsin Breast Cancer and Thyroid Cancer (TC) datasets, which are available in the UCI Machine Learning Repository. Specifically, this research represents a significant contribution by pioneering a novel approach that seamlessly integrates XAI and Formal Methods, thereby furnishing correctness guarantees for internal...",IEEE Access,28 June 2024,90299 - 90316,2169-3536,,10.1109/ACCESS.2024.3420415,https://doi.org/10.1109/ACCESS.2024.3420415,IEEE
Predicting COVID-19 in China Using Hybrid AI Model,Nanning Zheng; Shaoyi Du; Jianji Wang; He Zhang; Wenting Cui; Zijian Kang; Tao Yang; Bin Lou; Yuting Chi; Hong Long; Mei Ma; Qi Yuan; Shupei Zhang; Dong Zhang; Feng Ye; Jingmin Xin; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9090302/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9090302,"The coronavirus disease 2019 (COVID-19) breaking out in late December 2019 is gradually being controlled in China, but it is still spreading rapidly in many other countries and regions worldwide. It is urgent to conduct prediction research on the development and spread of the epidemic. In this article, a hybrid artificial-intelligence (AI) model is proposed for COVID-19 prediction. First, as traditional epidemic models treat all individuals with coronavirus as having the same infection rate, an improved susceptible–infected (ISI) model is proposed to estimate the variety of the infection rates for analyzing the transmission laws and development trend. Second, considering the effects of prevention and control measures and the increase of the public’s prevention awareness, the natural language processing (NLP) module and the long short-term memory (LSTM) network are embedded into the ISI model to build the hybrid AI model for COVID-19 prediction. The experimental results on the epidemic data of several typical provinces and cities in China show that individuals with coronavirus have a higher infection rate within the third to eighth days after they were infected, which is more in line with the actual transmission laws of the epidemic. Moreover, compared with the traditional epidemic models, the proposed hybrid AI model can significantly reduce the errors of the prediction results and obtain the mean absolute percentage errors (MAPEs) with 0.52%, 0.38%, 0.05%, and 0.86% for the next six days in Wuhan, Beijing, Shanghai, and countrywide, respectively.",IEEE Transactions on Cybernetics,08 May 2020,2891 - 2904,,32396126,10.1109/TCYB.2020.2990162,https://doi.org/10.1109/TCYB.2020.2990162,IEEE
A Heterogeneous and Programmable Compute-In-Memory Accelerator Architecture for Analog-AI Using Dense 2-D Mesh,Shubham Jain; Hsinyu Tsai; Ching-Tzu Chen; Ramachandran Muralidhar; Irem Boybat; Martin M. Frank; Stanisław Woźniak; Milos Stanisavljevic; Praneet Adusumilli; Pritish Narayanan; Kohji Hosokawa; Masatoshi Ishii; Arvind Kumar; Vijay Narayanan; Geoffrey W. Burr; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9957094/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9957094,"We introduce a highly heterogeneous and programmable compute-in-memory (CIM) accelerator architecture for deep neural network (DNN) inference. This architecture combines spatially distributed CIM memory array “tiles” for weight-stationary, energy-efficient multiply–accumulate (MAC) operations, together with heterogeneous special-function compute cores for auxiliary digital computation. Massively parallel vectors of neuron activation data are exchanged over short distances using a dense and efficient circuit-switched 2-D mesh, offering full end-to-end support for a wide range of DNN workloads, including CNNs, long-short-term-memory (LSTM), and transformers. We discuss the design of the “analog fabric”—the 2-D grid of tiles and compute cores interconnected by the 2-D mesh—and address the efficiency in both mapping of DNNs onto the hardware and in pipelining of various DNN workloads across a range of batch sizes. We show, for the first time, system-level assessments using projected component parameters for a realistic “analog AI” system, based on dense crossbar arrays of low-power nonvolatile analog memory elements, while incorporating a single common analog fabric design that can scale to large networks by introducing data transport between multiple analog AI chips. Our performance estimates for several networks, including large LSTM and bidirectional encoder representations from transformers (BERT), show highly competitive throughput while offering $40\times $ – $140\times $ higher energy efficiency than NVIDIA A100—thus illustrating the strong promise of analog AI and the proposed architecture for DNN inference applications.",IEEE Transactions on Very Large Scale Integration (VLSI) Systems,21 November 2022,114 - 127,,,10.1109/TVLSI.2022.3221390,https://doi.org/10.1109/TVLSI.2022.3221390,IEEE
Earliest Possible Global and Local Interpretation of Students’ Performance in Virtual Learning Environment by Leveraging Explainable AI,Muhammad Adnan; M. Irfan Uddin; Emel Khan; Fahd S. Alharithi; Samina Amin; Ahmad A. Alzahrani; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9970711/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9970711,"In this research study, we propose an Explainable Artificial Intelligence (XAI) model that provides the earliest possible global and local interpretation of students’ performance at various stages of course length. Global and local interpretation is provided in such a way that the prediction accuracy of a single local observation is close to the model’s overall prediction accuracy. For the earliest possible understanding of student performance, local and global interpretation is provided at 20%, 40%, 60%, 80%, and 100% of course length. Machine Learning (ML) and Deep Learning (DL) which are subfields of Artificial Intelligence (AI) have recently emerged to assist all educational institution’s in predicting the performance, engagement, and dropout rate of online students. Unfortunately, traditional ML and DL techniques lack in providing data analysis results in an understandable human way. Explainable AI (XAI), a new branch of AI, can be used in educational settings, specifically in VLEs, to provide the instructor with the study performance results of thousands or even millions of online students in a human-understandable way. Thus, unlike black box approaches such as traditional ML and DL techniques, XAI can help instructors to interpret the strengths and weaknesses of an individual student, providing them with timely personalized feedback and guidance. Various traditional and various ensemble ML algorithms were trained on demographic, clickstream, and assessment features to determine which algorithm gives the best performance result. The best-performing ML algorithm was ultimately selected and provided to the XAI model as an input for local and global interpretation of students’ study behavior at various percentages of course length. We have used various XAI tools to give students’ performance reports to instructors, in an explicable human way, at different stages of course length. The intermediate data analysis and performance reports will help instructors and all...",IEEE Access,06 December 2022,129843 - 129864,2169-3536,,10.1109/ACCESS.2022.3227072,https://doi.org/10.1109/ACCESS.2022.3227072,IEEE
Edge AI in Sustainable Farming: Deep Learning-Driven IoT Framework to Safeguard Crops From Wildlife Threats,Konkala Venkateswarlu Reddy; B. S. Karthikeya Reddy; Veerapu Goutham; Miriyala Mahesh; J. S. Nisha; Gopinath Palanisamy; Mallikarjuna Golla; Swetha Purushothaman; Katangure Rithisha Reddy; Varsha Ramkumar; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10540092/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10540092,"The relentless global population growth and the ever-increasing food demand pose formidable challenges to the agricultural sector. Farmers grapple with the ongoing challenge of wildlife-induced crop damage and human loss, which not only impedes food production but also exacerbates supply and demand imbalances. However, the rise of TinyML enables Edge AI as a promising avenue for implementing resource-efficient deep learning techniques on low-end edge devices. In this paper, we introduce an innovative solution that harnesses the power of Edge AI using tinyML-based deep learning algorithms in conjunction with the Internet of Things (IoT) for animal intrusion detection and deterrence system. The proposed system is developed to create remotely managed defense system tailored to safeguard vast agricultural expanses. It integrates a laser detection system and an AI-CAM with light weight deep learning algorithms for animal intrusion detection and classification. This system also ensures efficient animal deterrence and real-time monitoring for farmers, enabling them to assess the situation with the assistance of an intelligent rover build using IoT. This work emphasizes on proposing a light-weight deep learning model named EvoNet for animal classification. Results reveal that the proposed model achieves the highest accuracy at 96.7%, surpassing other models presented in this paper. However, for edge devices where compact file sizes are crucial, the model also offers comparable accuracy with file sizes as low as 1.63MB with the help of pruning and quantization techniques. This conceptualized solution has the potential to revolutionize agricultural wildlife management, ushering in a new era of crop protection and economic resilience.",IEEE Access,28 May 2024,77707 - 77723,2169-3536,,10.1109/ACCESS.2024.3406585,https://doi.org/10.1109/ACCESS.2024.3406585,IEEE
Record 22-dB Net Gain of Broadband Single-Mode Cr-Doped Crystalline Core Fiber by AI-Assisted Image Recognition Growth,Chun-Nien Liu; Kai-Chieh Chang; Chia-Ling Tsai; Chien-Wei Huang; Tien-Tsorng Shih; Sheng-Lung Huang; Wood-Hi Cheng; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10360145/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10360145,"A record net gain of 22-dB and improved twice gain-per-unit length (GPUL) of 110 dB/m in a 13-μm core, 20-cm length, and 300-nm broadband single-mode Cr-doped crystalline core fibers (CCFs) are demonstrated by AI-assisted image recognition growth. The gain is significantly higher compared to the previous core of 25-μm. Both high gain and GPUL are achieved thanks to a novel AI-assisted, image recognition applied to the precise control of the molten zone with luminance of 2.39 cd/m 2 for fabricating smaller core diameter of 13-μm. The AI-assisted growth is performed by capturing images of the molten zone, RGB image recognition, luminance calculation, and real-time luminance adjustment within required value. The gain of several core diameters and fiber lengths has been thereafter simulated, which agrees with measured result. The smaller core of 13-μm exhibits higher coupling efficiency that is 65% the previous core of 25-μm. A lower noise figure of 4.2-dB is also obtained. In this study, the proposed CDFs looks promising for broadband fiber amplifiers.",Journal of Lightwave Technology,14 December 2023,2971 - 2977,,,10.1109/JLT.2023.3342931,https://doi.org/10.1109/JLT.2023.3342931,IEEE
OGLE-2018-BLG-1428Lb: a Jupiter-mass planet beyond the snow line of a dwarf star,,https://ieeexplore.ieee.org/document/9480868/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9480868,"We present the analysis of the microlensing event OGLE-2018-BLG-1428, which has a short-duration (∼1 d) caustic-crossing anomaly. The event was caused by a planetary lens system with planet/host mass ratio q = 1.7 × 10 −3 . Because of the detection of the caustic-crossing anomaly, the finite source effect was well measured, but the microlens parallax was not constrained due to the relatively short time-scale (t E = 24 d). From a Bayesian analysis, we find that the host star is a dwarf star M_{\rm host}=0.43^{+0.33}_{-0.22} \ \mathrm{M}_{\odot } at a distance D_{\rm L}=6.22^{+1.03}_{-1.51}\ {\rm kpc} and the planet is a Jovian-mass planet M_{\rm p}=0.77^{+0.77}_{-0.53} \ M_{\rm J} with a projected separation a_{\perp }=3.30^{+0.59}_{-0.83}\ {\rm au} . The planet orbits beyond the snow line of the host star. Considering the relative lens-source proper motion of \mu _{\rm rel} = 5.58 \pm 0.38\ \rm mas\ yr^{-1} , the lens can be resolved by adaptive optics with a 30 m telescope in the future.",Monthly Notices of the Royal Astronomical Society,February 2021,2706 - 2712,,,10.1093/mnras/stab534,https://doi.org/10.1093/mnras/stab534,OUP
An 2.31uJ/Inference Ultra-Low Power Always-on Event-Driven AI-IoT SoC With Switchable nvSRAM Compute-in-Memory Macro,Haoyang Sang; Wenao Xie; Gwangtae Park; Hoi-Jun Yoo; ; ; ; ,https://ieeexplore.ieee.org/document/10463613/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10463613,"Internet-of-Things (IoT) drives the demand for artificial intelligence (AI) system-on-chips (SoCs) for vast always-on ultra-low power applications such as human action recognition (HAR) for surveillance systems, face detection (FD) and recognition (FR) for home security, etc. Previous AI-IoT SoCs still face limited system efficiency caused by the high leaky power of SRAMs, huge external memory access (EMA), and frequent on-chip data transfer. The proposed ultra-low power RISC-V embedded AI-IoT SoC is composed of 1) a novel bit-line (BL) segmented coupled nvSRAM macro with switchable working modes: SRAM, non-volatile memory (NVM), NVM computing in memory (CIM), performing pre-charge reusing, power gating and local data swapping; 2) a hot-silent encoded (HSE) uDMA cluster with 1MB multi-bank eMRAM to reduce the on-chip transmission power and eliminate the EMA power; 3) and an event-driven wake-up unit (EDWU) for skipping unnecessary inference; 4) a RISC-V core with dedicated ISA extension for switchable working modes. The proposed SoC achieves an energy efficiency of 20.3–35.5 TOPS/W @ResNet-20 (fix-point-8, FXP8) inferencing, which shows a $2.82\times $ – $3.69\times $ efficiency improvement compared to the previous state-of-the-art (SOTA) AI-IoT SoCs.",IEEE Transactions on Circuits and Systems II: Express Briefs,08 March 2024,2534 - 2538,,,10.1109/TCSII.2024.3374885,https://doi.org/10.1109/TCSII.2024.3374885,IEEE
Intervention of Machine Learning and Explainable Artificial Intelligence in Fiber-Optic Sensor Device Data for Systematic and Comprehensive Performance Optimization,Jatin Rana; Anuj K. Sharma; Yogendra Kumar Prajapati; ; ; ,https://ieeexplore.ieee.org/document/10643268/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10643268,"This letter illustrates the successful application of machine learning (ML) models with explainable artificial intelligence (XAI) to enhance the efficacy of a surface plasmon resonance (SPR)-based fiber-optic sensor device (FOSD). The investigation also examines the correlation between the sensor's figure of merit (FoM) and the following variables: light wavelength (λ), sensing region length, metal layer thickness, and refractive index (RI) of surrounding (i.e., sensing or analyte) medium. The study established that the FoM datasets were consistent with various boosting algorithms, such as XGBoost, CatBoost, etc. Incorporating these algorithms into datasets with a λ-resolution of 1 nm led to enhanced FoM magnitudes. The dataset comprises 32 768 data points, each of which falls within one of 15 distinct thickness values and 25 distinct sensing length values. The selected CatBoost ML model exhibits a high level of consistency with the data in terms of trend matching, with all other evaluation parameters lying within acceptable ranges. Furthermore, we have implemented XAI to gain a more comprehensive understanding of the model's internal mechanism in relation to FoM prediction. The results from the shapley additive explanations (SHAP) method indicate that analyte RI and λ play significantly bigger role in dictating the FoM of the SPR-based FOSD. This study emphasizes that the efficient finalization of sensor design and improved sensing performance can be achieved by selecting an appropriate ML model along with XAI and implementing it on a variety of FOSD datasets.",IEEE Sensors Letters,21 August 2024,,2475-1472,,10.1109/LSENS.2024.3445324,https://doi.org/10.1109/LSENS.2024.3445324,IEEE
A Conceptual Model Framework for XAI Requirement Elicitation of Application Domain System,Maria Aslam; Diana Segura-Velandia; Yee Mey Goh; ; ; ,https://ieeexplore.ieee.org/document/10251525/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10251525,"The use of data analytics and Machine Learning (ML) branches of AI for predictive and analytic knowledge retrieval has surged significantly in various industries (e.g., health, finance, business, and manufacturing). However, the acceptance of AI has been hindered by opaque models that lack transparency. Explainability in AI (XAI) has gained significant prominence owing to its focus on introducing avenues of accountability in AI. XAI acknowledges the importance of human factors and strives to incorporate them into the design process, recognising that the cognitive effort involved in understanding explanations is a key aspect. Mental Models play a crucial role in the XAI evaluative premise, but their current utility is limited. By intentionally designing explanations that align with users’ mental models, their experiences can be significantly enhanced, leading to improved understanding, satisfaction, trust, and performance. This study proposes using Mental Models to elicit explainability requirements and to develop an Ontology-Driven Conceptual Model to facilitate the learning process for a better understanding of explanations.",IEEE Access,14 September 2023,108080 - 108091,2169-3536,,10.1109/ACCESS.2023.3315605,https://doi.org/10.1109/ACCESS.2023.3315605,IEEE
"A Multifaceted Survey on Federated Learning: Fundamentals, Paradigm Shifts, Practical Issues, Recent Developments, Partnerships, Trade-Offs, Trustworthiness, and Ways Forward",Abdul Majeed; Seong Oun Hwang; ; ,https://ieeexplore.ieee.org/document/10555253/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10555253,"Federated learning (FL) is considered a de facto standard for privacy preservation in AI environments because it does not require data to be aggregated in some central place to train an AI model. Preserving data on the client side and sharing only the model’s parameters with a central server preserves privacy while training an AI model of higher generalizability. Unfortunately, sharing the model’s parameters with the server can create privacy leaks, and therefore, FL is unable to meet privacy requirements in many situations. Furthermore, FL is prone to other technical issues, such as data poisoning, model poisoning, fairness, client dropout, and convergence issues, to name just a few. In this work, we provide a multifaceted survey on FL, including its fundamentals, paradigm shifts, technical issues, recent developments, and future prospects. First, we discuss the fundamental concepts of FL (workflow, categorization, the differences between centralized learning and FL, and applications of FL in diverse fields), and we then discuss the paradigm shifts brought on by FL from a broader perspective (e.g., data use, AI model development, resource sharing, etc.). Later, we pinpoint ten practical issues currently hindering the viability of the FL landscape, and we discuss developments made under each issue by summarizing state-of-the-art (SOTA) literature. We highlight FL partnerships with two or more technologies that either improve practical aspects/issues in FL or extend its adoption to new areas/domains. We pinpoint various trade-offs that exist in an FL ecosystem, and the corresponding SOTA developments to mitigate them. We also discuss the latest studies that have been proposed to make FL trustworthy and beneficial for the community. Lastly, we suggest valuable research directions towards enhancing technical efficacy by guiding researchers to less explored topics in FL.",IEEE Access,12 June 2024,84643 - 84679,2169-3536,,10.1109/ACCESS.2024.3413069,https://doi.org/10.1109/ACCESS.2024.3413069,IEEE
A Survey on the Convergence of Edge Computing and AI for UAVs: Opportunities and Challenges,Patrick McEnroe; Shen Wang; Madhusanka Liyanage; ; ; ,https://ieeexplore.ieee.org/document/9778241/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9778241,"The latest 5G mobile networks have enabled many exciting Internet of Things (IoT) applications that employ unmanned aerial vehicles (UAVs/drones). The success of most UAV-based IoT applications is heavily dependent on artificial intelligence (AI) technologies, for instance, computer vision and path planning. These AI methods must process data and provide decisions while ensuring low latency and low energy consumption. However, the existing cloud-based AI paradigm finds it difficult to meet these strict UAV requirements. Edge AI, which runs AI on-device or on edge servers close to users, can be suitable for improving UAV-based IoT services. This article provides a comprehensive analysis of the impact of edge AI on key UAV technical aspects (i.e., autonomous navigation, formation control, power management, security and privacy, computer vision, and communication) and applications (i.e., delivery systems, civil infrastructure inspection, precision agriculture, search and rescue (SAR) operations, acting as aerial wireless base stations (BSs), and drone light shows). As guidance for researchers and practitioners, this article also explores UAV-based edge AI implementation challenges, lessons learned, and future research directions.",IEEE Internet of Things Journal,19 May 2022,15435 - 15459,,,10.1109/JIOT.2022.3176400,https://doi.org/10.1109/JIOT.2022.3176400,IEEE
AI-RAN in 6G Networks: State-of-the-Art and Challenges,Naveed Ali Khan; Stefan Schmid; ; ,https://ieeexplore.ieee.org/document/10360202/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10360202,"6G is a next-generation cellular communication technology that builds up on existing 5G networks which are currently rolled out worldwide. Through incorporation of artificial intelligence (AI) and machine learning (ML), the core 5G network is advanced into an intelligent 6G network. The 6G Artificial Intelligence Radio Access Network (AI-RAN) is anticipated to offer advanced features like reduced latency, improved bandwidth, data rates and coverage. Furthermore, AI-RAN is expected to support complex use cases such as extreme connectivity, multi-user communications and dynamic spectrum access. This paper provides a detailed survey and thorough assessment of AI-RAN’s vision and state-of-the-art challenges. We first present a concise introduction to 6G AI-RAN followed by background information on the current 5G RAN and its challenges that must be overcome to implement 6G AI-RAN. The paper then examines trending research issues in AI-RAN, i.e., challenges related to spectrum allocation, network architecture, and resource management. We discuss the methods to overcome these challenges which include the adoption of advanced machine learning and edge computing technologies to boost the performance of 6G AI-RAN. We conclude by stating open research directions.",IEEE Open Journal of the Communications Society,14 December 2023,294 - 311,2644-125X,,10.1109/OJCOMS.2023.3343069,https://doi.org/10.1109/OJCOMS.2023.3343069,IEEE
Systemic Oversimplification Limits the Potential for Human-AI Partnership,Jason S. Metcalfe; Brandon S. Perelman; David L. Boothe; Kaleb Mcdowell; ; ; ; ,https://ieeexplore.ieee.org/document/9425540/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9425540,"The modern world is evolving rapidly, especially with respect to the development and proliferation of increasingly intelligent, artificial intelligence (AI) and AI-related technologies. Nevertheless, in many ways, what this class of technologies has offered as return on investment remains less impressive than what has been promised. In the present paper, we argue that the continued failure to realize the potential in modern AI and AI-related technologies is largely attributable to the oversimplified, yet pervasive ways that our global society treats the relationship between these technologies and humans. Oversimplified concepts, once conveyed, tend to perpetuate myths that in turn limit the impact of such technologies in human society. To counter these oversimplifications, we offer a theoretical construct, which we call the landscape of human-AI partnership. This construct characterizes individual capability for real-world task performance as a dynamic function of information certainty, available time to respond, and task complexity. With this, our goal is to encourage more nuanced discourse about novel ways to solve challenges to modern and future sociotechnical societies, but without defaulting to notions that remain rooted in today's technologies-as-tools ways of thinking. The core of our argument is that society at large must recognize that intelligent technologies are evolving well beyond being mere tools for human use and are instead becoming capable of operating as interdependent teammates. This means that how we think about interactions between humans and AI needs to go beyond a “Human-or-AI” conversation about task assignments to more contextualized “Human-and-AI” way of thinking about how best to capitalize on the strengths hidden within emergent capabilities of unique human-AI partnerships that have yet to be fully realized.",IEEE Access,07 May 2021,70242 - 70260,2169-3536,,10.1109/ACCESS.2021.3078298,https://doi.org/10.1109/ACCESS.2021.3078298,IEEE
Study of an Evaluation Model for AIS Receiver Sensitivity Measurements,Qing Hu; Jingyun Cao; Gemengyue Gao; Linlin Xu; Meng’en Song; ; ; ; ; ,https://ieeexplore.ieee.org/document/8686151/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8686151,"To guarantee that ships can navigate safely, the International Maritime Organization mandates that all ships navigating internationally must install the automatic identification system (AIS). AIS works in the very high-frequency (VHF) maritime mobile band, and to ensure the signal receiving performance of AIS equipment, it is necessary that the receiver sensitivity can be quickly evaluated and detected. Hence, we propose an evaluation model of AIS receiver sensitivity. The model first measures the packet error rate (PER) of AIS data transmission at a specific power. The distribution of the AIS receiver sensitivity characteristic curve under any transmitted power can be directly obtained, and then whether or not the sensitivity of the AIS receiver satisfies the performance requirements can be quickly evaluated. Regression analysis and the results of actual measurement demonstrate that this model has a goodness of fit (R-squared) value of 0.99 between the power-PER curve of the analog input signal and the measured data, which signifies test efficiency and accuracy beyond conventional test methods.",IEEE Transactions on Instrumentation and Measurement,11 April 2019,1118 - 1126,,,10.1109/TIM.2019.2910341,https://doi.org/10.1109/TIM.2019.2910341,IEEE
Real-Time Diagnostic Technique for AI-Enabled System,Hiroaki Itsuji; Takumi Uezono; Tadanobu Toba; Subrata Kumar Kundu; ; ; ; ,https://ieeexplore.ieee.org/document/10614714/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10614714,"The last few decades have witnessed a dramatic evolution of Artificial Intelligence (AI) algorithms, represented by Deep Neural Networks (DNNs), resulting in AI-enabled systems being significantly dominant in various fields, including robotics, healthcare, and mobility. AI-enabled systems are currently used even for safety-critical applications, including automated driving, where they encounter reliability challenges from both hardware (HW) and software (SW) perspectives. However, there is no effective technique available that can diagnose HW and SW of AI-enabled systems in real-time during operation. Therefore, this paper proposes an intelligent real-time diagnostic technique for detecting HW and SW anomalies of AI-enabled systems and continuously improving the SW quality during operation. The proposed technique can detect HW anomalies to avoid unexpected changes in AI parameters and subsequent AI performance degradation using single context data with a detection accuracy of more than 92%. The proposed technique can also detect SW anomalies and identify edge cases in real-time, which could result in performance degradation by more than 50% compared to normal conditions. The identified edge cases can be used to continuously enhance the SW quality. Experimental results show the effectiveness of the technique for practical applications and thus can contribute to realize reliable and improved AI-enabled systems.",IEEE Open Journal of Intelligent Transportation Systems,30 July 2024,483 - 494,2687-7813,,10.1109/OJITS.2024.3435712,https://doi.org/10.1109/OJITS.2024.3435712,IEEE
AICyber-Chain: Combining AI and Blockchain for Improved Cybersecurity,Zia Ullah; Abdul Waheed; Muhammad Ismail Mohmand; Sadia Basar; Mahdi Zareei; Fausto Granda; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10684180/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10684180,"Artificial intelligence (AI) is one of the key technologies emerging in the Industrial Revolution that could protect against cybersecurity threats. AI is a key component of big data analytics and enables accurate real-time data analysis. AI can analyze big data, but it has some issues with security, privacy, and centralization of data. Moreover, cybercriminals continue to advance, so law enforcement faces more threats. With traditional cybersecurity solutions, sophisticated cyber-attacks are harder to detect and defend against. In complex cyberspaces, AI algorithms mine valuable features from data. However, the data on the Internet is scattered and controlled by different parties, making it challenging to authorize and validate its use. The AICyber-Chain model is presented in this paper for securely storing, calculating, and distributing data on the Internet at an enterprise scale. In a large-scale Internet environment, our proposed AICyber-Chain model integrates three key components to ensure a more secure cyberspace, enhancing AI, namely: Firstly, blockchain-based data sharing guarantees ownership at a large scale, enabling real-time data sharing. Secondly, a platform powered by AI makes cyberspace more trustworthy. Thirdly, sharing data or services rewards participants financially, which promotes sharing. We also discuss a typical use scenario, an alternative deployment method, and its security and commercial efficacy. Also, we simulated our model on Ethereum’s official test network, called Rinkeby, to demonstrate its practicality and efficiency. This model speeds up authentication by 1.8 times compared to the centralized model. In addition, our proposed solution reduces gas consumption by 20 to 25%. Our paper aims to serve as a guide and reference point for cybersecurity researchers and industry practitioners, especially from an intelligent computing or AI-based technical standpoint.",IEEE Access,19 September 2024,142194 - 142214,2169-3536,,10.1109/ACCESS.2024.3463976,https://doi.org/10.1109/ACCESS.2024.3463976,IEEE
User-Centric Explainability in Healthcare: A Knowledge-Level Perspective of Informed Machine Learning,Luis Oberste; Armin Heinzl; ; ,https://ieeexplore.ieee.org/document/9971460/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9971460,"Impact Statement:
The majority of investigations of the explainability challenge are being conducted from a developer-oriented focus, typically summarizing end-users based on their role or machine learning expertise. However, users are far more heterogeneous, with varying backgrounds, experiences, and needs. This motivates a recent surge of interest in explanations that account for multifaceted user requirements. However, how to effectively develop user-centric explanations is still unclear, and research lacks an understanding of which role users knowledge plays in developing satisfactory explanations. This synopsis acknowledges the potential of knowledge-informed machine learning for richer explanations. It is among the first to investigate how this strengthens user understanding from a knowledge perspective. It pinpoints knowledge characteristics of the fit between system explanations and users, which can guide the design of more user-centric clinical information systems.",IEEE Transactions on Artificial Intelligence,06 December 2022,840 - 857,2691-4581,,10.1109/TAI.2022.3227225,https://doi.org/10.1109/TAI.2022.3227225,IEEE
Enhancing Multilingual Hate Speech Detection: From Language-Specific Insights to Cross-Linguistic Integration,Ehtesham Hashmi; Sule Yildirim Yayilgan; Ibrahim A. Hameed; Muhammad Mudassar Yamin; Mohib Ullah; Mohamed Abomhara; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10662891/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10662891,"The rise of social media has enabled individuals with biased perspectives to spread hate speech, directing it toward individuals based on characteristics such as race, gender, religion, or sexual orientation. Constructive interactions in varied communities can greatly enhance self-esteem, yet it is vital to consider that adverse comments may affect individuals’ social standing and emotional health. The crucial task of detecting and addressing this type of content is imperative for reducing its negative effects on communities and individuals alike. The rising occurrence highlights the urgency for enhanced methods and robust regulations on digital platforms to protect humans from such prejudicial and damaging conduct. Hate speech typically appears as a deliberate hostile action aimed at a particular group, often with the intent to demean or isolate them based on various facets of their identity. Research on hate speech predominantly targets resource-aware languages like English, German, and Chinese. Conversely, resource-limited languages, including European languages such as Italian, Spanish, and Portuguese, alongside Asian languages like Roman Urdu, Korean, and Indonesian, present obstacles. These challenges arise from a lack of linguistic resources, making the extraction of information a more strenuous task. This study is focused on the detection and improvement of multilingual hate speech detection across 13 different languages. To conduct a thorough analysis, we carried out a series of experiments that ranged from classical machine learning techniques and mainstream deep learning approaches to recent transformer-based methods. Through hyperparameter tuning, optimization techniques, and generative configurations, we achieved robust and generalized performance capable of effectively identifying hate speech across various dialects. Specifically, we achieved a notable enhancement in detection performance, with precision and recall metrics exceeding baseline models by ...",IEEE Access,02 September 2024,121507 - 121537,2169-3536,,10.1109/ACCESS.2024.3452987,https://doi.org/10.1109/ACCESS.2024.3452987,IEEE
Which Heroes to Pick? Learning to Draft in MOBA Games With Neural Networks and Tree Search,Sheng Chen; Menghui Zhu; Deheng Ye; Weinan Zhang; Qiang Fu; Wei Yang; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9476982/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9476982,"Hero drafting is essential in multiplayer online battle arena (MOBA) game playing as it builds the team of each side and directly affects the match outcome. State-of-the-art drafting methods fail to consider: 1) drafting efficiency when the hero pool is expanded; 2) the multiround nature of a MOBA 5v5 match series, i.e., two teams play best-of- N and the same hero is only allowed to be drafted once throughout the series. In this article, we formulate the drafting process as a multiround combinatorial game and propose a novel drafting algorithm based on neural networks and Monte Carlo tree search, named JueWuDraft. Specifically, we design a long-term value estimation mechanism to handle the best-of- N drafting case. Taking Honor of Kings , one of the most popular MOBA games at present, as a running case, we demonstrate the practicality and effectiveness of JueWuDraft when compared to state-of-the-art drafting methods.",IEEE Transactions on Games,07 July 2021,410 - 421,,,10.1109/TG.2021.3095264,https://doi.org/10.1109/TG.2021.3095264,IEEE
Protecting Intellectual Property With Reliable Availability of Learning Models in AI-Based Cybersecurity Services,Ge Ren; Jun Wu; Gaolei Li; Shenghong Li; Mohsen Guizani; ; ; ; ; ,https://ieeexplore.ieee.org/document/9954194/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9954194,"Artificial intelligence (AI)-based cybersecurity services offer significant promise in many scenarios, including malware detection, content supervision, and so on. Meanwhile, many commercial and government applications have raised the need for intellectual property protection of using deep neural network (DNN). Existing studies (e.g., watermarking techniques) on intellectual property protection only aim at inserting secret information into DNNs, allowing producers to detect whether the given DNN infringes on their own copyrights. However, since the availability protection of learning models is rarely considered, the piracy model can still work with high accuracy. In this paper, a novel model locking (M-LOCK) scheme for the DNN is proposed to enhance its availability protection, where the DNN produces poor accuracy if a specific token is absent, while it maps only the tokenized inputs into correct predictions. The proposed scheme performs the verification process during the DNN inference operation, actively protecting models’ intellectual property copyright at each query. Specifically, to train the token-sensitive decision-making boundaries of DNNs, a data poisoning-based model manipulation (DPMM) method is also proposed, which minimizes the correlation between the dummy outputs and correct predictions. Extensive experiments demonstrate the proposed scheme could achieve high reliability and effectiveness across various benchmark datasets as well as typical model protection methods.",IEEE Transactions on Dependable and Secure Computing,17 November 2022,600 - 617,,,10.1109/TDSC.2022.3222972,https://doi.org/10.1109/TDSC.2022.3222972,IEEE
GeoTrackNet—A Maritime Anomaly Detector Using Probabilistic Neural Network Representation of AIS Tracks and A Contrario Detection,Duong Nguyen; Rodolphe Vadaine; Guillaume Hajduch; René Garello; Ronan Fablet; ; ; ; ; ,https://ieeexplore.ieee.org/document/9353410/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9353410,"Representing maritime traffic patterns and detecting anomalies from them are key to vessel monitoring and maritime situational awareness. We propose a novel approach—referred to as GeoTrackNet —for maritime anomaly detection from AIS data streams. Our model exploits state-of-the-art neural network schemes to learn a probabilistic representation of AIS tracks and a contrario detection to detect abnormal events. The neural network provides a new means to capture complex and heterogeneous patterns in vessels’ behaviours, while the a contrario detector takes into account the fact that the learnt distribution may be location-dependent. Experiments on a real AIS dataset comprising more than 4.2 million AIS messages demonstrate the relevance of the proposed method compared with state-of-the-art schemes.",IEEE Transactions on Intelligent Transportation Systems,11 February 2021,5655 - 5667,,,10.1109/TITS.2021.3055614,https://doi.org/10.1109/TITS.2021.3055614,IEEE
A Survey of Data-Driven and Knowledge-Aware eXplainable AI,Xiao-Hui Li; Caleb Chen Cao; Yuhan Shi; Wei Bai; Han Gao; Luyu Qiu; Cong Wang; Yuanyuan Gao; Shenjia Zhang; Xun Xue; Lei Chen; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9050829/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9050829,"We are witnessing a fast development of Artificial Intelligence (AI), but it becomes dramatically challenging to explain AI models in the past decade. “Explanation” has a flexible philosophical concept of “satisfying the subjective curiosity for causal information”, driving a wide spectrum of methods being invented and/or adapted from many aspects and communities, including machine learning, visual analytics, human-computer interaction and so on. Nevertheless, from the view-point of data and knowledge engineering (DKE), a best explaining practice that is cost-effective in terms of extra intelligence acquisition should exploit the causal information and explaining scenarios which is hidden richly in the data itself. In the past several years, there are plenty of works contributing in this line but there is a lack of a clear taxonomy and systematic review of the current effort. To this end, we propose this survey, reviewing and taxonomizing existing efforts from the view-point of DKE, summarizing their contribution, technical essence and comparative characteristics. Specifically, we categorize methods into data-driven methods where explanation comes from the task-related data, and knowledge-aware methods where extraneous knowledge is incorporated. Furthermore, in the light of practice, we provide survey of state-of-art evaluation metrics and deployed explanation applications in industrial practice.",IEEE Transactions on Knowledge and Data Engineering,30 March 2020,29 - 49,,,10.1109/TKDE.2020.2983930,https://doi.org/10.1109/TKDE.2020.2983930,IEEE
An Explainable AI-Based Intrusion Detection System for DNS Over HTTPS (DoH) Attacks,Tahmina Zebin; Shahadate Rezvy; Yuan Luo; ; ; ,https://ieeexplore.ieee.org/document/9796558/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9796558,"Over the past few years, Domain Name Service (DNS) remained a prime target for hackers as it enables them to gain first entry into networks and gain access to data for exfiltration. Although the DNS over HTTPS (DoH) protocol has desirable properties for internet users such as privacy and security, it also causes a problem in that network administrators are prevented from detecting suspicious network traffic generated by malware and malicious tools. To support their efforts in maintaining a secure network, in this paper, we have implemented an explainable AI solution using a novel machine learning framework. We have used the publicly available CIRA-CIC-DoHBrw-2020 dataset for developing an accurate solution to detect and classify the DNS over HTTPS attacks. Our proposed balanced and stacked Random Forest achieved very high precision (99.91%), recall (99.92%) and F1 score (99.91%) for the classification task at hand. Using explainable AI methods, we have additionally highlighted the underlying feature contributions in an attempt to provide transparent and explainable results from the model.",IEEE Transactions on Information Forensics and Security,15 June 2022,2339 - 2349,,,10.1109/TIFS.2022.3183390,https://doi.org/10.1109/TIFS.2022.3183390,IEEE
HierTrain: Fast Hierarchical Edge AI Learning With Hybrid Parallelism in Mobile-Edge-Cloud Computing,Deyin Liu; Xu Chen; Zhi Zhou; Qing Ling; ; ; ; ,https://ieeexplore.ieee.org/document/9094236/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9094236,"Nowadays, deep neural networks (DNNs) are the core enablers for many emerging edge AI applications. Conventional approaches for training DNNs are generally implemented at central servers or cloud centers for centralized learning, which is typically time-consuming and resource-demanding due to the transmission of a large number of data samples from the edge device to the remote cloud. To overcome these disadvantages, we consider accelerating the learning process of DNNs on the Mobile-Edge-Cloud Computing (MECC) paradigm. In this paper, we propose HierTrain, a hierarchical edge AI learning framework, which efficiently deploys the DNN training task over the hierarchical MECC architecture. We develop a novel hybrid parallelism method, which is the key to HierTrain, to adaptively assign the DNN model layers and the data samples across the three levels of the edge device, edge server and cloud center. We then formulate the problem of scheduling the DNN training tasks at both layer-granularity and sample-granularity. Solving this optimization problem enables us to achieve the minimum training time. We further implement a hardware prototype consisting of an edge device, an edge server and a cloud server, and conduct extensive experiments on it. Experimental results demonstrate that HierTrain can achieve up to 6.9\times speedups compared to the cloud-based hierarchical training approach.",IEEE Open Journal of the Communications Society,15 May 2020,634 - 645,2644-125X,,10.1109/OJCOMS.2020.2994737,https://doi.org/10.1109/OJCOMS.2020.2994737,IEEE
$\alpha$-Satellite: An AI-Driven System and Benchmark Datasets for Dynamic COVID-19 Risk Assessment in the United States,Yanfang Ye; Shifu Hou; Yujie Fan; Yiming Zhang; Yiyue Qian; Shiyu Sun; Qian Peng; Mingxuan Ju; Wei Song; Kenneth Loparo; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9141399/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9141399,"The fast evolving and deadly outbreak of coronavirus disease (COVID-19) has posed grand challenges to human society. To slow the spread of virus infections and better respond for community mitigation, by advancing capabilities of artificial intelligence (AI) and leveraging the large-scale and up-to-date data generated from heterogeneous sources (e.g., disease related data, demographic, mobility and social media data), in this work, we propose and develop an AI-driven system (named α-Satellite), as an initial offering, to provide dynamic COVID-19 risk assessment in the United States. More specifically, given a point of interest (POI), the system will automatically provide risk indices associated with it in a hierarchical manner (e.g., state, county, POI) to enable people to select appropriate actions for protection while minimizing disruptions to daily life. To comprehensively evaluate our system for dynamic COVID-19 risk assessment, we first conduct a set of empirical studies; and then we validate it based on a real-world dataset consisting of 5,060 annotated POIs, which achieves the area of under curve (AUC) of 0.9202. As of June 18, 2020, α-Satellite has had 56,980 users. Based on the feedback from its large-scale users, we perform further analysis and have three key findings: i) people from more severe regions (i.e., with larger numbers of COVID-19 cases) have stronger interests using our system to assist with actionable information; ii) users are more concerned about their nearby areas in terms of COVID-19 risks; iii) the user feedback about their perceptions towards COVID-19 risks of their query POIs indicate the challenge of public concerns about the safety versus its negative effects on society and the economy. Our system and generated datasets have been made publicly accessible via our website.",IEEE Journal of Biomedical and Health Informatics,15 July 2020,2755 - 2764,,32750960,10.1109/JBHI.2020.3009314,https://doi.org/10.1109/JBHI.2020.3009314,IEEE
Parkinson’s Disease Recognition Using SPECT Image and Interpretable AI: A Tutorial,Theerasarn Pianpanit; Sermkiat Lolak; Phattarapong Sawangjai; Thapanun Sudhawiyangkul; Theerawit Wilaiprasitporn; ; ; ; ; ,https://ieeexplore.ieee.org/document/9424574/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9424574,"In the past few years, there are several researches on Parkinson’s disease (PD) recognition using single-photon emission computed tomography (SPECT) images with deep learning (DL) approach. However, the DL model’s complexity usually results in difficultmodel interpretation when used in clinical. Even though there are multiple interpretation methods available for the DL model, there is no evidence of which method is suitable for PD recognition application. This tutorial aims to demonstrate the procedure to choose a suitable interpretationmethod for the PD recogni-tion model. We exhibit four DCNN architectures as an example and introduce six well-known interpretationmethods. Finally, we propose an evaluation method to measure the interpretation performance and a method to use the interpreted feedback for assisting in model selection. The evaluation demonstrates that the guided backpropagation and SHAP interpretation methods are suitable for PD recognition methods in different aspects. Guided backpropagation has the best ability to show fine-grained importance, which is proven by the highest Dice coefficient and lowest mean square error. On the other hand, SHAP can generate a better quality heatmap at the uptake depletion location, which outperforms other methods in discriminating the difference between PD and NC subjects. Shortly, the introduced interpretationmethods can contribute to not only the PD recognition application but also to sensor data processing in an AI Era (interpretable-AI) as feedback in constructing well-suited deep learning architectures for specific applications.",IEEE Sensors Journal,06 May 2021,22304 - 22316,,,10.1109/JSEN.2021.3077949,https://doi.org/10.1109/JSEN.2021.3077949,IEEE
FHI-Unet: Faster Heterogeneous Images Semantic Segmentation Design and Edge AI Implementation for Visible and Thermal Images Processing,Ming-Hwa Sheu; S. M. Salahuddin Morsalin; Szu-Hong Wang; Lin-Keng Wei; Shih-Chang Hsia; Chuan-Yu Chang; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9713892/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9713892,"The same class of objects clustering process in a frame is known as semantic segmentation. The deep convolutional neural network-based semantic segmentation needs large-scale computations and annotations for data training to reach real-time inference speeds. The heterogeneous image segmentation is a more challenging task to categorize each pixel of an image. However, the heterogeneous image semantic segmentation method extracts the features of visible and thermal images separately. We designed an efficient architecture with the multi-hybrid-autoencoder and decoder for Faster Heterogeneous Image (FHI) Semantic Segmentation. The proposed corresponding architecture has fewer layers resulting in lower parameters, higher inference speed, and Intersection over Union (IoU). The specialty of this architecture is the discrete autonomous feature extraction framework for RGB image and Thermal (T) image inputs with individual convolutional layers. Later, we combined the 4-channels (RGBT) convolution features to reduce computational complexity and robust the model performances. The proposed FHI-Unet semantic segmentation model experimented on NVIDIA Xavier NX edge AI platforms with standard accuracy under the real-time inference requirement. The proposed FHI-Unet model has the highest mIoU of 43.67 and the fastest real-time inference of 83.39 frames per second on edge AI implementation. The proposed approach improves 31.36% inference speed, 7.16% mAcc, and 5.1% mIoU on the Multi-spectral Semantic Segmentation Dataset compared with the existing works.",IEEE Access,14 February 2022,18596 - 18607,2169-3536,,10.1109/ACCESS.2022.3151375,https://doi.org/10.1109/ACCESS.2022.3151375,IEEE
SignExplainer: An Explainable AI-Enabled Framework for Sign Language Recognition With Ensemble Learning,Deep R. Kothadiya; Chintan M. Bhatt; Amjad Rehman; Faten S. Alamri; Tanzila Saba; ; ; ; ; ,https://ieeexplore.ieee.org/document/10122570/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10122570,"Deep learning has significantly aided current advancements in artificial intelligence. Deep learning techniques have significantly outperformed more than typical machine learning approaches, in various fields like Computer Vision, Natural Language Processing (NLP), Robotics Science, and Human-Computer Interaction (HCI). Deep learning models are ineffective in outlining their fundamental mechanism. That’s the reason the deep learning model mainly consider as Black-Box. To establish confidence and responsibility, deep learning applications need to explain the model’s decision in addition to the prediction of results. The explainable AI (XAI) research has created methods that offer these interpretations for already trained neural networks. It’s highly recommended for computer vision tasks relevant to medical science, defense system, and many more. The proposed study is associated with XAI for Sign Language Recognition. The methodology uses an attention-based ensemble learning approach to create a prediction model more accurate. The proposed methodology used ResNet50 with the Self Attention model to design ensemble learning architecture. The proposed ensemble learning approach has achieved remarkable accuracy at 98.20%. In interpreting ensemble learning prediction, the author has proposed SignExplainer to explain the relevancy (in percentage) of predicted results. SignExplainer has illustrated excellent results, compared to other conventional Explainable AI models reported in state of the art.",IEEE Access,10 May 2023,47410 - 47419,2169-3536,,10.1109/ACCESS.2023.3274851,https://doi.org/10.1109/ACCESS.2023.3274851,IEEE
Blockchain-Based Authentication and Explainable AI for Securing Consumer IoT Applications,Randhir Kumar; Danish Javeed; Ahamed Aljuhani; Alireza Jolfaei; Prabhat Kumar; A. K. M. Najmul Islam; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10266715/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10266715,"The consumer Internet of Things (IoT) applications in particular smart cities are mostly equipped with Internet-connected networked devices to improve city operations by giving access to a massive amount of valuable information. However, these smart devices in a smart city environment mostly use public channels to access and share data among different participants. This has introduced a great interest in using authentication and key agreement (AKA) mechanisms and intrusion detection systems (IDS) based on artificial intelligence (AI) techniques. However, most of the AKA mechanisms have high computation and communication costs and cannot be trusted completely. On the other hand, the AI-based IDS are treated as blackbox by the security analyst due to their inability to explain the reasons behind the decision. In this direction, we have integrated blockchain-based AKA mechanism with explainable artificial intelligence (XAI) for securing smart city-based consumer applications. Specifically, first, the participating entities communicate with each other in a secure manner to exchange data using a blockchain-based AKA mechanism. On the other hand, we have used SHapley Additive exPlanations (SHAP) mechanism to explain and interpret the prominent features that are most influential in the decision. The practical implementation of the proposed framework proves the efficiency over other recent state-of-the-art techniques.",IEEE Transactions on Consumer Electronics,28 September 2023,1145 - 1154,,,10.1109/TCE.2023.3320157,https://doi.org/10.1109/TCE.2023.3320157,IEEE
Explainable AI for Multimodal Credibility Analysis: Case Study of Online Beauty Health (Mis)-Information,Vidisha Wagle; Kulveen Kaur; Pooja Kamat; Shruti Patil; Ketan Kotecha; ; ; ; ; ,https://ieeexplore.ieee.org/document/9531594/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9531594,"“One person’s data or experience is another person’s information” this has become the golden rule of the 21st century which has resulted in a massive reservoir of data and immense amounts of information generation. However, there is no control over the source of this information, accessibility of this information, or the quality of it, which has given rise to the presence of “misinformation.” The research community has reacted by proposing frameworks and difficulties, which are helpful for (different subtasks of) recognizing misinformation. Most of these frameworks, however, fail to consider all the aspects that can contribute to making information “credible”. Furthermore, a valid explanation for each considered feature’s contribution to the model’s decision stands missing in most work. With this in mind, the authors have attempted to produce a system that yields highly accurate decisions, thus effectively separating credible health blogs from their non-credible counterparts while providing valid user-friendly explanations. The study proposes an Explainable AI-assisted Multimodal Credibility Assessment System that examines the credibility of the platform where the blog is hosted, the credibility of the author of the blog and the credibility of the images that contribute to the blog. This novel framework contributes to the existing body of knowledge by assessing the credibility of misleading beauty blogs using multiple crucial modalities which would lead to an insightful information consumption by the users. The proposed pipeline was successfully implemented on multiple carefully curated datasets and correctly identified 274 non credible blogs out of 321 blogs with an accuracy of 97.5%, Precision of 0.973 & F1score of 0.986. Further, the Explainable AI model, with the help of several visualizations displayed the feature contributions for each blog & it’s impact and magnitude in a concise comprehensible format. The framework can be further customized and applied to va...",IEEE Access,09 September 2021,127985 - 128022,2169-3536,,10.1109/ACCESS.2021.3111527,https://doi.org/10.1109/ACCESS.2021.3111527,IEEE
A Black-Box Attack Algorithm Targeting Unlabeled Industrial AI Systems With Contrastive Learning,Mingxing Duan; Guoqing Xiao; Kenli Li; Bin Xiao; ; ; ; ,https://ieeexplore.ieee.org/document/10381512/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10381512,"Adversarial attack algorithms are useful for testing and improving the robustness of industrial AI models. However, attacking black-box models with limited queries and unknown real labels remains a significant challenge. To overcome this challenge, we propose using contrastive learning to train a generated substitute model called attack contrastive learning network (ACL-Net) to attack black-box models with very few queries and no real labels. ACL-Net achieves end-to-end contrastive learning during training without labels, which differs from previous contrastive learning methods that required separate training for the classification layer with labels. We improve ACL-Net's robustness by using adversarial examples to train it during the attack stage. This approach results in more effective adversarial examples generated by ACL-Net. We conducted extensive experiments to validate the effectiveness of ACL-Net. Compared with the latest algorithms, ACL-Net requires fewer queries to achieve better attack performance, demonstrating its superiority in query-efficient black-box attacks. Overall, our approach presents a promising solution to the challenge of attacking black-box models with limited queries and unknown real labels. Our results show the effectiveness of using contrastive learning to train generated substitute models, and the potential for improving the robustness of industrial AI models through adversarial attacks.",IEEE Transactions on Industrial Informatics,04 January 2024,6325 - 6335,,,10.1109/TII.2023.3345472,https://doi.org/10.1109/TII.2023.3345472,IEEE
Optimizing Signal Detection in MIMO Systems: AI vs Approximate and Linear Detectors,M. Y. Daha; Kiran Khurshid; M. I. Ashraf; M. U. Hadi; ; ; ; ,https://ieeexplore.ieee.org/document/10659043/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10659043,"Artificial intelligence has transformed multiple input multiple output (MIMO) technology into a promising candidate for six-generation networks. However, several interference signals impact the data transmission between various antennas; therefore, sophisticated signal detection techniques are required at the MIMO receiver to estimate the transmitted data. This letter presents an optimized AI-based signal detection technique called AIDETECT for MIMO systems. The proposed AIDETECT network model is developed based on an optimized deep neural network (DNN) architecture, whose efficiency lies in its lightweight network architecture. To train and test the AIDETECT network model, we generate and process the data in a suitable form based on the transmitted signal, channel information, and noise. Based on this data, we calculate the received signal at the receiver end, where the received signal and channel information were integrated into the AIDETECT network model to perform reliable signal detection. Simulation results show that at a 20-dB signal-to-noise ratio (SNR), the proposed AIDETECT technique achieves between 97.33% to 99.99% better performance compared to conventional MIMO detectors and is also able to accomplish between 25.34% to 99.98% better performance than other AI-based MIMO detectors for the considered performance metrics. In addition, due to lightweight network architecture, the proposed AIDETECT technique has also achieved much lower computational complexity than conventional and AI-based MIMO detectors.",IEEE Communications Letters,29 August 2024,2387 - 2391,,,10.1109/LCOMM.2024.3451655,https://doi.org/10.1109/LCOMM.2024.3451655,IEEE
Application of Example-Based Explainable Artificial Intelligence (XAI) for Analysis and Interpretation of Medical Imaging: A Systematic Review,Miguel Fontes; João Dallyson Sousa De Almeida; António Cunha; ; ; ,https://ieeexplore.ieee.org/document/10440088/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10440088,"Explainable Artificial Intelligence (XAI) is an area of growing interest, particularly in medical imaging, where example-based techniques show great potential. This paper is a systematic review of recent example-based XAI techniques, a promising approach that remains relatively unexplored in clinical practice and medical image analysis. A selection and analysis of recent studies using example-based XAI techniques for interpreting medical images was carried out. Several approaches were examined, highlighting how each contributes to increasing accuracy, transparency, and usability in medical applications. These techniques were compared and discussed in detail, considering their advantages and limitations in the context of medical imaging, with a focus on improving the integration of these technologies into clinical practice and medical decision-making. The review also pointed out gaps in current research, suggesting directions for future investigations. The need to develop XAI methods that are not only technically efficient but also ethically responsible and adaptable to the needs of healthcare professionals was emphasised. Thus, the paper sought to establish a solid foundation for understanding and advancing example-based XAI techniques in medical imaging, promoting a more integrated and patient-centred approach to medicine.",IEEE Access,19 February 2024,26419 - 26427,2169-3536,,10.1109/ACCESS.2024.3367606,https://doi.org/10.1109/ACCESS.2024.3367606,IEEE
Counterfactual Explanations With Multiple Properties in Credit Scoring,Xolani Dastile; Turgay Celik; ; ,https://ieeexplore.ieee.org/document/10632141/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10632141,"EXplainable Artificial Intelligence (XAI) aims to reveal the reasons behind predictions from non-transparent classifiers. Explanations of automated decisions are important in critical domains such as finance, legal, and health. As a result, researchers and practitioners in recent years have actively worked on developing techniques that explain decisions from machine learning algorithms. For instance, an explanation technique called counterfactual explanation has recently been gaining traction in XAI. The interest in counterfactual explanations stems from the ability of the explanations to reveal what could have been different to achieve a desired outcome, as opposed to only highlighting important features. For instance, if a customer’s loan application is denied by the bank, a counterfactual will indicate the changes required for the customer to qualify for the loan in the future. For a counterfactual to be considered effective, several counterfactual properties must hold. This paper proposes a novel optimization formulation designed to generate counterfactual explanations that possess multiple properties concurrently. The efficacy of the proposed method is assessed on a publicly available credit dataset. The results showed a trade-off between validity and sparsity, which are both parts of a suite of counterfactual properties. Furthermore, the results showed that our proposed approach compromises validity to some degree but strikes a good balance between validity and sparsity.",IEEE Access,09 August 2024,110713 - 110728,2169-3536,,10.1109/ACCESS.2024.3441037,https://doi.org/10.1109/ACCESS.2024.3441037,IEEE
"Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers",Staphord Bengesi; Hoda El-Sayed; MD Kamruzzaman Sarker; Yao Houkpati; John Irungu; Timothy Oladunni; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10521640/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10521640,"The launch of ChatGPT in 2022 garnered global attention, marking a significant milestone in the Generative Artificial Intelligence (GAI) field. While GAI has been in effect for the past decade, the introduction of ChatGPT sparked a new wave of research and innovation in the Artificial Intelligence (AI) domain. This surge has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in GAI presents a wealth of exciting opportunities across various sectors, such as business, healthcare, education, entertainment, and media. However, concurrently, it poses unprecedented challenges such as impersonation, job displacement, privacy breaches, security vulnerabilities, and misinformation. To addressing these challenges requires a new direction for research to develop solutions and refine existing products. In our endeavor to contribute profound insights to society and advance research on GAI, we present a comprehensive journal which explores the theoretical and mathematical foundations of GAI state-of-the-art models, exploring the diverse spectrum of tasks they can perform, examining the challenges they entail, and discussing the promising prospects for the future of GAI.",IEEE Access,06 May 2024,69812 - 69837,2169-3536,,10.1109/ACCESS.2024.3397775,https://doi.org/10.1109/ACCESS.2024.3397775,IEEE
Developing Personalized Marketing Service Using Generative AI,Gun Ho Lee; Kyoung Jun Lee; Baek Jeong; Taekyung Kim; ; ; ; ,https://ieeexplore.ieee.org/document/10419357/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10419357,"In today’s world, the development of social network services (SNS) like Facebook and Instagram has enabled consumers to acquire information about products through various channels. The acquisition of diverse information has led to a diversification in consumer preferences and requirements. As consumer preferences diversify and online channels expand, there is an increasing need for companies to provide personalized marketing. Among the means of personalized marketing, personalized marketing messages are a key tool that can enhance customer engagement. However, a limitation of personalized marketing message services is the cost issue associated with manually writing individual marketing messages for personalization. To solve this problem, when developing automated technology for personalized marketing messages, there were concerns about the complexity of model development and the quality of messages generated automatically. In this study, we propose the Persuasive Message Intelligence (PMI) service, which utilizes the recently prominent Large Language Model for automated individual personalized marketing messages. PMI generates marketing messages through prompt engineering based on the theory of persuasion in marketing and prior research on AI-generated messages, and validates the elements of prompts through surveys. The trial and error of researchers presented in this study, along with the know-how and rules of prompt engineering, will serve as guidelines for those who wish to develop services through prompts in the future.",IEEE Access,05 February 2024,22394 - 22402,2169-3536,,10.1109/ACCESS.2024.3361946,https://doi.org/10.1109/ACCESS.2024.3361946,IEEE
Trust-Free Blockchain Framework for AI-Generated Content Trading and Management in Metaverse,Vu Tuan Truong; Hung Duy Le; Long Bao Le; ; ; ,https://ieeexplore.ieee.org/document/10466733/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10466733,"The rapid development of the metaverse and generative Artificial Intelligence (GAI) has led to the emergence of AI-Generated Content (AIGC). Unlike real-world products, AIGCs are represented as digital files, thus vulnerable to plagiarism and leakage on the Internet. In addition, the trading of AIGCs in the virtual world is prone to various trust issues between the involved participants. For example, some customers may try to avoid the payment after receiving the desired AIGC products, or the content sellers refuse to grant the products after obtaining the license fee. Existing digital asset management (DAM) systems often rely on a trusted third-party authority to mitigate these issues. However, this might lead to centralization problems such as the single-point-of-failure (SPoF) when the third parties are under attacks or being malicious. In this paper, we propose MetaTrade, a blockchain-empowered DAM framework that is designed to tackle these urgent trust issues, offering secured AIGC trading and management in the trustless metaverse environment. MetaTrade eliminates the role of the trusted third party, without requiring trust assumptions among participants. Numerical results show that MetaTrade offers higher performance and lower trading cost compared to existing platforms, while security analysis reveals that the framework is resilient against plagiarism, SPoF, and trust-related attacks. To showcase the feasibility of the design, a decentralized application (DApp) has been built on top of MetaTrade as a marketplace for metaverse AIGCs.",IEEE Access,18 March 2024,41815 - 41828,2169-3536,,10.1109/ACCESS.2024.3376509,https://doi.org/10.1109/ACCESS.2024.3376509,IEEE
"Leveraging the Synergy of IPv6, Generative AI, and Web Engineering to Create a Big Data-Driven Education Platform",Gao Yongli; Dong Qi; Chen Zhipeng; ; ; ,https://ieeexplore.ieee.org/document/10504107/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10504107,"The rapid advancement of network technology in China has significantly accelerated the implementation of information technology in higher education. Through the utilization of computer technology, multimedia technology, big data technology, artificial intelligence technology, and network communication technology, the integration of these technologies in university teaching has become widespread. This paper presents an analysis and discussion on the utilization of the latest IPv6 network transmission protocol technology to enhance the application of data collection in university education, with a specific focus on gathering information related to university faculties. By leveraging web engineering and multimedia technology as fundamental components, the network facilitates the sharing of educational resources among students, thereby enabling the reform of management approaches, fostering educational progress in China, and establishing a comprehensive big data-driven education platform specifically tailored to colleges and universities. Additionally, the incorporation of big data visualization and analysis tools allows for easy retrieval of existing university educational information, facilitates the creation of data charts, and expedites the utilization of data for its inherent value. Finally, the proposed approach employs generative AI to collect and analyze feedback from students and educators, followed by the application of web engineering techniques to continuously enhance the online education platform based on this feedback.",Journal of Web Engineering,March 2024,197 - 226,,,10.13052/jwe1540-9589.2321,https://doi.org/10.13052/jwe1540-9589.2321,River Publishers
XAI-3DP: Diagnosis and Understanding Faults of 3-D Printer With Explainable Ensemble AI,Deepraj Chowdhury; Aparna Sinha; Debanjan Das; ; ; ,https://ieeexplore.ieee.org/document/9980436/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9980436,"Additive manufacturing is one of the most widely used techniques in the domain of manufacturing. Three-dimensional (3-D) printers are one of those systems that made additive manufacturing easier. Fused-deposition-modeling-based 3-D printers provide cost-effective 3-D models. Like other mechanical systems, 3-D printers also face faults that damage the printing of the system. Hence, proper maintenance is required. The data-driven-based approach of the diagnosis of the fault in 3-D printers is proposed in this letter. Data are collected for three scenarios—1) healthy condition, 2) bed failure, and 3) arm failure. The ensemble learning model of Random Forest and XGBoost has been implemented with a ratio of 0.54 and 0.46, and a result of 99.75% accuracy is achieved, compared to 96% and 98% alone, respectively. The black box machine learning model is then further explained using the Shapley additive explanations library for the interpretation of the prediction, such that the trustworthiness of the artificial intelligence model gets improved.",IEEE Sensors Letters,12 December 2022,,2475-1472,,10.1109/LSENS.2022.3228327,https://doi.org/10.1109/LSENS.2022.3228327,IEEE
Contactless Elevator Button Control System Based on Weighted K-NN Algorithm for AI Edge Computing Environment,,https://ieeexplore.ieee.org/document/10247337/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10247337,"In recent years, attempts have been made to create a door-opening or elevator button that operates based on gestures when entering and exiting a building. This can consider the convenience of an individual carrying luggage, and in some cases, has the advantage of preventing the spread of disease between people through contact. In this study, we propose a method for operating elevator buttons without contact. Elevators cannot utilize high-performance processors owing to production costs. Therefore, this paper introduces a prototype of a low-performance processor-based system that can be used in elevators, and then introduces a weighted K-nearest neighbors (K-NN) based user gesture learning and number matching method for application in an optimal non-contact button control method that can be used in such an environment. As a result, through the proposed method, a performance gain of 7.5% in comparison to a conventional K-NN method and a performance improvement of 9.7% compared to a radial basis function were achieved in a relatively low-performance processor-based system.",Journal of Web Engineering,March 2022,443 - 458,,,10.13052/jwe1540-9589.21214,https://doi.org/10.13052/jwe1540-9589.21214,River Publishers
Evaluation of Applying Federated Learning to Distributed Intrusion Detection Systems Through Explainable AI,Ayaka Oki; Yukio Ogawa; Kaoru Ota; Mianxiong Dong; ; ; ; ,https://ieeexplore.ieee.org/document/10685528/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10685528,"We apply federated learning (FL) to a distributed intrusion detection system (IDS), in which we deploy numerous detection servers on the edge of a network. FL can mitigate the impact of decreased training data in each server and exhibit almost the same detection rate as that of the non-distributed IDS for all attack classes. We verify the effect of FL using explainable artificial intelligence (XAI); this effect is demonstrated by the distance between the feature set of each attack class in the distributed IDS and that in the non-distributed IDS. The distance increases for independent learning and decreases for FL.",IEEE Networking Letters,23 September 2024,198 - 202,2576-3156,,10.1109/LNET.2024.3465516,https://doi.org/10.1109/LNET.2024.3465516,IEEE
On the Existence of Robot Zombies and Our Ethical Obligations to AI Systems,,https://ieeexplore.ieee.org/document/10412089/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10412089,"As artificial intelligence algorithms improve, we will interact with programs that seem increasingly human. We may never know if these algorithms are sentient, yet this quality is crucial to ethical considerations regarding their moral status. We will likely have to make important decisions without a full understanding of the relevant issues and facts. Given this ignorance, we ought to take seriously the prospect that some systems are sentient. It would be a moral catastrophe if we were to treat them as if they were not sentient, but, in reality they are.",Journal of Social Computing,December 2023,270 - 274,2688-5255,,10.23919/JSC.2023.0023,https://doi.org/10.23919/JSC.2023.0023,TUP
AI Threats (Addressing Hawking and Musk),,https://ieeexplore.ieee.org/document/8139091/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8139091,"Professor Max Bramer, Chair, BCS Specialist Group on Artificial Intelligence (SGAI), addresses some recent comments made by Stephen Hawking and Elon Musk on AI (artifi cial intelligence).",ITNOW,June 2015,58 - 59,,,10.1093/itnow/bwv052,https://doi.org/10.1093/itnow/bwv052,OUP
Hybrid AI,,https://ieeexplore.ieee.org/document/8138733/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8138733,"There are many defi nitions of artificial intelligence (AI), but I often use this one: the science of mimicking human mental faculties in a computer. One of the criticisms of this definition is that it stops at human intelligence rather than superhuman intelligence, says Adrian Hopgood FBCS CITP, Pro Vice-Chancellor and Dean of the Sheffield Business School at Sheffield Hallam University.",ITNOW,December 2013,10 - 11,,,10.1093/itnow/bwt066,https://doi.org/10.1093/itnow/bwt066,OUP
"Dual Indicators to Analyze AI Benchmarks: Difficulty, Discrimination, Ability, and Generality",Fernando Martínez-Plumed; José Hernández-Orallo; ; ,https://ieeexplore.ieee.org/document/8550672/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8550672,"With the purpose of better analyzing the result of artificial intelligence (AI) benchmarks, we present two indicators on the side of the AI problems, difficulty and discrimination, and two indicators on the side of the AI systems, ability and generality. The first three are adapted from psychometric models in item response theory (IRT), whereas generality is defined as a new metric that evaluates whether an agent is consistently good at easy problems and bad at difficult ones. We illustrate how these key indicators give us more insight on the results of two popular benchmarks in AI, the Arcade Learning Environment (Atari 2600 games) and the General Video Game AI competition, and we include some guidelines to estimate and interpret these indicators for other AI benchmarks and competitions.",IEEE Transactions on Games,28 November 2018,121 - 131,,,10.1109/TG.2018.2883773,https://doi.org/10.1109/TG.2018.2883773,IEEE
Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond,Sidra Nasir; Rizwan Ahmed Khan; Samita Bai; ; ; ,https://ieeexplore.ieee.org/document/10445375/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10445375,"In the past decade, the deployment of deep learning (Artificial Intelligence (AI)) methods has become pervasive across a spectrum of real-world applications, often in safety-critical contexts. This comprehensive research article rigorously investigates the ethical dimensions intricately linked to the rapid evolution of AI technologies, with a particular focus on the healthcare domain. Delving deeply, it explores a multitude of facets including transparency, adept data management, human oversight, educational imperatives, and international collaboration within the realm of AI advancement. Central to this article is the proposition of a conscientious AI framework, meticulously crafted to accentuate values of transparency, equity, answerability, and a human-centric orientation. The second contribution of the article is the in-depth and thorough discussion of the limitations inherent to AI systems. It astutely identifies potential biases and the intricate challenges of navigating multifaceted contexts. Lastly, the article unequivocally accentuates the pressing need for globally standardized AI ethics principles and frameworks. Simultaneously, it aptly illustrates the adaptability of the ethical framework proposed herein, positioned skillfully to surmount emergent challenges.",IEEE Access,26 February 2024,31014 - 31035,2169-3536,,10.1109/ACCESS.2024.3369912,https://doi.org/10.1109/ACCESS.2024.3369912,IEEE
A Multianalytical SEM-ANN Approach to Investigate the Social Sustainability of AI Chatbots Based on Cybersecurity and Protection Motivation Theory,Ibrahim Arpaci; ,https://ieeexplore.ieee.org/document/10342742/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342742,"With a primary focus on cybersecurity risks, this study endeavors to explore the sustainable deployment of artificial intelligence (AI) chatbots and, ultimately, to promote their social sustainability. The study introduces an enhanced model built upon the “Protection Motivation Theory” (PMT) to explore the factors that predict the social sustainability of AI chatbots. The proposed model is evaluated using both “structural equation modeling” and “artificial neural network” (ANN) analyses, leveraging data obtained from 1741 participants. The findings reveal that PMT factors significantly predict the sustainable use of AI chatbots. Moreover, cybersecurity concerns, including confidentiality and privacy, have emerged as significant predictors of sustainable use, impacting the social sustainability of AI chatbots. The indicated paths in the model explain 70% and 74% of the variance in sustainable use and social sustainability, respectively. The results from the ANN analysis also emphasize the critical role of confidentiality as the primary predictor. The significance of this study lies in the development of a unified model that integrates cybersecurity and PMT, offering a distinctive framework. In addition to its theoretical contributions, the study offers practical insights for service providers, application developers, and decision-makers in the field, thereby influencing the future of AI chatbots.",IEEE Transactions on Engineering Management,05 December 2023,1714 - 1725,,,10.1109/TEM.2023.3339578,https://doi.org/10.1109/TEM.2023.3339578,IEEE
An Integer-Only Resource-Minimized RNN on FPGA for Low-Frequency Sensors in Edge-AI,Jim Bartels; Aran Hagihara; Ludovico Minati; Korkut Kaan Tokgoz; Hiroyuki Ito; ; ; ; ; ,https://ieeexplore.ieee.org/document/10161725/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161725,"The growth of Artificial Intelligence (AI) and the Internet of Things (IoT) sensors has given rise to a synergistic paradigm known as AIoT, wherein AI functions as the decision-maker and sensors collect information. However, a substantial proportion of AIoT rely on cloud-based AI, which process wirelessly transmitted raw data, increasing power consumption and reducing battery life at sensor nodes. Edge-AI has emerged as a promising alternative, implementing AI directly on sensor nodes, eliminating the need of raw data transmission. Despite its potential, there is a scarcity of hardware architectures optimized for resource-constrained platforms, such as field programmable gate arrays (FPGAs), particularly for low-frequency sensors. This work presents a shared-scale integer-only recurrent neural network (RNN) implemented on a Lattice ICE40UP5K FPGA using a resource-minimized time and layer-multiplexed (TLM) hardware architecture. This architecture adopts real-time processing, setting clock frequency to complete a single RNN timestep preceding the next sensor sample, reducing power consumption significantly. Measurements on this FPGA implementing our proposed architecture applied to a pretrained RNN on cow behavior show a power consumption of 360 \mu \text{W} at a clock frequency of 146 kHz and negligible accuracy loss at 8-bit bitwidth. This finding suggests that our methods lead to the most accurate implementation of animal behavior estimation with a power consumption below 500 \mu \text{W} on an FPGA. The implementation in Systemverilog and Python code is publicly available, enabling adaptation of the RNN for various tasks involving low-frequency sensors on resource-constrained FPGAs, thereby contributing to the further advancement and democratization of Edge-AI solutions.",IEEE Sensors Journal,23 June 2023,17784 - 17793,,,10.1109/JSEN.2023.3286580,https://doi.org/10.1109/JSEN.2023.3286580,IEEE
An Edge and Trustworthy AI UAV System With Self-Adaptivity and Hyperspectral Imaging for Air Quality Monitoring,Chun-Hsian Huang; Wen-Tung Chen; Yi-Chun Chang; Kuan-Ting Wu; ; ; ; ,https://ieeexplore.ieee.org/document/10584104/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10584104,"Leveraging the mobility and flexibility of unmanned aerial vehicles (UAVs), the proposed edge and trustworthy artificial intelligence (AI) UAV system (ETAUS) offers a comprehensive approach to air quality monitoring, complementing fixed monitoring stations. We propose a new convolutional neural network (CNN) model that utilizes hyperspectral imaging (HSI) data as input, enabling ETAUS to directly and accurately classify air quality index (AQI) levels without relying on a back-end AI computing platform. Additionally, ETAUS employs an FPGA-based system architecture, allowing for the integration of a neural engine, cryptographic hardware modules, and hardware protection matrices into a single FPGA device for accelerated processing, edge AI, and trustworthy AI functionalities. Based on its self-adaptivity, edge AI models, cryptographic hardware modules, and protection matrices can also be dynamically loaded into the system to support diverse functional requirements. Experiments have demonstrated that using our proposed CNN model and HSI data, the accuracy of AQI level classification can be achieved to 86.38%. ETAUS can achieve a speedup of $2.28\times $ to $36.9\times $ in terms of frames per second (FPS) for AQI-level classification compared to microprocessor-based and embedded GPU-based designs. ETAUS can also enhance energy efficiency by $2.7\times $ compared to embedded GPU solutions, such as NVIDIA Jetson Nano. To support all the cryptographic functions and protection matrices, system adaptivity in ETAUS can significantly increase resource utilization while decreasing power consumption by up to 2.79%.",IEEE Internet of Things Journal,03 July 2024,32572 - 32584,,,10.1109/JIOT.2024.3422470,https://doi.org/10.1109/JIOT.2024.3422470,IEEE
Toward Explainable Reasoning in 6G: A Proof of Concept Study on Radio Resource Allocation,Farhad Rezazadeh; Sergio Barrachina-Muñoz; Hatim Chergui; Josep Mangues; Mehdi Bennis; Dusit Niyato; Houbing Song; Lingjia Liu; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10689363/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10689363,"The move toward artificial intelligence (AI)-native sixth-generation (6G) networks has put more emphasis on the importance of explainability and trustworthiness in network management operations, especially for mission-critical use-cases. Such desired trust transcends traditional post-hoc explainable AI (XAI) methods to using contextual explanations for guiding the learning process in an in-hoc way. This paper proposes a novel graph reinforcement learning (GRL) framework named TANGO which relies on a symbolic subsystem. It consists of a Bayesian-graph neural network (GNN) Explainer, whose outputs, in terms of edge/node importance and uncertainty, are periodically translated to a logical GRL reward function. This adjustment is accomplished through defined symbolic reasoning rules within a Reasoner. Considering a real-world testbed proof-of-concept (PoC), a gNodeB (gNB) radio resource allocation problem is formulated, which aims to minimize under- and over-provisioning of physical resource blocks (PRBs) while penalizing decisions emanating from the uncertain and less important edge-nodes relations. Our findings reveal that the proposed in-hoc explainability solution significantly expedites convergence compared to standard GRL baseline and other benchmarks in the deep reinforcement learning (DRL) domain. The experiment evaluates performance in AI, complexity, energy consumption, robustness, network, scalability, and explainability metrics. Specifically, the results show that TANGO achieves a noteworthy accuracy of 96.39% in terms of optimal PRB allocation in inference phase, outperforming the baseline by 1.22\times .",IEEE Open Journal of the Communications Society,23 September 2024,6239 - 6260,2644-125X,,10.1109/OJCOMS.2024.3466225,https://doi.org/10.1109/OJCOMS.2024.3466225,IEEE
Anomalous Behaviors Detection for Underwater Fish Using AI Techniques,Jung-Hua Wang; Shih-Kai Lee; Yi-Chung Lai; Cheng-Chun Lin; Ting-Yuan Wang; Ying-Ren Lin; Te-Hua Hsu; Chang-Wen Huang; Chung-Ping Chiang; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9290081/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9290081,"Anomalous events detection in real-world video scenes is a challenging problem owing to the complexity of anomaly and the untidy backgrounds and objects in the scenes. Although there are already many studies on dealing with this problem using deep neural networks, very little literature aims for real-time detection of the anomalous behavior of fish. This paper presents an underwater fish anomalous behavior detection method by combining deep learning object detection, DCG (Directed Cycle Graph), fish tracking, and DTW (Dynamic Time Warping). The method is useful for detecting the biological anomalous behavior of underwater fish in advance so that early countermeasures can be planned and executed. Also, through post-analysis it is possible to access the cause of diseases or death, so as to reduce unnecessary loss, facilitate precision breeding selection, and achieve ecological conservation education as well. A smart aquaculture system incorporating the proposed method and IoT sensors allows extensive data collection during the system operation in various farming fields, thus enabling to develop optimal culturing conditions, both are particularly useful for researchers and the aquaculture industry.",IEEE Access,10 December 2020,224372 - 224382,2169-3536,,10.1109/ACCESS.2020.3043712,https://doi.org/10.1109/ACCESS.2020.3043712,IEEE
"Explainable AI for Time Series Classification: A Review, Taxonomy and Research Directions",Andreas Theissler; Francesco Spinnato; Udo Schlegel; Riccardo Guidotti; ; ; ; ,https://ieeexplore.ieee.org/document/9895252/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9895252,"Time series data is increasingly used in a wide range of fields, and it is often relied on in crucial applications and high-stakes decision-making. For instance, sensors generate time series data to recognize different types of anomalies through automatic decision-making systems. Typically, these systems are realized with machine learning models that achieve top-tier performance on time series classification tasks. Unfortunately, the logic behind their prediction is opaque and hard to understand from a human standpoint. Recently, we observed a consistent increase in the development of explanation methods for time series classification justifying the need to structure and review the field. In this work, we (a) present the first extensive literature review on Explainable AI (XAI) for time series classification, (b) categorize the research field through a taxonomy subdividing the methods into time points-based, subsequences-based and instance-based, and (c) identify open research directions regarding the type of explanations and the evaluation of explanations and interpretability.",IEEE Access,19 September 2022,100700 - 100724,2169-3536,,10.1109/ACCESS.2022.3207765,https://doi.org/10.1109/ACCESS.2022.3207765,IEEE
An ADC-Less RRAM-Based Computing-in-Memory Macro With Binary CNN for Efficient Edge AI,Yi Li; Jia Chen; Linfang Wang; Woyu Zhang; Zeyu Guo; Jun Wang; Yongkang Han; Zhi Li; Fei Wang; Chunmeng Dou; Xiaoxin Xu; Jianguo Yang; Zhongrui Wang; Dashan Shang; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/10004708/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10004708,"Resistive random-access memory (RRAM) based non-volatile computing-in-memory (nvCIM) has been regarded as a promising solution to enable efficient data-intensive artificial intelligence (AI) applications on resource-limited edge systems. However, existing weighted-current summation-based nvCIM suffers from device non-idealities and significant time, storage, and energy overheads when processing high-precision analog signals. To address these issues, we propose a 3T2R digital nvCIM macro for a fully hardware-implemented binary convolutional neural network (HBCNN), focusing on accelerating edge AI applications at low weight precision. By quantizing the voltage-division results of RRAMs through inverters, the 3T2R macro provides a stable rail-to-rail output without analog-to-digital converters or sensing amplifiers. Moreover, both batch normalization and sign activation are integrated on-chip. The hybrid simulation results show that the proposed 3T2R digital macro achieves an 86.2% (95.6%) accuracy on the CIFAR-10 (MNIST) dataset, corresponding to a 4.7% (1.9%) accuracy loss compared to the software baselines, which also feature a peak energy efficiency of 51.3 TOPS/W and a minimum latency of 8 ns, realizing an energy-efficient, low-latency, and robust AI processor.",IEEE Transactions on Circuits and Systems II: Express Briefs,02 January 2023,1871 - 1875,,,10.1109/TCSII.2022.3233396,https://doi.org/10.1109/TCSII.2022.3233396,IEEE
Big Data and AI Revolution in Precision Agriculture: Survey and Challenges,Showkat Ahmad Bhat; Nen-Fu Huang; ; ,https://ieeexplore.ieee.org/document/9505674/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9505674,"Sustainable agricultural development is a significant solution with fast population development through the use of information and communication (ICT) in precision agriculture, which produced new methods for making cultivation further productive, proficient, well-regulated while preserving the climate. Big data (machine learning, deep learning, etc.) is amongst the vital technologies of ICT employed in precision agriculture for their huge data analytical capabilities to abstract significant information and to assist agricultural practitioners to comprehend well farming practices and take precise decisions. The main goal of this article is to acquire an awareness of the Big Data latest applications in smart agriculture and be acquainted with related social and financial challenges to be concentrated on. This article features data creation methods, accessibility of technology, accessibility of devices, software tools, and data analytic methods, and appropriate applications of big data in precision agriculture. Besides, there are still a few challenges that come across the widespread implementation of big data technology in agriculture.",IEEE Access,03 August 2021,110209 - 110222,2169-3536,,10.1109/ACCESS.2021.3102227,https://doi.org/10.1109/ACCESS.2021.3102227,IEEE
Explanation as a Social Practice: Toward a Conceptual Framework for the Social Design of AI Systems,Katharina J. Rohlfing; Philipp Cimiano; Ingrid Scharlau; Tobias Matzner; Heike M. Buhl; Hendrik Buschmeier; Elena Esposito; Angela Grimminger; Barbara Hammer; Reinhold Häb-Umbach; Ilona Horwath; Eyke Hüllermeier; Friederike Kern; Stefan Kopp; Kirsten Thommes; Axel-Cyrille Ngonga Ngomo; Carsten Schulte; Henning Wachsmuth; Petra Wagner; Britta Wrede; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9292993/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9292993,"The recent surge of interest in explainability in artificial intelligence (XAI) is propelled by not only technological advancements in machine learning but also by regulatory initiatives to foster transparency in algorithmic decision making. In this article, we revise the current concept of explainability and identify three limitations: passive explainee, narrow view on the social process, and undifferentiated assessment of explainee’s understanding. In order to overcome these limitations, we present explanation as a social practice in which explainer and explainee co-construct understanding on the microlevel. We view the co-construction on a microlevel as embedded into a macrolevel, yielding expectations concerning, e.g., social roles or partner models: typically, the role of the explainer is to provide an explanation and to adapt it to the current level of explainee’s understanding; the explainee, in turn, is expected to provide cues that direct the explainer. Building on explanations being a social practice, we present a conceptual framework that aims to guide future research in XAI. The framework relies on the key concepts of monitoring and scaffolding to capture the development of interaction. We relate our conceptual framework and our new perspective on explaining to transparency and autonomy as objectives considered for XAI.",IEEE Transactions on Cognitive and Developmental Systems,14 December 2020,717 - 728,,,10.1109/TCDS.2020.3044366,https://doi.org/10.1109/TCDS.2020.3044366,IEEE
Low Complexity Binarized 2D-CNN Classifier for Wearable Edge AI Devices,David Liang Tai Wong; Yongfu Li; Deepu John; Weng Khuen Ho; Chun-Huat Heng; ; ; ; ; ,https://ieeexplore.ieee.org/document/9848993/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9848993,"Wearable Artificial Intelligence-of-Things (AIoT) devices exhibit the need to be resource and energy-efficient. In this paper, we introduced a quantized multilayer perceptron (qMLP) for converting ECG signals to binary image, which can be combined with binary convolutional neural network (bCNN) for classification. We deploy our model into a low-power and low-resource field programmable gate array (FPGA) fabric. The model requires 5.8× lesser multiply and accumulate (MAC) operations than known wearable CNN models. Our model also achieves a classification accuracy of 98.5%, sensitivity of 85.4%, specificity of 99.5%, precision of 93.3%, and F1-score of 89.2%, along with dynamic power dissipation of 34.9 μW.",IEEE Transactions on Biomedical Circuits and Systems,03 August 2022,822 - 831,,35921347,10.1109/TBCAS.2022.3196165,https://doi.org/10.1109/TBCAS.2022.3196165,IEEE
Learning Finite-State Machine Controllers From Motion Capture Data,Marco Gillies; ,https://ieeexplore.ieee.org/document/4812072/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4812072,"With characters in computer games and interactive media increasingly being based on real actors, the individuality of an actor's performance should not only be reflected in the appearance and animation of the character but also in the AI that governs the character's behavior and interactions with the environment. Machine learning methods applied to motion capture data provide a way of doing this. This paper presents a method for learning the parameters of a finite-state machine (FSM) controller. The method learns both the transition probabilities of the FSM and also how to select animations based on the current state.",IEEE Transactions on Computational Intelligence and AI in Games,07 April 2009,63 - 72,,,10.1109/TCIAIG.2009.2019630,https://doi.org/10.1109/TCIAIG.2009.2019630,IEEE
A Stackelberg Game Approach for Managing AI Sensing Tasks in Mobile Crowdsensing,Hamta Sedghani; Mina Zolfy Lighvan; Hadi S. Aghdasi; Mauro Passacantando; Giacomo Verticale; Danilo Ardagna; ; ; ; ; ; ,https://ieeexplore.ieee.org/document/9866032/,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9866032,"Mobile Crowdsensing (MCS) is a new paradigm that leverages the collective sensing ability of a crowd so that a special task can be performed through the aggregation of information collected from personal mobile devices. While MCS brings several benefits, its application is prevented by challenges such as the efficient recruitment of users, effective mechanisms for rewarding users to encourage participation, and an effective and fast enough approach for managing the underlying resources that support large-scale MCS applications involving a large number of people in data collection. On the other hand, Artificial Intelligence (AI) applications, which are mostly based on Deep Neural Networks (DNN), are becoming pervasive today and are executed by the end users’ mobile devices, which are characterised by limited memory and computing power, and low battery level. This paper describes and evaluates an incentive mechanism for a mobile crowdsensing system with an AI sensing task based on a one-leader multi-follower Stackelberg game. The MCS platform, as a leader, provides an AI sensing task to be executed by a DNN, which can be deployed in two different ways: fully on the user device or partially on the device and partially on edge or cloud resources. The users, as followers, make their decisions regarding their participation to the MCS system and select their desired deployment given the energy and memory available on their device and the deployment reward proposed by the MCS platform. The goals of the MCS platform are: i) to motivate the users to participate in the system, ii) to maximize its profit, and iii) to identify the optimal resources supporting the sensing task that minimizes the cost and provide performance guarantees. This problem has been formulated as a mixed integer nonlinear program and propose an efficient algorithmic approach to solve it quickly. The proposed approach has been compared with some baseline methods and with BARON state-of-the-art solver. Resu...",IEEE Access,24 August 2022,91524 - 91544,2169-3536,,10.1109/ACCESS.2022.3201353,https://doi.org/10.1109/ACCESS.2022.3201353,IEEE
